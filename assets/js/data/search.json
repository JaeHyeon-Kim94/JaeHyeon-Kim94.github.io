[ { "title": "하드 디스크 관리", "url": "/posts/%ED%95%98%EB%93%9C/", "categories": "linux", "tags": "linux", "date": "2023-04-10 00:00:00 +0900", "snippet": " 리눅스 디스크 파티션 마운트 포인트 설명   / 루트 파티션   /bin 기본 명령어   /sbin 시스템 관리용 명령어   /etc 시스템의 환경 설정 관련 파일   /boot 부팅 커널   /media 외부 장치 마운트 위해 제공   /usr 응용 프로그램이 주로 저장됨   /lib 프로그램의 라이브러리가 저장   /dev 장치 파일들이 저장   /proc 시스템의 프로세서 정보, 프로그램 정보, 하드웨어 정보 등     tmp 임시 파일 /var 로그 파일   /root 시스템 관리자 root의 홈 디렉터리   /lost+found 파일 시스템 복구 위한 디렉터리   /swap RAM 부족시 사용되는 공간   하드 디스크 네이밍처음 장착된 하드디스크의 이름을 /dev/sda라고 하며, 추가로 장착될 경우 /dev/sdb, /dev/sdc와 같은 방식으로 네이밍.디스크에 대해 나뉘어진 파티션은 그 뒤에 넘버링으로 구분한다. ex. /dev/sda1, /dev/sda2그리고 리눅스에서 이러한 파티션은 CD, USB처럼 반드시 특정한 디렉터리에 마운트 시켜야 사용할 수 있다. 파티션 할당파티셔닝은 하나의 물리적 저장장치를 시스템 내부에서 여러 디스크 공간으로 나누는 작업을 말함. 이 공간은 물리적으로 나뉠 수도, 논리적으로 나뉠 수도 있는데물리적으로 나뉘는 경우를 Primary, 논리적으로 나뉘는 경우를 Extended라고 한다. 나뉜 각각의 저장 공간을 파티션이라고 한다.Primary는 네 개의 파티션까지 설정 가능하다. 한 디스크에 다섯 개 이상 설정하기 위해서는 Extended 파티션을 2개 이상의 Logical 파티션으로 설정해야 한다.# 1. 하드 디스크에 파티션 할당$ fdisk /dev/sdb # SCSI 0:1 하드디스크 선택&gt; Command : n #새로운 파티션&gt; Select : p #primary 파티션 &gt; Partition number : 1 #파티션 번호. 최대 4&gt; First sector : #시작 섹터&gt; Last sector : #마지막 섹터&gt; Command : w #설정 저장# 2. 파일 시스템 설정(파일시스템 : ext4, xfs, ext2, ext3)$ mkfs -t 파일시스템 파티션장치# 혹은$ mkfs.파일시스템 파티션 장치# ex) mkfs -t ext4 /dev/sdb1 디렉터리 마운트$ mkdir /mydata$ mount /dev/sdb1 /mydata$ umount /dev/sdb1mydata 디렉터리는 마운트된 디스크 파티션의 저장 항목들을 보여주게 된다. 즉, /dev/sda2에 마운트 되면 해당 파티션의 항목들을, /dev/sdb1에 마운트 되면 해당 파티션 항목들을 보여준다.이렇게 파티션을 나누어 사용할 필요가 있을 경우에는 디스크 추가 =&gt; 파티션 할당 =&gt; 파일 시스템 설정 =&gt; 디렉터리 마운트 의 과정이 필요하다. 부팅시 디렉터리 마운트 자동화 설정$ vi /etc/fstabUUID=314207a5-5f68-405d-a787-7cd8cd8a66f6 / xfs defaults 0 0UUID=dad90950-01b5-4d05-b363-874805a29721 swap swap defaults 0 0/dev/sdb1 /mydata ext4 defaults 0 0/etc/fstab은 마운트 정보가 수록되어 있으며, 리눅스 부팅시 자동으로 읽는 파일.총 필드는 여섯 가지이며, 순서대로 장치 이름 마운트될 디렉터리 파일 시스템 속성 dump 사용 여부 파일 시스템 체크 여부REFERENCES이것이 리눅스다 with RedHat CentOS 8" }, { "title": "RAID와 LVM", "url": "/posts/RAID-LVM/", "categories": "linux", "tags": "linux", "date": "2023-04-10 00:00:00 +0900", "snippet": "RAID와 LVMRAIDRAID(Redundant Array of Inexpensive/Independent Disks)는 여러 디스크를 하나로 묶어 하나의 논리적 디스크로 작동하게 하는 것이다.RAID에는 하드웨어 방식과 소프트웨어 방식이 있는데 하드웨어 방식은 고비용, 고성능, 안정적이라는 특징을, 소프트웨어 방식은 저비용, 비교적 저성능 등의 특징을 가지고 있다.RAID 레벨RAID는 구성 방식에 따라서 성능, 용량이 바뀌게 된다. Linear RAID와 RAID 0Linear RAID 방식은 2개 이상의 하드 디스크를 1개의 볼륨으로 사용하고, 앞 디스크의 저장공간이 꽉 차게 되면 다음 저장 공간에 데이터를 저장하는 방식이다.따라서 앞 디스크의 저장 공간이 남아 있다면 다음 저장 공간은 사용되지 않는다.Linear는 순차적으로 저장하는 방식이기 때문에 각 하드디스크의 용량이 달라도 각 디스크 용량의 총 합만큼 저장 공간을 활용할 수 있다는 장점이 있다.(공간 효율성 100%) 단점은 병렬형 저장방식보다 속도 측면에서 느리다는 단점이 있다.Linear 방식과 다르게 RAID 0 방식은 복수의 하드 디스크에 동시에 저장되며, 이를 스트라이핑방식이라고 한다.동시에 저장하는 병렬형 저장방식이기 때문에 속도 측면에서 가장 우월한 장점을 가지고 있으나, 그만큼 데이터의 위험성도 높다. 또한 데이터를 나눠 보관하기 때문에 각 디스크가 용량에 있어서 차이가 클 수록 공간 활용도는 떨어질 수 있다. RAID 1RAID1 방식은 미러링을 이용한 방식으로서, 데이터 저장시 복수의 하드디스크에 동일하게 저장한다. 공간 효율은 50%밖에 나오지 않는다는 단점이 있지만, 한 쪽이 고장나도 다른 한 쪽에 같은 데이터가 있기 때문에 데이터 안정성이 높다는 장점이 있다. 높은 비용을 감수하고서라도 중요한 데이터를 저장할 필요가 있을 때 사용한다.(결함 허용) RAID 5RAID 5는 위의 RAID 0과 RAID 1의 장점을 취하기 위한 방법으로서, 방식상 최소한 3개 이상의 하드디스크가 있어야 구성할 수 있다.이 방식은 패리티를 이용하기 때문에 디스크에 문제가 생겨도 비트를 유추하여 데이터를 복구할 수 있다.(결함 허용)000 111 010 011이라는 12bit 데이터를 4개의 디스크에 저장해야 한다고 했을 때, 데이터를 병렬저장하되 4개의 디스크 중 한 디스크는 패리티 데이터를 저장하기 위한 공간으로 사용한다. 짝수 패리티의 경우 각 행이 짝수가 되도록 패리티 데이터를 저장하고, 만약 한 디스크가 고장났을 시 패리티 데이터를 참고하여 상실된 데이터를 유추할 수 있게 된다.이러한 방식이기 때문에 데이터의 결함에도 어느 정도 대응이 가능하고 디스크가 N개일 경우 N-1 만큼의 공간을 사용할 수 있어 공간 효율이 높다.다만 디스크가 두 개 이상 고장이 날 경우 데이터는 복구할 수 없게 된다. RAID 6RAID 6은 RAID 5의 문제점을 개선하기 위해 2개의 패리티를 사용한 방식이다. 최소 4개의 디스크가 필요하다. 비교적 공간 효율이 낮지만 데이터 신뢰도를 확보할 수 있는 방식이다. RAID 0+1 / RAID 1+01+0은 미러링 후 스트라이핑, 0+1은 스트라이핑 후 미러링 하는 방식이다. 안정성과 비용 측면에서 10이 더 우월하다### RAID 구축하기 디스크 및 파티션 설정 과정은 생략한다. 다만, 파티션 설정시 type을 fd로 설정해야 한다.(Command : t, Hex code : fd) Linear RAID(1) RAID 장치 생성$ fdisk -l /dev/sdb; fdisk -l /dev/sdc #디스크 선처리 작업 완료 여부 확인$ mdadm --create /dev/md9 --level=linear --raid-devices=2 /dev/sdb1 /dev/sdc1 #RAID 생성# 다른 방식의 경우 0 : raid0, 1 : raid1 ...# 1+0의 경우 : raid1 장치를 각각 생성 후(level=1) 두 raid 장치를 --raid-devices 옵션으로 지정한다(level=0).$ mdadm --detail --scan #RAID 확인mdadm 명령 --create /dev/md9 : md9 장치에 RAID 생성. md9는 사용자가 임의로 설정. linear는 식별할 수 있는 번호 없기에 비어있는 9로 지정 --level=linear : Linear RAID로 지정. 0은 RAID 0, 1은 RAID 1 --raid-devices=2 /dev/sdb1, /dev/sdc1 : 2개의 하드 디스크 사용하며, 뒤에는 공백을 구분자로 하여 장치 이름을 지정한다. --stop /dev/md9 : RAID 장치 /dev/md9 작동 중지 --run /dev/md9 : 중지된 장치 가동 --detail /dev/md9 : 장치 상세 내용 출력(2) 장치의 파일 시스템 생성$ mkfs -t ext4 /dev/md9(3) 디렉터리 마운트$ mkdir /raidLinear #디렉터리 생성$ mount /dev/md9 /raidLinear #마운트$ df #결과 확인$ mdadm --detail /dev/md9 #상세 내용 확인(+) 부팅시 자동으로 마운트 되도록 fstab 파일 설정$ vi /etc/fstab#아래 내용 append/dev/md9 /raidLinear ext4 defaults 0 0LVM(Logical Volumn Manager)LVM은 주로 여러 하드디스크를 합쳐 하나의 파티션으로 구성한 뒤 다시 필요에 따라 나눌 때 사용한다.즉, 하드디스크 파티션들을 하나의 볼륨 그룹으로 합치고 이 볼륨 그룹을 다시 적절한 용량으로 필요에 따라 논리 볼륨으로 나눈다.# 1. 파티셔닝$ fdisk /dev/sdb&gt; Command : n&gt; Select : p&gt; Partition number(1-4) : 1&gt; First sector : &gt; Last sector : &gt; Command : t&gt; Hex Code : 8e&gt; Command : w#2. 물리 볼륨 생성$ pvcreate /dev/sdb1$ pvcreate /dev/sdc1#3. 볼륨 그룹 생성$ vgcreate myVG /dev/sdb1 /dev/sdc1#4. 볼륨 그룹 확인$ vgdisplay#5. 볼륨 그룹의 파티션 생성(논리 볼륨 생성)$ lvcreate --size 1G --name myLG1 myVG$ lvcreate --size 3G --name myLG2 myVG$ lvcreate --extents 100%FREE --name myLG3 myVG#6. 파일 시스템 생성$ mkfs.ext4 /dev/myVG/myLG1$ mkfs.ext4 /dev/myVG/myLG2$ mkfs.ext4 /dev/myVG/myLG3#7. 디렉터리 생성 및 마운트$ mkdir /lvm1$ mkdir /lvm2$ mkdir /lvm3$ mount /dev/myVG/myLG1 /lvm1$ mount /dev/myVG/myLG2 /lvm2$ mount /dev/myVG/myLG3 /lvm3REFERENCES이것이 리눅스다 with RedHat CentOS 8" }, { "title": "커널과 모듈", "url": "/posts/%EC%BB%A4%EB%84%90%EA%B3%BC-%EB%AA%A8%EB%93%88/", "categories": "linux", "tags": "linux", "date": "2023-04-07 00:00:00 +0900", "snippet": "커널과 모듈커널의 구조와 기능컴퓨터는 크게 하드웨어(HW)와 소프트웨어(SW)로 나뉘고, SW는 다시 운영체제와 응용 프로그램으로 나뉜다.그리고 운영체제는 커널과 시스템 프로그램으로 구분되는데, 사용자와의 직접적인 상호작용은 시스템 프로그램을 통해서 이루어지며 커널은 컴퓨터 자원들을 관리하는 운영체제의 핵심 부분이다.컴퓨터 자원은 물리적인 하드웨어 자원과 추상화된 자원을 의미하는 것으로, 자원을 추상화한다는 것은 물리적으로 하나 뿐인 하드웨어를 여러 사용자들이 번갈아 사용하게 중재함으로서, 마치 한 개의 하드웨어가 여러개인 것 처럼 보여지도록 하는 것을 의미한다. 커널이 추상화하여 관리하는 물리적 자원(A)들과 이를 추상화한 자원을 칭하는 용어(B) A B CPU 태스크(task) 메모리 페이지(page), 세그먼트(segment) 디스크 파일(file) 네트워크 소켓(socket) 이 외에 외부 장치(프린터, 키보드 등)가 있다.결론적으로 커널은 하드웨어 자원을 관리하는 역할을 하며, 커널의 구성요소들은 각각 특정 하드웨어 자원을 관리하는 관리자로, 다음과 같다. Task Manager : 프로세스 생성 및 소멸 담당. 프로세스 스케줄러로 여러 프로세스가 동작할 수 있도록 각 프로세스 생성 및 제거 Memory Manager : 시스템 메모리 하드웨어의 효율적 관리. 각각의 프로세스가 독립적 공간에서 수행할 수 있도록 가상 메모리 주소를 제공하여 이 가상 메모리를 관리. File System Manager : 시스템에 동작하는 모든 자원을 파일처럼 다룰 수 있도록 인터페이스를 제공 Network Manager : 응용 프로그램과 네트워크 디바이스 드라이버를 연결 Device Driver : 입출력 장치 관리, 인터럽트 요청 및 처리 등 기능 수행커널 구성요소들이 존재하는 공간인 Kernel Space,태스크(Process)가 돌아가는 공간인 User Space,Hardware 세 영역으로 나뉘는데, C/C++과 같은 컴퓨팅 언어로 작성된 프로그램 파일이 메모리상에 적재되어 실행되면 task가 되고, 이 task에서 커널이 관리하는 자원(하드웨어)에 접근할 필요가 있을 경우 System Call Interface를 통해 Kernel Space의 자원 관리자에게 요청이 전달된다. 그리고 커널의 자원 관리자는 사용자 요청에 맞는 하드웨어에 사용자 명령을 전달하고 작업을 수행한다.커널과 모듈위에 설명한 것처럼, 커널은 하드웨어 자원을 관리/지원하는 역할을 수행한다. 초창기 커널의 경우 지원할 하드웨어 자원이 많지 않았으므로 문제가 없었으나, 시간이 지날수록 지원해야 할 하드웨어가 많아짐에 따라 커널에도 들어가야 할 코드가 많아지게 되었다. 이렇게 되면 운영체제가 무거워지는 결과를 낳게 되는데, 항상 필요한 부분이 아니라 가끔씩 필요할 때에만 사용하는 경우에는 별도로 보관하다가 필요시 호출하는 방식으로 분리하게 되었다. 이렇게 별도로 보관되는 것을 모듈이라고 한다.이렇게 분리하거나 커널에 넣어두는 기존 커널이 사용자 입장에서 적절하지 않을 수 있다. 각각이 필요한 기능, 필요하지 않은 기능들이 다를 것이기 때문에 커널에 포함될 것과 모듈로 분리할 것을 사용자가 원하는 대로 지정하여 다시 컴파일하게 되면 같은 하드웨어라도 더 효율적인 성능을 발휘할 수 있게 된다.커널 컴파일 추가적 학습 필요CentOS 8 기준 커널 : /boot/vmlinuz* 파일 모듈 : /lib/modules/{version}/ 디렉터리#1. 관련 패키지 설치$ dnf -y install make bison flex elfutils-libelf-devel openssl-devel gcc gcc-c++#2. 현재 디렉터리 확인(unpack된 커널 소스 파일이 있는 디렉터리)$ pwd #3. 커널 설정 초기화$ make mrproper#4. 커널 환경 설정$ make xconfig#5. 설정 파일 편집$ vi .config # ==&gt; CONFIG_SYSTEM_TRUSTED_KEYRING, CONFIG_SYSTEM_TRUSTED_KEYS 주석처리#6. 컴파일#6.1. 이전 컴파일 정보 삭제$ make clean#6.2. 컴파일$ make; make moduels_install; make install# 7. 결과 확인$ ls -l /lib/modules$ ls -l /bootREFERENCES커널의 개념과 커널의 구조리눅스 커널과 디바이스 드라이버이것이 리눅스다 with RedHat CentOS 8" }, { "title": "명령어", "url": "/posts/%EB%AA%85%EB%A0%B9%EC%96%B4/", "categories": "linux", "tags": "linux", "date": "2023-04-07 00:00:00 +0900", "snippet": "Linux 명령어4.14.1.1 터미널/콘솔에서 시스템 종료 명령 실행 poweroff shutdown -P now P : poweroff (ex. shutdown -P +10 shutdown -r 22:00 은 각각 10분 후에 종료, 22시에 재부팅) c : cancel (예약된 shutdown 취소) r : reboot k : 실제로 종료되지는 않지만, 종료된다고 다른 사용자에게 메시지 출력. halt -p init 0cf) 가상 콘솔 Ctrl + Alt + f1~64.1.5 런레벨 런레벨 영문 모드 설명 비고 0 Power Off 종료 모드   1 Rescue 시스템 복구 모드 단일 사용자 모드 2 Multi-User   사용하지 않음 다만 호환성을 위해 3번과 동일한 것으로 취급 3 Multi-User 텍스트 모드의 다중 사용자 모드   4 Multi-User   사용하지 않음. 다만 호환성을 위해 3번과 동일한 것으로 취급 5 Graphical 그래픽 모드의 다중 사용자 모드   6 Reboot     런레벨 변경 실습 터미널에서 현재 설정된 런레벨 확인# 1$ cd # 2 링크 파일 확인$ ls -l /etc/systemd/system/default.target## 결과 : /etc/systemd/system/default.target -&gt; /lib/systemd/system/graphical.target ==&gt; 그래픽 환경으로 부팅되는 것을 확인할 수 있다.# 3 텍스트 모드로 런레벨 변경$ ln -sf /lib/systemd/system/multi-user.target /etc/systemd/default.target# 4 결과 확인$ ls -l /etc/systemd/system/default.target# 5 텍스트 모드에서 x윈도를 실행하려면 $ startx# 6 다시 그래픽 환경으로 변경$ ln -sf /lib/systemd/system/graphical.target /etc/systemd/system/default.target4.1.6 자동 완성과 히스토리 자동 완성 tab tab 두번 누를 경우 후보들 출력됨. 히스토리 history : 기존에 사용했던 명령들 출력 -c : 히스토리 삭제 vi editor 책 165, 166 참고4.1.8 도움말 사용법 man &lt;명령어&gt; : 명령어에 대한 메뉴얼 확인 종료 : q 입력4.1.9 마운트와 CD/DVD/USB 활용 마운트된 장비 확인 : mount 입력 마운트 해제 : umount &lt;장치명&gt; cd : /dev/cdrom0 자동으로 마운트될 경우 /run/media/&lt;사용자이름&gt;/&lt;CD/DVC의 라벨 이름&gt; 4.2 리눅스 기본 명령어 ls List의 약자로, 해당 디렉터리에 있는 파일의 목록을 나열한다. 사용 예 ls [옵션] [파일] $ ls -a /etc/sysconfig/a* #/etc/sysconfig 디렉터리에 있는 파일 목록 중 a로 시작하는 것을 출력.(-a : 숨김파일 포함) pwd 현재 디렉터리의 전체 경로를 출력한다. rm remove의 약자로 파일이나 디렉터리를 삭제한다. 사용 예 rm [옵션] [파일] $ rm -i abc.txt #해당 파일 삭제. 삭제여부 확인$ rm -f abc.txt #해당 파일 삭제. 삭제여부 확인하지 않음.(force)$ rm -r abc #해당 디렉터리 삭제.(recursive)$ rm -rf abc #abc 디렉터리와 그 아래에 있는 하위 디렉터리 모두를 강제로 전부 삭제. cp copy의 약자로 파일이나 디렉터리 복사(새로 복사한 파일은 복사한 사용자의 소유가 됨. 읽기 권한 필요함) 사용 예 cp [옵션] [파일] $ cp abc.txt cba.txt : 파일 이름 변경하여 복사$ cp -r abc cba : 디렉터리 복사 touch 크기가 0인 새 파일 생성하거나, 이미 파일이 존재한다면 파일의 최종 수정시간 변경 mv move의 약자로, 파일이나 디렉터리의 이름을 변경하거나 다른 디렉터리로 옮김 사용 예 mv [옮길 파일] [옮길 위치와 파일명] mkdir make directory의 약자로, 새로운 디렉터리 생성함. 명령 실행 사용자의 소유 사용 예 mkdir [옵션] [디렉터리 경로 및 이름] $ mkdir -p /dev/fgh # fgh 디렉터리 생성하는데, 만약 부모 디렉터리가 존재하지 않을 경우 생성.(parent) rmdir remove directory로서 디렉터리 삭제. 파일이 들어있는 디렉터리라면 rm -r 실행. cat concatenate의 약자로, 파일 내용을 화면에 보여줌. 여러 파일을 나열할 경우 파일을 연결해서 보여준다. head, tail 텍스트 형식으로 작성된 파일의 앞 10행 또는 마지막 10행만 화면에 출력한다. 사용 예 head|tail [옵션] [파일명] $ head -3 anaconda-ks.cfg # 앞 3행만 화면에 출력 more 텍스트 형식으로 작성된 파일을 페이지 단위로 화면에 출력한다. 사용 예 more [옵션] [파일명] $ more +100 anaconda-ks.cfg # 100행부터 출력 less more과 비슷하지만 더 확장된 명령어. file 어떤 종류의 파일인지 표시. 4.3 사용자 관리와 파일 속성4.3.1 사용자와 그룹 사용자 확인$ cat /etc/passwd#결과 포맷#사용자 이름:암호:사용자 ID:사용자가 소속된 그룹 ID:전체 이름:홈 디렉터리:기본 셀$ cat /etc/group#결과 포맷#그룹 이름:비밀번호:그룹 ID:그룹에 속한 사용자 이름 useradd(또는 adduser) : 새로운 사용자 추가. 사용자 생성시 해당 사용자에 대해 새로운 홈 디렉터리가 지정되며(/home/사용자이름),/etc/skel 디렉터리의 모든 내용을 사용자의 홈 디렉터리에 복사하는 작업이 발생한다.따라서 생성되는 사용자에 특정 파일을 배포하고 싶을 경우 /etc/skel에 넣어두면 된다. $ useradd newuser #newuser 이름의 사용자 생성$ useradd -u 1111 newuser #사용자 ID를 1111로 지정$ useradd -g mygroup newuser #mygroup에 포함.mygroup 필요$ useradd -d /newhome newuser #홈 디렉터리를 /newhome으로.$ useradd -s /bin/csh newuser #기본 셀을 /bin/csh로 지정. passwd : 사용자 비밀번호 지정 혹은 변경 usermod : 사용자의 속성을 변경. 옵션은 useradd와 동일. $ usermod -g root newuser # newuser 사용자의 그룹을 root 그룹으로 변경 userdel : 사용자 삭제 $ userdel newuser$ userdel -r newuser #사용자 삭제와 함께 홈 디렉터리까지 삭제 chage : 사용자 암호를 주기적으로 변경하도록 설정 $ chage -l newuser #newuser 사용자에 설정된 사항 확인$ chage -m 2 newuser #newuser 사용자에 설정된 암호를 사용해야 하는 최소 일자(2일)$ chage -M 30 newsuer #bewuser 사용자에 설정된 암호를 사용할 수 있는 최대 일자(30일)$ chage -E 2026/12/12 newuser #암호가 만료되는 날짜$ chage -W 10 newuser #암호 만료 전에 경고하는 기간(기본값 7). 암호 만료 10일 전부터 경고 groups : 사용자가 소속된 그룹 보여준다. $ groups #현재 사용자의 그룹$ groups newuser #newuser의 그룹 groupadd : 새로운 그룹 생성 $ groupadd newgrouop #newgroup 생성$ groupadd -g 2222 newgroup #newgroup 생성하며 그룹 ID를 2222로 지정 groupmod : 그룹의 속성 변경 $ groupmod -n mygroup newgroup #이름을 mygroup으로 변경 groupdel : 그룹 삭제(해당 그룹을 주요 그룹으로 지정한 사용자 없어야 함.) gpasswd : 그룹의 암호를 설정하거나 그룹 관리를 수행. $ gpasswd newgroup$ gpasswd -A newuser newgroup #newuser 사용자를 newgroup 그룹의 관리자로 지정$ gpasswd -a user1 newgroup #user1을 newgroup의 사용자로 추가$ gpasswd -d newuser newgroup #newuser를 newgroup의 사용자에서 제거 4.3.2 파일과 디렉터리의 소유권과 허가권 파일 유형d : 디렉터리- : 일반 파일b : 블록 디바이스c : 문자 디바이스l : 링크 파일 파일 허가권총 아홉자리로, 세 글자씩 끊어서 사용자의 읽기/쓰기/실행 권한(rwx) + 그룹 rwx + 그 외 사용자(Other)의 rwx chmod : 파일의 허가권을 변경하는 명령어 $ chmod 777 sample.txt #sample.txt를 모든 사용자가 읽고 쓰고 실행 가능$ chmod u+x 파일이름 #상대적인 표현. 해당 파일에 대해 사용자에게 실행 권한 부여.$ chmod g-x 파일이름 #해당 파일에 대한 그룹의 실행 권한 revoke$ chmod o+rwx 파일이름 #그 외 사용자(others)에 대해 읽/쓰/실 허가 chown : 파일의 소유권을 변경하는 명령어$ chown 새로운사용자이름(.새로운그룹이름) 파일이름 #format$ chown centos sample.txt #sample.txt의 소유자를 centos 사용자로 변경$ chown centos.centosGroup sample.txt #사용자 뿐 아니라 파일의 그룹도 변경$ chgrp centos sample.txt #그룹만 변경4.4 리눅스 관리자를 위한 명령어4.4.1 프로그램 설치를 위한 RPM RPM은 레드햇 사에서 제작한 설치 파일이며, .rpm의 확장자명을 가지고 파일의 형식은 패키지이름-버전-릴리스번호.Centos버전.아키텍처.rpm이다.자주 사용하는 rpm 명령어 옵션설치$ rpm -Uvh 패키지파일이름.rpm# U : 기존의 패키지가 설치되지 않았다면 일반적인 설치를 진행하며, 설치되어있는 경우에는 업그레이드.# v : 설치 과정 확인# h : 설치 진행 과정을 # 기호로 화면에 출력삭제$ rpm -e 패키지이름 # (erase)이미 설치된 패키지 조회$ rpm -qa 패키지이름 # 시스템에 패키지가 설치되었는지 확인$ rpm -qf 파일의절대경로 # 이미 설치된 파일이 어느 패키지에 포함된 것인지 확인$ rpm -ql 패키지이름 # 특정 패키지에 어떤 파일들이 포함되어있는지 확인$ rpm -qi 패키지이름 # 설치된 패키지의 상세 정보# q : query아직 설치되지 않은 rpm 파일 조회$ rpm -qlp 패키지파일이름.rpm #패키지 파일에 어떤 파일들이 포함되었는지 확인$ rpm -qip 패키지파일이름.rpm #패키지 파일의 상세 정보DNFrpm은 마운트된 cd, usb 혹은 rpm 파일이 있어야 하며, 의존성 관리가 되지 않았지만dnf의 경우에는 원격 저장소로부터 패키지를 다운로드하고, 의존성 관리도 함께 해줌.DNF의 기본 사용법기본 설치 방법$ dnf -y install 패키지이름rpm 파일 설치 방법$ dnf install rpm파일이름.rpm업데이트 가능한 목록 보기$ dnf check-update업데이트$ dnf update 패키지이름삭제$ dnf remove 패키지이름정보 확인$ dnf info 패키지이름패키지 그룹 설치$ dnf groupinstall 패키지그룹이름패키지 리스트 확인$ dnf list 패키지이름$ dnf list httpd* #httpd 이름이 들어간 패키지 목록$ dnf list available특정 파일이 속한 패키지 이름 확인$ dnf provides 파일이름 # 특정 파일이 어느 패키지에 들어있는지 확인 가능.GPG 키 검사 생략$ dnf install --nogpgcheck rpm파일이름.rpm기존 저장소 목록 지우기$ dnf clean all4.4.3 파일 압축과 묶기파일 압축xz : 확장명 xz로 압축하거나 풀어줌.$ xz 파일이름 #파일 이름을 압축 파일인 파일이름.xz로 만들며 기존 파일 삭제됨$ xz -d 파일이름.xz #압축파일을 일반 파일로 만듬(Decompress)$ xz -l 파일이름.xz #압축파일에 포함된 파일 목록과 압축률 등을 출력$ xz -k 파일이름 #압축 후에 기존 파일을 삭제하지 않고 그대로 둠bzip2/bunzip2 : 압축/압축해제$ bzip2 파일이름$ bunzip2 파일이름.bz2 #bzip2에 -d 옵션을 주는 것과 동일gzip/gunzip$ gzip 파일이름$ gzip -d 파일이름.gz$ gunzip 파일이름.gzzip/unzip$ zip 생성할파일이름.zip 압축할 파일이름$ unzip 압축파일이름.zip파일 묶기tar[동작] c(소) : 새로운 묶음을 만듦 C(대) : 묶음을 풀 때 지정된 디렉터리에 압축을 풀어줌. x : 묶인 파일을 풀어줌 t : 묶음을 풀기 전에 묶인 경로를 보여줌[옵션] f(필수) : 묶음 파일 이름 지정. v : visual의 의미로서 파일이 묶이거나 풀리는 과정을 보여줌 J(대) : tar + xz z(소) : tar + gzip j(소) : tar + bzip2[사용 예]$ tar cvf my.tar /etc/sysconfig/ #묶기$ tar cvfJ my.tar.xz /etc/sysconfig/ #묶기 + xz 압축$ tar cvfz my.tar.gz /etc/sysconfig/ #묶기 + gzip 압축$ tar cvfj may.tar.bz2 /etc/sysconfig/ #묶기 + bzip2 압축$ tar tvf my.tar #파일 확인$ tar xvf my.tar #tar 풀기$ tar cxvf newdir #newdir에 tar 풀기$ tar xfJ my.tar.xz #xz 압축 해제 + tar 풀기$ tar xfz my.tar.gz #gz 압축 해제 + tar 풀기$ tar xfj my.tar.bz2 #bzip2 압축 해제 + tar 풀기4.4.4 파일 위치 검색find[옵션] -name -user(소유자) -newer(전, 후) -perm(허가권) -size(크기)[동작] -print(기본값) -exec(외부 명령 실행)[기본 사용 예]$ find /etc -name \"*.conf\" #etc 디렉터리 하위에 conf 확장자인 파일 검색$ find /home -user centos #home 디렉터리 하위에 소유자가 centos인 파일 검색$ find ~ -perm 644 #현재 사용자의 홈 디렉터리에 허가권이 644인 파일 검색$ find /usr/bin -size +10k - size -100k # /usr/bin 디렉터리 하위에 # 파일 크기가 10KB~100KB인 파일 검색[고급 사용 예]# 현재 사용자의 홈 디렉터리 하위에 크기가 0인 파일의 목록을 상세히 출력$ find ~ -size 0k -exec ls -l { } \\;# /home 디렉터리 하위에 swp 확장자인 파일 삭제$ find /home -name \"*.swp\" -exec rm { } \\;# -exec는 외부 실행 명령의 시작을, \\;는 끝을 의미하며# { }에는 find의 실행 결과가 들어간다.which 실행파일 이름 : PATH에 설정된 디렉터리만 검색. 절대 경로를 포함한 위치 검색.whereis 실행파일 이름 : 실행 파일 및 소스, man 페이지 파일까지 검색.locate 파일이름 : 파일 목록 데이터베이스에서 검색하기 때문에 매우 빠르고 유용하나, updatedb 명령을 1회 실행해야 사용할 수 있다.4.5 네트워크 관련 설정과 명령어nmtui 자동IP 주소 또는 고정 IP 주소 사용 결정 IP 주소, 서브넷 마스크, 게이트웨이 정보 입력 DNS 정보 입력 네트워크 카드 드라이버 설정 네트워크 장치 설정systemctl start/stop/restart/status NetworkManager 네트워크 설정 변경 후 변경된 내용을 시스템에 적용시키는 명령어 nmtui 혹은 네트워크 장치 설정 변경 후에는 restart 필수.(restart = stop + start)ifup/ifdown 장치이름 장치를 작동시키거나 장치를 끄는 명령어ifconfig 장치이름 해당 장치의 IP 주소와 관련 정보를 출력하는 명령어nslookup DNS 서버의 작동을 테스트하는 명령어예시$ nslookup&gt; serverDefault server: 168.126.63.1 #KT DNS Server&gt; www.naver.comServer : 168.126.63.1Address : 168.126.63.1#53Non-authoritative answer:www.naver.com\tcanonical name = www.naver.com.nheos.com.Name:\twww.naver.com.nheos.comAddress: 223.130.200.104Name:\twww.naver.com.nheos.comAddress: 223.130.195.95&gt; exit4.6 파이프, 필터, 리디렉션파이프 : 명령어를 연결시키는 용도로 사용하며, |를 사용한다. 사용 예 $ ls -l /etc | more 필터 : 명령어 실행 결과에서 필요한 것만 걸러준다. grep, tail, wc, sort, awk, sed 등이 있음. 사용 예 $ ps -ef | grep bash #ps -ef의 결과 중 bash 들어간 것 필터링$ rpm -qa | grep dnf 리디렉션 : 표준 입출력의 방향을 바꿔주는 역할. 키보드, 모니터가 아니라 파일을 이용하고 싶을 경우 사용. 사용 예$ ls -l &gt; list.txt #ls -l 의 결과를 list.txt에 덮어쓰기(Override)$ ls -l &gt;&gt; list.txt #ls -l의 결과를 list.txt에 추가(Append)$ sort &lt; list.txt #list.txt 파일을 정렬하여 화면에 출력$ sort &lt; list.txt &gt; out.txt #list.txt 파일을 정렬하여 out.txt에 출력4.7 프로세스, 데몬, 서비스 cf) X 윈도는 firefox 등의 부모 프로세스이며 자식 프로세스는 부모 프로세스 종료시 함께 종료된다.ps : 현재 프로세스의 상태를 확인. 다양한 옵션 있으며 대표적으로 -efkill : 프로세스 강제 종료. -9 옵션 사용시 무조건 종료 포그라운드 프로세스의 경우 Ctrl + c로 종료할 수 있으나, 백그라운드의 경우 kill 명령어 사용 필요.pstree : 부모 프로세스와 자식 프로세스 트리 형태 출력 예제$ yes &gt; /dev/null #무한 루프 포그라운드 프로세스 생성#Ctrl + Z =&gt; 일시정지#[1]+ Stopped yes &gt; /dev/null$ bg #포그라운드 -&gt; 백그라운드 전환#[1]+ yes &gt; /dev/null &amp; $ jobs #백그라운드 프로세스 확인#[1]+ Running yes &gt; /dev/null &amp;$ fg 1 #[1]은 작업번호로, 지정하여 포그라운드로 전환#yes &gt; /dev/null#Ctrl + C # 종료# 백그라운드 프로세스로 실행$ tar xfJ my.tar.xz &amp; # 모든 명령어 뒤에 &amp;가 뒤에 붙으면 백그라운드로 실행4.8 서비스와 소켓서비스는 항상 가동되는 서버 프로세스이며, 소켓은 필요할 때만 작동하는 서버 프로세스이다. 둘 다 systemd라는 서비스 매니저 프로그램으로 관리한다.4.8.1 서비스 서비스 실행 스크립트 파일은 /usr/lib/systemd/system/서비스이름.service 경로 및 파일명을 가지고 있다.systemctl : 서비스 시작/중지/재시작, 상태 확인, 사용/사용 안함 설정 등$ systemctl start/stop/restart 서비스이름 #시작/중지/재시작$ systemctl status 서비스이름 #상태 확인$ systemctl enable/disable 서비스이름 #서비스 사용/사용 안 함 설정4.8.2 소켓서비스는 항상 가동되는 반면, 소켓은 외부에서 특정 서비스를 요청할 경우 systemd가 구동시킴. 요청 끝나면 소켓도 종료.대표적인 소켓의 예로 텔넷 서버가 있음.소켓 관련 스크립트 파일은 /usr/lib/systemd/system/소켓이름.socketREFERENCES이것이 리눅스다 with RedHat CentOS 8" }, { "title": "네트워크 설정", "url": "/posts/%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-%EC%84%A4%EC%A0%95/", "categories": "linux", "tags": "linux", "date": "2023-04-07 00:00:00 +0900", "snippet": "네트워크 설정과 관련된 주요 파일 /etc/sysconfig/network 네트워크의 기본적인 설정 정보 파일 /etc/sysconfig/network-scripts/ifcfg-ens160 ens160 장치에 설정된 네트워크 정보가 담겨있는 파일. /etc/resolv.confDNS 서버의 정보와 호스트 이름이 들어 있는 파일 일반적으로 nmtui 명령어나, ifcfg-ens160파일 수정을 통해 네트워크 설정을 변경하는 경우 systemctl restart NetworkManager 명령어를 통해 변경된 설정을 적용하는 과정이 필요하지만, resolv.conf 파일의 경우 필요 없으며 restart시 오히려 설정이 원복된다. 영구적으로 변경하고 싶다면 nmtui나 ifcfg-ens160 수정을 이용해야 한다. /etc/hosts 현재 컴퓨터의 호스트 이름과 FQDN이 들어있는 파일.### DNS Server list KT : 168.126.63.1, 168.126.63.2 Google : 8.8.8.8### nslookup 명령어를 통해 DNS 서버의 정상 동작 여부 확인하기$ nslookup&gt; server100.100.100.100 #유효하지 않은 DNS Server주소...&gt; www.naver.com;; connection timed out; no servers could be reached #IP 주소 찾지 못함.&gt; server 168.126.63.1 # 다른 DNS Server 주소(KT)로 임시 변경. nslookup 종료시 100.100.100.100으로 원복된다.&gt; www.naver.com... #정상적인 결과 출력 ==&gt; DNS 서버에 문제가 있는 것.## REFERENCES이것이 리눅스다 with RedHat CentOS 8" }, { "title": "GRUB", "url": "/posts/GRUB/", "categories": "linux", "tags": "linux", "date": "2023-04-07 00:00:00 +0900", "snippet": "GRUB 부트로더grub 설정파일 /etc/default/grub.cfg ==&gt; 일반 사용자에겐 읽기 전용이며, root 사용자도 직접 편집해선 안됨. 따라서 /etc/default/grub 파일과 /etc/grub.d/ 디렉터리의 파일을 수정한 후, grub2-mkconfig 명령을 실행해야 한다. GRUB_TIMEOUT=&gt; 부팅시 부트로더(처음 화면) 대기 시간. -1시 자동으로 진행하지 않음. GRUB_DISTRIBUTOR=&gt; 부팅시 엔트리 앞에 붙을 배포판 이름을 추출 GRUB_DEFAULT=&gt; 어떤 엔트리를 기본 값으로 선택할지. saved는 이전에 선택했던 것을, 0은 첫 번째 엔트리를 의미 GRUB_TERMINAL_OUTPUT=&gt; GRUB가 나올 장치 설정. 기본값=console(모니터) GRUB_CMDLINE_LINUX=&gt; 부팅 시 커널에 전달할 파라미터 지정grub2 설정 파일 /boot/grub2/grub.cfg이며, 링크파일로 /etc/grub2.cfg가 있다.REFERENCES이것이 리눅스다 with RedHat CentOS 8" }, { "title": "DNF 작동 방식", "url": "/posts/DNF-%EC%9E%91%EB%8F%99%EB%B0%A9%EC%8B%9D/", "categories": "linux", "tags": "linux", "date": "2023-04-07 00:00:00 +0900", "snippet": "DNF 작동 방식dnf와 관련한 설정 파일은 /etc/yum.conf와 /etc/yum.repos.d/ 디렉터리가 있는데, 중요한 것은 후자로서 인터넷에서 해당 패키지 파일을 검색하는 네트워크 주소가 들어가 있다.작동 순서 dnf install 입력 /etc/yum.repos.d/ 디렉터리의 repo파일을 열어서 URL 주소 확인 전체 패키지 목록 파일 요청 전체 패키지 목록 파일만 다운로드 설치할 패키지와 관련된 패키지의 이름을 화면에 출력 y를 입력하면 설치에 필요한 패키지 파일 요청 설치할 패키지 파일을 다운로드 하여 자동 설치REFERENCES이것이 리눅스다 with RedHat CentOS 8" }, { "title": "cron과 at", "url": "/posts/CRON%EA%B3%BC-AT/", "categories": "linux", "tags": "linux", "date": "2023-04-07 00:00:00 +0900", "snippet": "CRON과 ATCRON시스템 작업을 예약해놓는 것. 관련 데몬은 crond이고, 파일은 /etc/crontab이다.형식 : 분 시 일 월 요일 사용자 실행명령분에는 0~59, 시에는 0~23, 일에는 1~31, 월에는 1~12, 요일에는 0(일)~6(토)사용자는 명령을 실행할 사용자가 올 수 있다.ex)00 05 1 * * root cp -r /home /backup# 매월 1일 5시 0분에 root 사용자의 권한으로 /home 디렉터리를 /backup 디렉터리로 복사한다.crontabcrontab 파일을 통해 주기적으로 실행할 내용을 디렉터리에 넣어놓고 작동하게 할 수 있다./etc/ 디렉터리 안에는 cron.hourly, daily, weekly, monthly가 있음을 확인할 수 있고, crontab 파일에서 run-parts 명령어를 통해 주기적으로 실행시킬 수 있다. run-parts 명령은 지정된 경로에 있는 모든 실행 파일을 실행하는 명령.예제# crontab# Example of job definition:# .---------------- minute (0 - 59)# | .------------- hour (0 - 23)# | | .---------- day of month (1 - 31)# | | | .------- month (1 - 12) OR jan,feb,mar,apr ...# | | | | .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat# | | | | |# * * * * * user-name command to be executed01 3 15 * * root \trun-parts /etc/cron.monthly#!/bin/shset $(date)fname=\"backup-$2$3tar.xz\"tar cfJ /backup/$fname /homeATcron이 주기적으로 반복되는 작업을 예약하는 것이었다면, at은 일회성 명령어를 예약하는 것이다.사용 예$ rdate -s time.bora.net # 원격 호스트 기준으로 date 세팅.$ at 4:00 am tomorrow # at 시작. 내일 오전 4시에 실행$ dnf -y update # 모든 패키지 업데이트$ reboot # 재시작# Ctrl + D # 작업 예약을 완료.$ at -l # 작업 리스트. 맨 앞에 작업 번호를 출력한다.$ atrm 작업번호 # 해당 작업번호의 작업을 삭제한다.$ at -l # 삭제 결과 확인REFERENCES이것이 리눅스다 with RedHat CentOS 8" }, { "title": "링크", "url": "/posts/%EB%A7%81%ED%81%AC/", "categories": "linux", "tags": "linux", "date": "2023-04-06 00:00:00 +0900", "snippet": "하드링크와 심볼릭 링크 하드파일의 링크에는 하드 링크와 심볼릭 링크가 있으며,하드 링크가 가리키는 inode블록은 Data 블록의 원본 파일 데이터를 가리킨다. 이 inode는 원본 파일이 가리키는 곳과 동일함.심볼릭 링크 파일이 가리키는 inode블록은 Data 블록의 원본 파일 포인터를 가리킨다. 이 원본 파일 포인터는 원본 파일의 디렉터리를 가리킨다. inode란?파일이나 디렉터리의 여러 정보(해당 파일의 소유권/허가권, 파일 종류, 파일의 실제 데이터 위치)가 담긴, 리눅스/유닉스 파일 시스템에서 사용하는 자료구조 명령어#하드 링크$ ln 링크대상파일이름 링크파일이름#심볼릭 링크$ ln -s 링크대상파일이름 링크파일이름실습ls -li는 inode의 번호를 맨 앞에 출력하도록 하는 옵션이다.hardlink와 원본 파일은 같은 inode를 가리키는 것을 확인할 수 있고, 심볼릭 링크는 다른 inode 번호를 가지는 것을 확인할 수 있다.원본 파일을 이동시킨 후 softlink와 hardlink를 각각 확인해보면, 구조의 차이에 대해 이해할 수 있다. (softlink는 원본 파일 경로를 가리킴)" }, { "title": "Spring Security(5) - JWT 검증", "url": "/posts/Spring-Security(5)-JWT-%EA%B2%80%EC%A6%9D/", "categories": "Spring", "tags": "oauth2, security, jwt", "date": "2023-02-10 00:00:00 +0900", "snippet": "JWT 검증 이해 선행 지식 JWT 포스트 암호화 " }, { "title": "Spring Security(4) - Spring-Security와 OAuth2.0 사용자 인증", "url": "/posts/Spring-Security(4)-Spring-Security%EC%99%80-OAuth2.0/", "categories": "Spring", "tags": "oauth2, security", "date": "2023-02-10 00:00:00 +0900", "snippet": "Spring Security와 OAUth2.0Spring Security에서는 OAuth2.0을 기반으로 한 사용자 인증과, 클라이언트 인가 과정에 대한 기능을 지원합니다.이 섹션에선 아래 이미지의 1번부터 8번까지의 프로세스를 Client Server와 Authorization Server 내부 동작과정을 중심으로 살펴보고자 합니다.Authorization Code 권한 부여 타입을 중심으로 기술합니다.Client Server의 인가 코드 요청(1 ~ 2)1_ ClientRegistration인가 서버에게 인가 코드를 부여받기 위한 요청을 보내야 하는데, 이 때 필요한 메타데이터를 구성합니다.메타 데이터는 두 가지로 분류할 수 있으며 인가 서버측의 요청 엔드포인트(1), 클라이언트 측에서 인가 서버 측에 등록한 클라이언트 정보(2)입니다. 클라이언트 정보에는 client id, client secret, redirect uri, scope 등이 있습니다.이 메타데이터는 properties 파일에서 정해진 prefix를 따라 기술하거나, 직접 Spring Bean으로 등록된 ClientRegistrationRepository에 추가할 수 있습니다.2_ OAuth2AuthorizationRequestRedirectFilter RequestMatcher Uri : /oauth2/authorization/{registrationId}권한 코드 요청을 위한 데이터가 준비되었으니 인가 서버에게 요청을 보낼 차례입니다. 스프링 시큐리티는 필터 기반 동작 구조를 가진다는 점을 인지하는 것이 좋습니다.스프링 시큐리티에서는 OAuth2.0 인증 프로세스 시작을 위한 단일한 URI 패턴을 제공하기 때문에 인가 서버마다 다른 엔드 포인트를 구체적으로 지정할 필요가 없습니다.이미지의 Resolver에서 OAuth2AuthorizationRequest를 registrationId를 이용하여 구성하고, 이 request 객체는 나중에 참조할 필요가 있기 때문에 최종적으로 redirect 처리 하기 전에 세션에 저장해둡니다.authorization code 요청을 보내면 인가 서버는 내부 프로세스(3~4)를 거쳐 인가 코드를 보내주는데, 파라미터로 보냈던 redirect uri로 사용자를 redirect 시키는 방식으로 진행됩니다.인가 서버의 권한 코드 부여 (3 ~ 6)OAuth2AuthorizationEndpointFilter이전 단계를 거쳐 인가 서버의 Authorization Code Endpoint로 요청이 왔습니다. 클라이언트 서버로 권한 코드를 보내기 전까지의 큰 흐름은 다음과 같습니다.(1) 요청 파라미터로 온 Client ID, Redirect URI 등의 데이터를 인가 서버에 등록되어있는 클라이언트에 대한 데이터와 대조합니다.(2) Resource Owner의 인증, 동의가 없다면 인증, 그리고 지정한 scope에 대한 동의 과정을 진행합니다. Resource Owner에 대한 인증(Form Login 등)이 성공하면, scope에 대한 동의가 필요한 경우 이를 얻습니다.(3) 클라이언트가 Code 요청시 파라미터로 전달했던 scope와 Resource Owner가 동의한 scope를 대조하여, 전자가 후자를 포함하고 있다면 최종적으로 권한 코드를 Client에게 부여합니다. 이때 보내는 권한 코드는 인가 서버측에 저장되며, 이후 토큰 발행 요청시 code 검사에 활용됩니다. 기술한 (1 - 클라이언트 검증), (2 - Resource Owner 인증), (3 - 동의 여부 검사)의 과정은 모두 OAuth2AuthorizationEndpointFilter를 중심으로 진행됩니다. 항상 스프링 시큐리티에서 요청 처리시 반복되는 구조인 Filter(Matcher) ====&gt; Token(Converter) ====&gt; Provider 중심으로 파악하면 이해하기 쉽습니다. 클라이언트 서버의 Access Token 요청( 7 )OAuth2LoginAuthenticationFilter 권한 부여 코드 요청을 보낼 때 세션에 저장해두었던 OAuth2AuthorizationRequest 객체와, 인가 서버로부터 코드를 부여받아 매핑시킨 OAuth2AuthorizationResponse로 인증 객체를 생성합니다.(OAuth2AuthorizationExchange - OAuth2LoginAuthenticationFilter) 이 인증 객체로 OAuth2LoginAuthenticationProvider에서는 Token 엔드포인트로 요청을 보내기 위한 준비를 합니다.즉, code, client id와 secret 등의 파라미터를 포함한 요청객체를 만들고 요청을 보냅니다. 이러한 파라미터들은 클라이언트 자격 증명 유형(grant_type)에 따라 달라집니다. (authorization code, client credentials, refresh token, authorization code pkce)인가 서버의 Access Token 발급( 8 )OAuth2ClientAuthenticationFilter토큰과 관련한 요청에 대해선 당연하지만 클라이언트 인증이 항상 선행됩니다. 토큰 발급, 토큰 유효성 검사, 토큰 해지 모두 이 필터를 거치게 되어 있으며, 인증 성공 후 SecuirtyFilterChain의 그 다음에 위치한 OAuth2TokenEndPointFilter에 의한 토큰 발급 과정이 이루어지게 됩니다.OAuth2TokenEndpointFilterToken 발급을 진행하기 전 인가 서버 측에 저장되어있는 권한 부여 코드와, 요청 파라미터로 넘어온 권한 부여 코드를 비교합니다. 이후 JWT를 발급하는 과정으로 진행됩니다.인가 서버에서는 RSA와 같은 알고리즘으로 generate된 KeyPair(public, private)를 담은 JWKSet을 생성해두어야 하며, public key는 jwkset uri로 제공합니다. 이 jwkset은 발급될 JWT를 검증할 때 사용됩니다.그리고 openid scope가 있는경우 ID Token또한 같이 응답하게 됩니다.권한 부여 코드를 검사하여 JWT 발급으로 진행되는 부분은 파라미터로 넘어오는 grant_type에 따라 대동소이하게 진행됩니다. 종류로는 위에서 대표적으로 설명한 Authorization Code Grant Type, Client Credentials Grant Type, Referesh Token, Authorization Code with PKCE Grant Type이 있습니다.마무리이러한 과정을 통해 클라이언트는 인가 서버로부터 Access Token 혹은 ID Token을 부여받게 됩니다. Access Token을 부여받는 경우, Resource Server로 user info를 요청하는 과정이 추가적으로 진행 되면서 사용자 OAuth 인증이 마무리 되며, ID Token을 부여받는 OIDC 방식의 경우 그 자체로 인증을 처리할 수 있습니다.(다만, scope와 관련하여 userinfo endpoint로 요청을 보내는 경우가 있을 수 있습니다.)Referencehttps://www.inflearn.com/course/정수원-스프링-시큐리티" }, { "title": "JWT", "url": "/posts/JWT/", "categories": "보안", "tags": "jose, jwt", "date": "2023-02-06 00:00:00 +0900", "snippet": "JOSE(Json Object Signing and Encryption)당사자간 클레임의 안전한 전송을 위한 방법을 제공하는 프레임워크. IETF에서 표준화 하였다.JOSE는 이러한 목적을 위해 여러 스펙을 제공함. JWT(Json Web Token)두 당사자 간 안전하게 전달되는 클레임을 표현하기 위한 개방형 표준으로서 추상적인 개념이며, 구현 방식으로 JWS 혹은 JWE가 있다. JWS(Json Web Signature)JWS는 디지털 서명 혹은 MAC(메시지 인증 코드)로 보안된 콘텐츠를 표현하는 방법. JWE(Json Web Encryption)의도한 수신자만 읽을 수 있도록 암호화된 데이터를 나타내는 형식. JWK(Json Web Key)HMAC, ECC, RSA 알고리즘을 사용해 공개 키 세트를 JSON 객체로 나타냄. 일반적으로 개인키 서명 후 공개키로 검증하는데 사용. 인가서버에서는 JWT를 서명하는데 사용했던 public key를 제공하기 위해 JWK 형태로 표현된 key를 접근할 수있는 URL을 제공한다. JWA(Json Web Algorithm)JWS, JWK 및 JWE에 필요한 알고리즘 목록. JWS 헤더 및 JWS 페이로드의 내용을 서명하는데 사용됨. JWT(JWS) 구조 Header : 일반적으로 토큰 유형(JWT)과 서명 알고리즘(HMAC SHA256, RSA)으로 구성됨. Payload : claim을 담고있는 부분. 후술. Signature : Base64urn encoding으로 header와 payload를 인코딩 한 후, 점(.)으로 연결하고 헤더에 정의한 서명 알고리즘을 통해 생성함. ClaimPayload에는 토큰에 담을 정보가 담겨 있으며, 이를 Claim Set이라고 한다. Claim Set은 Key : Value 형태.클레임의 종류1) Registered Claims(등록된 클레임)토큰에 대한 정보를 담기 위해 이름이 이미 정해진 클레임이며, 선택적으로 사용할 수 있다. iss : 토큰 발급자(issuer) sub : 토큰의 제목, 주제(subject) aud : 토큰 수신자(audience) exp : 토큰 만료시간(expiration Time) nbf : 이 시간 이전에는 이 토큰을 처리하지 않아야 함을 의미(not before) iat : 토큰 발급된 시간(issued at) jti : JWT의 고유 식별자. 중복 방지를 위해 사용.2) Public Claims(공개된 클레임)충돌이 방지된 이름을 가지고 있어야 하며, 이를 위해 URI형식으로 명명.{ \"https://example.com/jwt_claims/is_admin\" : true}3) Private Claims(비공개 클레임)당사자간(보통 클라이언트-서버) 협의하에 사용되는 클레임 이름.공개 클레임과는 달리 이름이 중복되어 충돌이 발생할 수 있으므로 사용시 주의.{ \"username\" : \"user\", \"age\" : \"20\"} JWT은 필요한 모든 정보를 자체적으로 지니고 있으며, 전달이 쉽다는 장점이 있다. 인증 및 인가, 데이터의 안정성 있는 교환 등에 유용하게 사용될 수 있다.JWK 관련 님버스(Nimbus JOSE) 제공 객체암호화 키를 저장하는 방식,(JWK - JWKSet)또한 이를 확장하여 암호화 및 전자서명 이후 검증을 위한 키 생성, 변환 등을 지원하기도 한다.(구현체 : RSAKey(비대칭), OctetSequenceKey(대칭), ECKey, OctetKeyPair)++ JWKGeneratorREFERENCEShttps://www.inflearn.com/course/정수원-스프링-시큐리티https://www.letmecompile.com/api-auth-jwt-jwk-explainedhttps://syntaxsugar.tistory.com/entry/JOSEJSON-Object-Signing-and-Encryptionhttps://velopert.com/2389" }, { "title": "암호화", "url": "/posts/%EC%95%94%ED%98%B8%ED%99%94/", "categories": "보안", "tags": "message digest, signature", "date": "2023-02-05 00:00:00 +0900", "snippet": "정보보안의 3대 요소 CIA웹의 경우 사용자의 요청을 처리하는 서버는 HTTP 프로토콜의 특성상 그 요청이 누구의 요청인지 알 수 없다.따라서 사용자를 식별하는 인증과, 권한 제어인 인가처리를 위해서 로그인 + 쿠키를 이용할 수도 있다.하지만 정보 보안에 대한 고려 없이 쿠키에 사용자에 대한 민감한 정보를 담았을 때 제 3자가 이를 탈취하거나, 변조하게 되면 치명적인 이슈가 발생할 수 있다. 기밀성(Confidentiality) : 허가된 자만 해당 정보에 접근할 수 있는 성질. 무결성(Integrity) : 적절한 권한을 가진 사용자가 인가된 방법으로만 정보를 변경할 수 있는 성질 가용성(Availability) : 정보에 대한 접근이 인가된 자는 그 정보를 사용할 수 있는 성질암호화는 정보 보안의 3대 요소 중 기밀성과 무결성을 위한 것이다.암호화암호화는 데이터 보호를 위해 알고리즘으로 평문을 변환하는 과정을 말한다. 암호화의 분류양방향양방향 암호화는 암호화와 복호화가 가능한 알고리즘을 의미한다. 양방향 알고리즘에는 대칭키 알고리즘, 비대칭키 알고리즘이 있다. 대칭키 암호화암호화와 복호화에 같은 키를 사용하는 알고리즘이다. 비대칭키에 비해 계산 속도가 빠르지만, 사용자가 많아지면 관리해야 할 키의 수가 많아진다는 단점이 있다. ex. HMAC : 누구든 무결성 검사가 가능한 해싱을 보완하여, 공유된 개인 키를 가진 자만이 데이터 무결성 검사를 할 수 있는 기법.(데이터 무결성 + 송수신자간 인증) 해시 + 대칭키 알고리즘으로 데이터의 무결성, 기밀성을 확보할 수 있다. 서로 같은 개인 키를 공유해야 하기 때문에 데이터가 송수신되는 경로와 다른 경로로 안전하게 전달되어야 한다. 비대칭키 암호화암호화와 복호화에 다른 키를 사용하는 알고리즘이다. 개인키로 암호화된 데이터는 공개키로 복호화, 공개키로 암호화된 데이터는 개인키로 복호화 하며, 같은 키로는 복호화를 할 수 없다. (1)개인키로 암호화 하는 경우 : 메시지 인증(부인방지)에 중점 (2)공개키로 암호화 하는 경우 : 데이터의 안전한 전송(데이터 보안)에 중점 개인적으로 이유를 추론해 보자면, (1)공개키로 복호화 되는 암호문은 반드시 개인키로 암호화 되어야 하므로 개인키를 소지한 주체가 데이터를 전송하였음이 보장(부인방지)되는 것. (2)공개키로 암호화 한 암호문은 개인키를 소지한 주체만이 복호화 하여 내용을 확인할 수 있기 때문에 데이터를 안전하게 전송할 수 있다. RSA : 공개키 암호화 알고리즘. 소인수분해의 어려움에 기반. SHA-256 + 비대칭키 암호화로 데이터 기밀성 + 무결성을 확보한다. 단방향= Hash암호화된 암호문을 평문으로 되돌릴 수 없는 암호화 방식. 대표적으로 SHA, MD 등이 있다.Referencehttps://velog.io/@dd9s2/보안-암호-알고리즘-Encryption-Algorithms" }, { "title": "HTTP Method, Status Code", "url": "/posts/http/", "categories": "HTTP", "tags": "", "date": "2023-01-25 00:00:00 +0900", "snippet": "HTTP Method GET 특정 리소스의 Representation을 요청하는 메서드 URL 쿼리 스트링으로 데이터를 전달하며, 바디를 사용할 수는 있으나 권장하지 않음. 데이터 조회에만 사용하도록 한다. POST 메시지 바디를 이용해 자원에 대한 데이터 개체를 전달한다. 요청 데이터 처리를 위한 메서드로서, 처리 방식은 리소스마다 적절하게 정하도록 한다. 리소스 등록에만 국한되지 않음. PUT 요청 페이로드로 현재 타겟 리소스의 모든 representaion을 대체한다. 리소스가 존재하는 경우 대체, 존재하지 않는 경우 생성 클라이언트 측에서 리소스를 구체적으로 식별할 수 있다. ex) /order/{id} POST와 달리 PUT은 멱등성을 가진다.(no side effect) PATCH 리소스를 부분적으로 변경한다. DELETE 리소스 제거 HEAD GET 요청과 유사하며, 차이는 body가 없는 응답이 반환된다. CONNECT 목표 자원으로 식별되는 (서버로의)터널을 생성한다. OPTIONS describes the communication options for the target resource. TRACE performs a message loop-back test along the path to the target resource. HTTP Status Code 1xx (정보): 요청을 받았으며 프로세스를 계속한다 2xx (성공): 요청을 성공적으로 받았으며 인식했고 수용하였다 3xx (리다이렉션): 요청 완료를 위해 추가 작업 조치가 필요하다 4xx (클라이언트 오류): 요청의 문법이 잘못되었거나 요청을 처리할 수 없다 5xx (서버 오류): 서버가 명백히 유효한 요청에 대해 충족을 실패했다2xx 200 OK요청이 성공했음을 나타내는 성공 응답 상태코드. 기본적으로 캐시 가능. 201 Created 자원이 생성되었음을 나타내는 요청 성공 응답 상태코드. 응답이 반환되기 이전에 새로운 리소스가 생성되며, 응답 메시지 본문에 새로 만들어진 리소스 혹은 리소스에 대한 링크를 메시지 본문에 넣어 반환 Location 헤더 필드로 식별 url 제공. 202 Accepted요청이 성공적으로 접수되었으나, 아직 해당 요청에 대해 처리 중이거나 처리 시작 전임을 의미 204 No Content요청 성공 but 응답 데이터 없음을 의미 3xx 301 Moved Permanently요청한 리소스가 Location 헤더에 주어진 URL로 완전히 옮겨졌다는 것을 나타냄. 브라우저는 이 페이지로 리다이렉트 함. 리다이렉트 요청은 GET으로 변경되며 본문 변경될 수 있음. 308 Permanent Redirect301과 같으나, 요청 HTTP Method와 요청 body 유지됨. 302 Found요청한 리소스가 Location 헤더에 지정된 URL로 일시적으로 이동되었음을 나타냄.리다이렉트 요청은 GET으로 변경되며 본문 변경될 수 있음. 307 Temporary Redirect요청한 리소스가 Location 헤더에 주어진 URL 로 임시로 옮겨졌다는 것을 나타냄.Method 와 Body 를 변경하지 않고 리다이렉트 요청을 하도록 보장 303 See Other요청한 리소스 자체에 연결되지 않고 다른 페이지로 리다이렉션 됨. 메서드가 GET으로 변경. 활용 예를 들어 상품 주문 POST 요청을 한 경우, 새로고침시 재요청이 가지 않도록 하기 위해해당 리소스에 대한 POST요청에 대해 303 혹은 302 응답. 주문 완료 페이지로 리디렉션. 304 Not Modified요청된 리소스를 재전송할 필요가 없음을 나타낸다. 캐시 목적으로 사용.클라이언트에게 리소스가 수정되지 않았음을 알려줌으로써 클라이언트는 로컬PC에 저장된 캐시를 재사용한다.응답 메시지에 body를 포함하면 안됨.4xx원인이 클라이언트 측인 오류. 복구 가능성 없음. 400 Bad Request잘못된 요청 401 Unauthorized해당 리소스에 대한 인증이 필요WWW-Authenticated 헤더와 함께 전송.(인증 방법에 대한 설명) 403 Forbidden해당 자원에 대한 권한이 없는 요청. 5xx원인이 서버측인 오류. 복구 가능성 있음. 500 Internal Server Error서버 내부 문제 503 Service Unavailable서버가 요청을 처리할 준비가 되지 않은 것을 의미.서버가 점검을 위해 다운되거나 과부하 때문에 발생. retry-after 헤더로 복구 예상 시간 표현 Referenceshttps://ko.wikipedia.org/wiki/HTTP_%EC%83%81%ED%83%9C_%EC%BD%94%EB%93%9Chttps://developer.mozilla.org/en-US/docs/Web/HTTP/Methodshttps://developer.mozilla.org/ko/docs/Web/HTTP/Status" }, { "title": "HTTP Header", "url": "/posts/http-header/", "categories": "HTTP", "tags": "", "date": "2023-01-25 00:00:00 +0900", "snippet": "컨텍스트에 따른 헤더 분류 Message Body Content-Type 리소스의 미디어 타입 ex) text/html, application/json, multipart/form-data Content-Encoding 표현 데이터 압축을 위한 헤더. 전달하는 쪽에선 압축 후 인코딩 헤더 추가, 읽는 쪽에선 헤더로 압축 해제 ex) gzip, deflate, identity(압축 X를 의미) Content-Language 사용자 선호 언어 구분 위한 헤더. ex) ko, en … Content-Length 데이터 길이 협상 (only request) Accept : 서버에게 돌려줄 데이터 타입 명시. Accept-Charset : 클라이언트가 이해할 수 있는 문자 인코딩 Acept-Encoding : 돌려줄 리소스에 사용할 압축 알고리즘에 대해 서버에게 알려줌 Accept-Language : 서버가 돌려줄 언어를 알려줌. ex) Accept-Language: ko-KR, ko;q=0.9,en-US;q=0.8 q는 우선순의 표현. 0부터 1까지의 range. 높을 수록 우선순위 높음. 전송 방식 단순 전송 : Content-Length 압축 전송 : Content-Encoding 분할 전송 : Transfer-Encoding (Content-Length 미포함) 범위 전송 : Request시 Range: bytes=100-200, response시 Content-Range: bytes 100-200 / 1000 요청 컨텍스트 Host : 도메인명 혹은 서버에서 리스닝중인 TCP:PORT. 하나의 IP에 여러 도메인이 있을 경우 특정 도메인 식별 Referer : 이전 웹 페이지 주소. 유입 경로 분석에 사용 User-Agent : 클라이언트 애플리케이션 정보. 브라우저 등. 응답 컨텍스트 Allow : 허용 가능한 HTTP 메서드. 405(Method Not Allowed)에서 응답에 포함해야 한다. Server : 오리진 서버의 소프트웨어 정보 리다이렉트 Location : 페이지를 리다이렉트할 URL. 201 혹은 3xx 응답 헤더. 인증 WWW-Authenticate : 인증 방법에 대한 정의 Authorization : 인증을 위한 자격 증명. ex) Authorization: Berer xxxxx(credentials) 쿠키 Set-Cookie : 서버에서 클라이언트로 쿠키 전달 expires, Max-Age, Domain, Path, Secure, HttpOnly, SameSite 등의 options Cookie : 서버로부터 받은 쿠키를 저장하고, HTTP 요청에 포함하여 서버로 전달. 캐시, 조건부 Cache-Control : 캐싱 메커니즘 위한 옵션 정의 public, private, no-cache, max-age, must-revaidate, no-store 등 no-cache : 데이터 캐시 가능. 변경 여부를 항상 Origin Server에 검증하고 사용. no-store : 민감한 정보가 있으므로 저장하지 말 것. must-revalidate : 캐시 만료 후 최초 조회시 원 서버에 검증 필요. Last-Modified : 리소스의 마지막 수정 날짜로, 동일한 리소스의 여러 버전 비교하는데 사용. 변경되지 않은 경우 304 코드와 헤더만 응답(바디 X). 클라이언트는 저장된 캐시로 데이터 재활용. 변경된 경우 200 코드와 모든 데이터(바디 O) 응답. If-Modified-Since, If-Unmodified-Since ETag : 리소스 버전 식별하는 고유한 문자열. If-Match, If-None-Match Referenceshttps://developer.mozilla.org/ko/docs/Web/HTTP/Headers" }, { "title": "OAuth2.0과 OIDC", "url": "/posts/OAuth2/", "categories": "Security", "tags": "", "date": "2023-01-08 13:07:08 +0900", "snippet": "OAuth2.0과 OIDCOAuth2.0OAuth는 Open + Authorization의 앞 글자를 합성한 단어로서 인가 프레임워크이다. 인증이 아닌 인가라는 점에 주목해야 한다. 언뜻 봐서는 인증 절차에 관한 것 같지만 이에 대해서는 아래에서 설명하도록 하겠다.RFC 6749문서에서 OAuth2.0(애플리케이션이 사용자를 대신해 사용자의 자원에 대한 제한된 액세스를 얻기 위해 authorization server와 상호작용) 표준을 정의하고 있다.RolesOAuth에서는 네 가지 주체를 정의하고 있다. Authorization Server : 사용자의 허가를 받아서 보호된 자원에 대한 접근 권한을 Client에게 넘겨준다. Client와 권한 부여(access token)를 위한 상호작용을 하는 주체이다. Resource Owner : 위에서 말한 허가를 하는 주체이다. 사용자를 대신하여 제한된 자원에 접근하려는 Client는 이 사용자의 허가를 받아야 한다. Client : 사용자를 대신하여 권한을 부여받아 사용자의 리소스에 접근하려는 어플리케이션. Resource Server : 사용자의 자원을 관리하고있는 서버를 말한다. Client가 부여받은 접근 권한을 검증하여 응답한다.Grant TypesClient는 사용자의 승인, 동의 하에 보호받는 자원에 대한 접근을 위해 인가 서버로부터 권한을 부여받는데, OAuth2.0에서는 아래와 같은 권한 부여 유형을 지원한다. 보안에 취약한 Resource Owner Password Credentials Grant Type과 Implicit Grant Type은 생략하도록 하겠다. 간단하게 설명하자면 전자는 사용자의 id, password를 직접 받아 권한을 부여받는 방식이며, 후자는 클라이언트단에서 직접 access token을 요청하는 방식이다.Authorization Code Grant Type가장 많이 쓰이고 안전하기도 한 방식이다. 절차 (front channel)Client는 Resource Owner의 요청에 따라 Authorization Server에게 권한 부여 코드(Authorization Code)를 요청한다. csrf 공격을 방지하기 위해 임의의 문자열(state)을 요청에 포함하기도 한다. (front channel)Authorization Server는 Resource Owner에게 승인(로그인 접속), 동의(email, 이름 등 scope 항목에 대한 동의 체크)를 얻어 redirect uri parameter로 authorization code를 Client에게 전달한다. 이전에 state가 Client로부터 전달되었다면 해당 문자열을 parameter로 함께 보낸다.(매개변수 : response_type=code(필수), client_id(필수), redirect_uri, scope, state) (back channel)Client는 받은 code로 request를 구성하여 Authorization Server에게 접근 권한을 요청한다. state가 같이 왔다면 동일 여부를 검증한다. (매개변수 : grant_type=authorization_code(필수), code(필수), redirect_uri(조건부 필수), client_id(필수), client_secret(필수)) Authorization Server는 받은 파라미터를 통해 검증과정을 거쳐 access token(+ refresh token)을 발급하며, Client는 이 token으로 Resource Server에게 자원을 요청하게 된다. 요청시 파라미터 2번 과정 response_type = code (필수) client_id (필수) redirct_uri scope state 3번 과정 grant_type=authorization_code (필수) code (필수. 2번 과정에서 받은 권한 부여 코드.) redirect_uri (조건부 필수. 2번 요청 파라미터에 포함되었던 경우.) client_id (필수) client_secret (필수. client_id와 secret은 Client의 자격 증명에 활용된다.) Client Credentials Grant권한 코드 타입에선 두 차례의 통신이 수반되었다면, Client Credentials Grant Type은 한 차례만이 수행된다.이 유형은 애플리케이션이 Client임과 동시에 Resource OWner의 역할을 한다. 즉, 자기 자신이 Resource Owner로서 자원에 직접 접근한다.사용자가 곧 클라이언트이기 때문에 절차가 간소화되어 client_id와 client_secret으로 바로 액세스 토큰을 발급받으며, refresh token은 제공되지 않는다. 요청시 파라미터 grant_type=client_credentials (필수) client_id (필수) client_secret (필수) scope Refresh Token Grantaccess token 발급시 함께 발급된다. access token 만료시 이를 이용하여 권한 부여 과정을 반복하지 않고 바로 access token을 발급받는다.한 번 사용된 refresh token은 폐기될 수도, 재사용될 수도 있다. 요청시 파라미터 grant_type=refresh_token (필수) refresh_token (필수) client_id (필수) client_secret (필수) PKCE-enhanced Authorization Code Grant이름에서 알 수 있듯이 권한 코드 타입 확장 버전으로서 PKCE를 이용한다.권한부여코드 요청시 Code Verifier와 Code Challenge를 추가하여 권한부여코드 탈취시 access token을 발급하지 못하도록 할 수 있다. Code Verifier : 권한부여코드 요청 전에 앱이 생성한 48 ~ 128 글자의 ASCII 무작위 문자열 Code Challenge : 선택한 Hash 알고리즘으로 Code Verifier를 해싱 후 Base64 인코딩을 한 값 Code Challenge Method : 암호화 알고리즘 적용에 관한 설정 plain : Code Verifier가 특정한 알고리즘을 사용하지 않도록 설정. 즉 단순히 문자열이 일치하는가만 확인. S256 : ode Verifier가 해시 알고리즘을 사용하도록 설정. 해시 메서드를 통해 검증. 절차 클라이언트는 code_verifier 생성 및 code_challenge_method 사용하여 code_challenge를 계산. 권한부여코드 요청시 code_challenge와 code_challenge_method를 보내고, 인가 서버는 이를 기억해둔다. 클라이언트가 권한부여코드와 함께 토큰을 요청할 때 code_verifier를 함꼐 보낸다. 인가 서버는 이전에 받아 기억해둔 code_challenge, code_challenge_method를 이용해 code_verifier를 검증한다. 위 과정이 권한 코드 타입의 과정에 추가된다. OIDCOAuth2.0을 확장하여 인증 방식을 표준화 한 OAuth2.0 기반의 인증 프로토콜이다. 앞서 OAuth2.0이 인가 전용 프로토콜이라는 점을 언급했는데,OAuth 동작 프로세스를 살펴보면 사용자 인증을 위한 프로세스는 아니며, 사용자가 보유한 자원에 대한 접근 권한만을 얻는 프로세스였다.접근 권한을 얻어 access token으로 사용자의 정보를 얻어온 뒤 이를 이용하여 애플리케이션에서 인증이 이루어지는 것일 뿐이지 access token을 받는 것 만으로는 인증이 이루어졌다고 볼 수 없다.즉, OAuth는 권한을 얻어 자원에 대한 접근을 가능하게 하는 것이 목적인 것이다.반면 OIDC는 인증 전용 프로토콜이다. scope에 openid를 포함하면 인증에 대한 정보가 담겨있는 JWT, 즉 ID Token이 발급된다.ID TokenID Token은 인가서버인 발급자가 개인키로 서명하여 토큰의 출처와 변조되지 않았음을 보장하는 인증 결과물이다.어플리케이션(클라이언트)는 공개 키로 ID Token을 검증 및 유효성을 검사하고 토큰의 클레임 및 만료여부를 확인하며 클레임에 포함되어있는 정보를 토대로 인증 관리를 할 수 있다.OIDC의 경우 인가서버를 OpenId Provider, 클라이언트를 Relying Party로 정의하고있다.OIDC 로그인 요청시에는 scope에 openid를 필수로 포함하여야 하며, OP가 지원하는 경우 response_type 매개변수에 id_token을 포함하도록 한다.또한 요청에는 csrf 공격을 방지하기 위해 OAuth에서의 state 변수와 같은 nonce 매개변수를 포함할 수 있다." }, { "title": "Spring Security(3) - 인증 예외시의 처리 과정", "url": "/posts/Spring-Security(3)/", "categories": "Spring, Security", "tags": "authentication, authorization", "date": "2023-01-08 00:00:00 +0900", "snippet": "Spring Security(3) - 인증 예외시의 처리 과정Spring Security 1편에서 스킵하고 지나간 인증 예외시 처리 과정에 대해 설명하고자 한다.인증 - 인가 프로세스 개관우선 기본적인 인증 - 인가 프로세스 전체에 대해 살펴보고 넘어가겠다.username과 password를 이용하는 기본적인 인증 과정을 기준으로 설명하겠다. DelegatingFilterProxy를 통해 Servlet Filter에서 Spring Bean으로 등록된 Filter에게 요청 처리를 위임한다. 기본적으로 인증과 인가 프로세스는 접근 권한이 요구되는 자원에 접근할 때 진행된다. AuthenticationFilter는 인증 요청을 기반으로 Authentication 객체를 생성하여 AuthenticationManager에게 처리를 위임하고, AuthenticationManager 구현체는 자신이 지닌 AuthenticationProvider 구현체들을 순회하며 support 메서드를 통해 적절한 Provider를 찾은 뒤 인증 처리를 위임한다. AuthenticationProvider 구현체에서는 username과 password를 검증하고, 인증에 성공하면 유저에 관한 정보가 담긴 UserDetails 객체와 권한 정보를 인증 객체에 담아 return한다. 이후 인가 프로세스에서는 FilterSecurityInterceptor에서 AccessDecisionManager에게 인가 처리를 위임하고, AccessDecisionManager는 인증 정보, 요청 정보, 권한 정보를 자신이 지닌 AccessDecisionVoter에게 순회하며 전달한다. AccessDecisionVoter 각 구현체는 자신이 담당하는 인가 처리 기준에 따라 인가 여부를 결정한 뒤 투표 결과를 AccessDecisionManager에게 전달하고 AccessDecisionManager는 이러한 결과들과 인가 결정 전략을 기반으로 인가 여부를 결정한다. 인가처리까지 완료되면 최종적으로 MVC의 Controller로 요청이 전달된다.인증 예외시 처리 프로세스인증 예외가 발생하면 AuthenticationEntryPoint에서 이를 처리한다. 주의해야 할 점이 있다.지금 말하는 인증 예외는 인증이 필요한 자원에 접근한 요청이 인증되지 않은 사용자의 요청일 경우를 말하며, 로그인 과정에서 비밀번호 불일치와 같은 예외의 경우에는 Handler에서 처리.전자의 경우에는 ExceptionTranslationFilter에서 EntryPoint의 commence 메서드를 호출하며, 후자의 경우에는 해당 인증과정을 처리하던 필터에서 failureHandler의 메서드를 호출하는 것에서 확인할 수 있다.인증 방식에 따라 각각 다른 EntryPoint가 지정되는데, ExceptionHandlingConfigurer가 이 설정을 관장한다.ExceptionHandlingConfigurer는 내부에 LinkedHashMap 형태로 entrypoint 객체를 담아둔다. CustomEntryPoint가 있는 경우 Custom한 AuthenticationEntryPoint에 의한 인증 예외 처리가 가장 우선시된다 CustomEntryPoint가 없는 경우 defaultEntryPointMappings라는 LinkedHashMap에 저장되어있는 EntryPoint가 없을 경우 Http403ForbiddenEntryPoint가 처리한다 defaultEntryPointMappings라는 LinkedHashMap에 저장되어있는 EntryPoint가 있는 경우 하나만 있다면 바로 그 EntryPoint 객체가 처리하게 되며, 그게 아닐 경우는 DelegatingAuthenticationEntryPoint에 의해 내부적으로 어떤 인증방식인지 판별한 뒤 적절한 EntryPoint를 ExceptionTranslationFilter에게 넘겨주고 예외 처리가 동작하게 된다. Reference정수원 - 스프링 시큐리티" }, { "title": "Spring Security(2) - SpringBoot 자동 설정에 의한 초기화 과정", "url": "/posts/Spring-Security(2)/", "categories": "Spring, Security", "tags": "authentication, authorization", "date": "2023-01-08 00:00:00 +0900", "snippet": "Spring Security(2) - SpringBoot 자동 설정에 의한 초기화 과정서블릿 기반 어플리케이션에서 Spring Security의 동작과 초기화 과정을 살펴보기 앞서 이해하고 넘어가야 할 부분이 있다.서블릿 컨테이너와 스프링 Bean필터 기반의 Spring Security가 Servlet 기반의 어플리케이션으로서 동작하기 위해선 서블릿 컨테이너에서 스프링 빈으로 등록된 클래스들을 알아야 한다.하지만 서블릿 컨테이너는 스프링이 관리하는 빈을 인식하지 못하는데, DelegatingFilterProxy 를 통해 이러한 문제를 해결하였다.DelegatingFilterProxy는 내부적으로 Spring Container인 WebApplicationContext를 통해 스프링 빈으로 등록된 Filter들에게 요청 처리를 위임하는 역할을 수행한다.구체적으로, DelegatingFilterProxy는 필요한 시점에 WebApplicationContext로부터 springSecurityFilterChain이라는 이름으로 등록된 Bean을 받아오며, 이 Bean은 FilterChainProxy이다.FilterChainProxy는 내부적으로 SecurityFliterChain List를 가지고 있으며, 요청에 따라 적절한 SecurityFilterChain을 선택(by requestMatcher)한다. 그 후 순서에 따라 SecurityFilterChain 필터들의 doFilter 메서드를 호출하는 역할을 수행한다.Springboot와 자동 설정 및 초기화Spring Security 의존성만 추가하고 아무런 설정을 하지 않은 채 DelegatingFilterProxy 내부에 브레이크 포인트를 지정해 디버그를 찍어보면 DefaultSecurityFilterChain이 등록되어있고, 그 내부에는 여러 개의 Spring Bean Filter들이 등록되어 있는 것을 볼 수 있다.스프링은 이렇게 의존성만 추가하더라도 기본적인 Security 설정 및 초기화를 도와주는데, 그 중심에는 SecurityBuilder와 SecurityConfigruer가 있다.Custom 설정이 없다는 가정 하에 진행 과정을 설명하자면,어플리케이션을 구동하게 되면 시큐리티 - MVC Integration 관련 설정과 Csrf설정, 그리고 DelegatingFilterProxy를 등록 하는 등의 초기화 과정이 수행된다. 그 과정에서 HttpSecurityConfiguration이라는 Spring 제공 설정 클래스가 생성되는데, 여기서 기본적인 SecurityFilterChain을 담은 HttpSecurity를 Bean으로 등록한다. 이렇게 기본적인 설정이 된 HttpSecurity으로부터 SecurityFilterChain을 WebSecurityConfiguration에서 List형태로 주입받아 최종적으로 FilterChainProxy에 생성자에게 전달된다.SecurityFilterChain Bean을 등록하는 과정에서 각 Filter들을 생성하고 Configurer의 init, configure 메서드를 호출하며 초기화 작업이 이루어진다.(WebSecurityConfiguration의 springSecurityFilterChain 메서드와 AbstractConfiguredSecurityBuilder의 doBuild 메서드 참고)CustomSecurityConfigurer 등록다음은 Custom한 SecurityConfigurer를 등록하는 간략한 설정이다.@EnableWebSecuritypublic class SecurityConfig { @Bean SecurityFilterChain securityFilterChain(HttpSecurity http) throws Exception { // ... http.apply(new CustomSecurityConfigurer().setFlag(true)); // ... return http.build(); }}public class CustomSecurityConfigurer extends AbstractHttpConfigurer&lt;CustomSecurityConfigurer, HttpSecurity&gt; { private boolean isSecure; @Override public void init(HttpSecurity builder) throws Exception { super.init(builder); System.out.println(\"init method started..\"); } @Override public void configure(HttpSecurity builder) throws Exception { super.configure(builder); System.out.println(\"configure method started..\"); if(isSecure){ System.out.println(\"https is required\"); }else{ System.out.println(\"https is optional\"); } } public CustomSecurityConfigurer setFlag(boolean isSecure){ this.isSecure = isSecure; return this; } public CustomSecurityConfigurer setFlag2(boolean isSecure){ this.isSecure = isSecure; return this; }}간단하게 등록 여부를 확인하기 위한 메시지 출력을 init, configure 오버라이드 메서드에 추가하였다. 이처럼 SecurityConfigurer의 경우 init, configure 메서드를 오버라이드하여 filter 등록 및 초기화를 customize할 수 있다.References정수원 - 스프링 시큐리티공식 레퍼런스" }, { "title": "Spring Security(1) - 인증과 인가", "url": "/posts/Spring-Security(1)/", "categories": "Spring, Security", "tags": "authentication, authorization", "date": "2022-12-30 00:00:00 +0900", "snippet": "Spring Security(1) - 인증과 인가스프링 시큐리티는 인증, 인가를 지원하고 주요 공격으로부터 어플리케이션을 보호해주는 스프링 표준 보안 프레임워크이다.인증(Authentiation)인증은 사용자가 누구인지를 증명하는 것이다. 사용자가 어플리케이션의 특정 리소스에 접근하고자 할 때 그 사용자가 누구인지를 확인할 때 사용한다. 주로 id와 password를 통해 인증을 수행하며, FormLogin 기준으로 작성해보겠다. 우선 Authentication Flow를 살펴보기 전에 일부 관련 객체를 설명하도록 하겠다.Authentication 객체 Authentication : 말 그대로 인증 객체이다. 인증에 필요한 정보를 담고있다. Principal : 사용자를 식별하기 위한 정보이다. 사용자의 Id, 혹은 User 객체를 저장한다. Credentials : 사용자 비밀번호 Authorities : 인증된 사용자의 권한 목록 SecurityContext : 위에서 설명한 인증 객체를 저장하는 보관소이다. 필요 시 인증 객체를 꺼내어 쓸 수 있는 기능을 제공한다. SecurityContextHolder에 Strategy와 함께 저장된다. SecurityContextHolder : SecurityContext + Strategy SecurityContext Strategy : SecurityContext 객체의 저장 방식을 결정한다. 종류 MODE_THREADLOCAL(default) : 스레드당 SecurityContext를 할당한다. 해당 스레드에서만 사용할 수 있다. MODE_INHERITABLETHREADLOCAL : 메인 스레드가 가지는 SecurityContext를 자식 스레드에서도 참조할 수 있도록 한다. MODE_GLOBAL : 어플리케이션 전역에서 단 하나의 SecurityContext를 저장한다. 따라서 모든 쓰레드는 해당 컨텍스트를 참조한다. AuthenticationManager와 AuthenticationProvidersAuthenticationManager 객체는 인증 요청 처리를 위한 인터페이스로서, 대표적이고 가장 많이 사용하는 구현체로 ProviderManager가 있다.ProviderManager는 AuthenticationManager의 authenticate(Authentication aut) 메서드를 구현하고 있는데, 실제 인증 처리 역할을 수행하는 건 아니다. 이 객체는 AuthenticationProvider 리스트를 멤버로 가지고 있으며 AuthenticationProvider를 순회하며 적합한 객체를 찾아 인증 처리를 위임하는 역할만을 수행한다.Authentication Flow(1) 사용자는 로그인을 위해 서버측으로 username과 password를 보낸다. UsernameAuthenticationFilter는 이를 받아 Authentication의 구현체인 UsernamePasswordAuthenticationToken을 생성한다. UsernameAuthenticationFilter는 AbstractAuthenticationFilter를 상속받아 attemptAuthenticate를 구현한 클래스이다. (UsernamePasswordAuthenticationFilter의 attemptAuthentication 메서드 참고)(2) 생성한 객체는 ProviderManager에게 넘기고, ProviderManager는 AuthenticationProvider 구현체들을 순회하며 적합한 Provider에게 인증 처리를 위임한다. (ProviderManager의 authenticate메서드 참고) - AuthenticationProvider 구현체들은 기본적으로 authentication, supports 메서드를 구현하고 있는데, 자신이 해당 인증을 처리하기 적합한 provider인지 그 결과를 ProviderManager에게 전달하여 적합한 Provider에게 위임할 수 있도록 한다.(3), (4) 인증에 성공하면 SecurityContext에 인증 객체를 저장하며, 인증 실패시 인증 예외를 처리하는 방법에 대해서는 다른 게시글에 작성하도록 하겠다. 인증을 유지하기 위해 SecurityContext는 Session에 저장되며, 응답마다 SecurityContext는 clear되며 앞으론 Session에서 SecurityContext를 꺼내어 쓰게 된다. (SecurityContextPersistenceFilter 참고. - create SecurityContext &amp; load SecurityContext from Session)AuthenticationManager(ProviderManager)의 세부 동작 과정이다. UserDetailsService에서는 username으로 사용자의 정보를 담은 객체(UserDetails)를 반환하고, 이를 호출했던 Provider는 UserDetails를 받아 passwordEncoder로 비밀번호를 검증한 뒤 이를 다시 ProviderManager에게 반환한다.1번과 5의 각 Authentication 객체에서 담고 있는 데이터가 다름에 주목한다. 인증 요청이 들어올 때에는 해당 사용자를 검증하기 위한 데이터를 담고 있었다면, 인증이 완료된 후에는 그 외에 권한 정보 등을 담고 있다.(password는 제외) 이제 인증 객체는 context에 저장되어 전역적으로 사용될 수 있다.인가(Authorization)인증을 통해 사용자가 누구인지를 식별하였다면, 그 사용자가 어떠한 자원에 대해 허가를 받았는지를 확인하는 것이다.인가는 세 가지 정보가 필요하다. 1) 누가(인증 정보 - Authentication)1) 어떤 자원을 요청했고((URL방식 기준) 요청 정보 - FilterInvocation)2) 그 자원을 사용하기 위한 조건(권한 정보 - ConfigAttribute)은 무엇인지이 세 정보는 접근 결정 관리자인 AccessDecisionManager 구현체의 decide메서드를 호출하며 전달된다.Authorization Flow를 분석하기 전에 관련 일부 객체를 살펴보겠다.AbstractSecurityInterceptor대표적인 구현체로 FilterSecurityInterceptor, MethodSecurityInterceptor 둘이 있고 각각 Url, Method 방식을 담당한다. 인증된 사용자에 대해 특정 요청의 승인/거부 여부를 최종적으로 결정한다. 상기한 세 정보를 AccessDicisionManager에게 보내는 역할을 한다.SecurityMetadataSource이 인터페이스는 세 추상 메서드를 선언하고 있다. Collection getAttributes(Object object) Collection getAllConfigAttributes() boolean supports(Class&lt;?&gt; clazz)Url방식의 경우 DefaultFilterInvocationSecurityMetadataSource가 이를 구현하고 있는데, 사용자가 접근하고자 하는 Url 자원을 받아서 자신이 DB에서든 받아 가지고 있던 Key(자원) - Value(권한정보)의 map과 비교하여 해당하는 권한정보를 리턴한다.AccessDeicisionManager인증 정보, 요청 정보, 권한 정보를 이용해 사용자의 자원 접근 허용 여부를 결정하는 최종 주체이다.구현체로 AffirmitiveBased, ConsesnsusBased, UnanimousBased가 있는데 각 클래스들은 접근 결정 방식에 따른 것이다.이를 이해하기 위해선 Voter 클래스들에 대한 이해가 선행되어야 한다. 간략하게 설명하자면 각각이 규정한 조건에 따라 인가 여부에 투표하는 객체이다. (AccessDicisionVoter 섹션에서 설명) AffirmitiveBased : 여러 개의 Voter 클래스 중 하나라도 접근 허가를 낸 Voter가 있다면 접근 허가로 판단한다. ConsensusBased : 다수결로 결정하는데 동수일 때에는 기본적으로 접근 허가이고, allowEqualGrantedDeniedDecision으로 변경할 수 있다.(true(default), false) UnianimousBased : 모든 Voter가 만장일치로 접근을 승인해야 하며 그렇지 않은 경우 접근을 거부한다.AccessDecisionVoterAccessDicisionManager의 구현체인 AbstractAccessDecisionManager는 AccessDicisionVoter list를 멤버로 가지고 있다. AuthenticationManager - AuthenticationProivder와 같이 AccessDecisionManager도 이 Voter 구현체들에게 권한 심사를 위임한다.권한 심사를 위임할 때는 필터로부터 전해받은 인증 정보, 요청 정보, 권한 정보를 전달한다.AccessDeicisionVoter의 vote 메서드 리턴 값은 int로서 접근허용(ACCESS_GRANTED : 1), 접근 거부(ACCESS_DENIED : 0), 접근 보류(ACCESS_ABSTAIN : -1)이다. 접근 보류의 경우 해당 Voter로는 요청에 대한 접근 허가를 결정할 수 없는 경우에 사용한다.Authorization Flow(1) SecurityContextHolder에서 Authentication 객체를 찾는다. 인증되지 않은 사용자일 경우 AuhthenticationException이 발생한다.(2) FilterInvocation : request, response 객체가 null이 아니며 HttpServletRequest, HttpServletResponse 객체임을 보장한다. 뿐만 아니라 Security System Class들이 Filter 환경에의 접근을 가능하게 해준다.(3) FilterInvocation을 MetadataSource로 넘겨 ConfigAttribute를 가져오는데, 이는 요청 정보를 이용해 해당 자원 접근에 필요한 권한 정보를 담고 있다.(4 이제까지 얻은 세 정보를 AccessDicisionManager에게 넘긴다.(5, 6) 인가 거절시 AccessDeniedException 발생한다.References스프링 시큐리티 공식 레퍼런스 정수원 - 스프링 시큐리티 - Spring Boot 기반으로 개발하는 Spring Security" }, { "title": "Spring Validation", "url": "/posts/Spring-Validation/", "categories": "Spring", "tags": "validation", "date": "2022-12-01 00:00:00 +0900", "snippet": "SpringBoot validation요청 파라미터 값이 바인딩된 도메인 클래스의 입력값을 검증한다. implementation 'org.springframework.boot:spring-boot-starter-validation'예제 입력값 검증을 할 메서드 파라미터의 도메인 클래스를 정의하고, @Validated 를 붙여준다.(입력값 검증 기능 활성화) 입력값 검증 대상 도메인 클래스 직후에 BindingResult를 정의한다. 이 인자에 검증 오류 관련 데이터가 담김. BindingResult가 제공하는 메서드를 통해 에러 정보 확인. @PostMapping(path=\"\", produces=\"application/json; charset=UTF-8\") public ResponseEntity&lt;String&gt; register(@Validated @RequestBody Board board, BindingResult result){ ResponseEntity&lt;String&gt; entity; if(result.hasErrors()){ List&lt;ObjectError&gt; allErrors = result.getAllErrors(); //객체 레벨의 에러 발생 List&lt;ObjectError&gt; globalErrors = result.getGlobalErrors(); //필드 레벨의 에러 발생 //(hasFieldErrors의 인자로 필드명을 넘겨주면 해당 필드에서 에러 발생시 true 반환) List&lt;FieldError&gt; fieldErrors = result.getFieldErrors(); for( ObjectError oe : allErrors){ log.info(\"all Error : \" + oe); } for( ObjectError oe : globalErrors){ log.info(\"global Error : \" + oe); } for( FieldError fe : fieldErrors){ log.info(\"all Error : \" + fe); log.info(\"field error getDefaultMessage : \" + fe.getDefaultMessage()); } return entity = new ResponseEntity&lt;&gt;(\"FAIELD\", HttpStatus.BAD_REQUEST); } boardService.register(board); entity = new ResponseEntity&lt;&gt;(\"SUCCESS\", HttpStatus.OK); return entity; } @Data public class Board{ private Long boardNo; @NotBlank private String title; private String content; private String writer; private LocalDateTime regDate; private LocalDateTime edtDate; }입력값 검증 규칙 @NotNull : Null이 아니어야 한다. @NotEmpty : Null이 아니며, 하나 이상의 공백 아닌 문자가 있어야 한다. @NotEmpty : collection과 배열, map이 null이 아니며 비어있지 않아야 한다. @Size : 글자 수나 컬렉션의 요소 개수를 검증 @Email : 이메일 주소 형식인지를 검증 @Past : 현재보다 과거인지를 검증(@PastOrPresent) @Future : 현재보다 미래인지를 검증(@FutureOrPresent) @Valid : 멤버 필드로 선언된 다른 객체에 대한 입력값 검증. ex) public class Team{ ... @Valid private List&lt;Member&gt; members; @Valid private Manager manager; } " }, { "title": "Filter와 Spring Interceptor, AOP", "url": "/posts/Spring-Filter,Interceptor,AOP/", "categories": "Spring", "tags": "interceptor", "date": "2022-12-01 00:00:00 +0900", "snippet": "공통 처리를 위해 어떤 것을 사용해야 하나?애플리케이션을 구축할 때 권한 처리, 로깅 등 필요하지만 비즈니스 로직과는 거리가 먼 요소들이 있다.공통적인 것들을 비롯한 이러한 요소들은 비즈니스 로직에서 분리하여 관리할 필요가 있는데, Filter와 Interceptor, AOP를 사용하여 문제를 해결할 수 있다.이 세 기능들의 차이점을 알아보고, 효과적인 방법을 선택하도록 한다.들어가며차이점을 살펴보기 앞서 요청이 처리되는 과정에 대해 살펴볼 필요가 있다.출처:갓대희 님의 [spring]filter vs interceptor vs AOPFilter필터는 doFilter의 메서드 매개변수로 ServletRequest, SevletResponse, FilterChain을 받아 요청과 응답을 재가공하여 FilterChain의 흐름에 싣는 일을 한다.이미지에서 볼 수 있는 것처럼 필터는 스프링 영역 외에 존재한다. 필터를 직접 구현할 때 implements하는 Filter 클래스를 보면 spring이 아닌 javax.servlet이다. (다만 DelegatingFilterProxy를 사용하거나 서블릿 컨테이너까지 관리하는 스프링 부트의 경우에는 스프링 컨테이너의 관리를 받게 되지만.)즉, 필터는 웹 컨테이너에 의해 관리되며, 스프링 컨텍스트 밖에서 동작한다. (추가로 스프링의 최 앞단에는 DispatcherServlet이라는 프론트 컨트롤러가 존재한다.)Interceptor인터셉터는 DispatcherServlet이 컨트롤러를 호출하기 전 요청과 응답을 참조하고 재가공할 수 있는 기능을 제공한다. 즉, 스프링 컨텍스트 내에서 DispatcherServlet과 Controller의 사이에 존재한다.DispatcherSerlvet은 HandlerMapping을 통해 컨트롤러를 찾고 HandlerExecutionChain을 return한다. HandlerExecutionChain은 등록된 인터셉터가 있다면 순차적으로 거친 후 컨트롤러가 실행되도록 한다. 단, 필터와 달리 request, response 객체를 임의로 조작할 순 없다. 그 내부의 값을 참조하고, 변경할 순 있지만.interceptor의 preHandle 메서드의 경우 리턴 타입이 boolean으로서 리턴값에 따라 다음 인터셉터 혹은 컨트롤러의 작업을 지속할지, 중단할지를 결정할 수 있다.postHandle 메서드의 경우 컨트롤러 메서드의 동작 후에 필요한 후처리작업을 정의할 수 있으며 컨트롤러에서 예외 발생시 postHandle은 호출되지 않는다.afterCompletion 메서드의 경우 view 관련 작업 전에 실행되는 postHandle 메서드와 달리 view 관련 작업을 비롯한 모든 작업이 완료된 후 호출되며 예외 발생 여부와 상관 없이 반드시 호출된다. 요청 처리 중 사용한 리소스 반환에 적합하다.AOP객체지향적인 프로그래밍으로는 줄일 수 없는 중복을 줄이기 위해 사용할 수 있다. JoinPoint와 Pointcut(Before, After, Around)를 이용해 메서드를 세밀하게 조정할 수 있다.인자로 ProceedingJoinPoint를 받아 처리하는데, 리플렉션을 통해 공통적인 부분을 조정한다. Request객체를 RequestContextHolder에서 받아 처리할 수 있지만, 성격상 컨트롤러 호출 과정에서 적용해야 하는 부가 기능을 적용하기는 상대적으로 적절하지 않아 보이며 메서드 자체의 기능과 관련된 작업에 사용하기 좋을 것 같다. 어노테이션 @Around, @Before, @AfterReturning, @After ,@AfterThrowing 동작 AfterReturing : 비즈니스 메서드가 성공적으로 결과를 return했을시 동작. After : 성공 실패와 상관 없이 동작. Around : 프록시 객체를 통해 비즈니스 메서드 실행. 다른 것과 달리 ProceedingJoinPoint를 인자로 받음. 실행 순서 : Around -&gt; Before -&gt; AfterReturing -&gt; After -&gt; Around Filter와 Interceptor알아본 바와 같이 필터는 스프링 밖, 인터셉터는 스프링 안에서 동작한다.따라서 필터는 보안 공통 작업(비정상적 요청 차단)등 스프링과 무관하게(스프링과 분리될 필요가 있는)웹 애플리케이션 전역에서 공통적으로 처리해야 할 작업들을 규정하기 적절해 보인다.반면 인터셉터는 스프링 컨텍스트 내에서 요청과 관련한 전역적인 작업들을 처리하기 적절해 보인다.필터의 경우 filterChain.doFilter를 통해 request, response를 임의로 넘겨줄 수 있어 해당 객체들과 관련한 강력한 기능을 가지고 있는 반면,인터셉터의 경우 request, response를 제공받긴 하지만 객체 자체는 변경이 불가능하고 객체 내부의 값만 변경할 수 있다. 따라서 컨트롤러로 넘겨주기 위한 정보를 가공하기에는 용이하다.Reference[Spring] 필터(Filter) vs 인터셉터(Interceptor) 차이 및 용도 - (1)" }, { "title": "계층적인 데이터 구조와 RDB", "url": "/posts/%EA%B3%84%EC%B8%B5%EC%A0%81%EC%9D%B8-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EA%B5%AC%EC%A1%B0%EC%99%80-RDB/", "categories": "DB", "tags": "", "date": "2022-11-22 00:00:00 +0900", "snippet": "" }, { "title": "JPA(13)-QueryDSL", "url": "/posts/JPA(13)-QueryDSL/", "categories": "jpa", "tags": "jpa, hibernate", "date": "2022-11-19 00:00:00 +0900", "snippet": " 세부 내용 누락되어있음.QueryDSL Criteria처럼 JPQL을 편하게 작성하도록 도와주는 빌더클래스 모음. 비표준 오픈소스 프레임워크. 장황하고 복잡한 Criteria에 비해 단순하고 사용하기 쉽다.Settings 필요 라이브러리 querydsl-jpa : QueryDSL JPA 라이브러리 querydsl-apt : 쿼리타입 생성시 필요한 라이브러리 플러그인 설정 &lt;project&gt; &lt;build&gt; &lt;plugins&gt; ... &lt;plugin&gt; &lt;groupId&gt;com.mysema.maven&lt;/groupId&gt; &lt;artifactId&gt;apt-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.1.3&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;process&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;outputDirectory&gt;target/generated-sources/java&lt;/outputDirectory&gt; &lt;processor&gt;com.querydsl.apt.jpa.JPAAnnotationProcessor&lt;/processor&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; ... &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt; 기능들QueryDSL이 제공하는 메서드를 비롯한 기능들 중심으로 정리하도록 한다.main(){ EntityManager em = emf.createEntitymanager(); JPAQuery query = new JPAQuery(em); //m : JPQL의 별칭 QMember qMember = new QMember(\"m\"); List&lt;Member&gt; members = query.from(qMember) .where(qMember.name.contains(\"김\") .and(qMember.name.height.gt(\"180\"))) .list(qMember);} 우선 1) JPAQuery객체와 2) 쿼리객체가 필요함. from(), where()등은 직관적이므로 설명 생략. 결과 조회 uniqueResult() : 하나일 때만 singleResult() : 하나 이상이면 처음 것만 lst() : 하나 이상일 때 페이징 asc()/desc() + offset() + limit() 조합 =&gt; SearchResult 반환하면 활용하여 구현 ex) ```java // 1) QPost qPost = new QPost(“p”); JPAQuery query = new JPAQuery(em); SearchResults result = query.from(qPost) .where(qPost.regDate.gt(anyDate)) .orderBy(qPost.regDate.desc(), qPost.id.asc()) .offset(10).limit(20) .listResults(qPost); // 2) QueryModifiers mod = new QueryModifiers(20L, 10L) //limit, offset SearchResults result = query.from(qPost) .where(...) .restrict(mod) .listResults(qPost); long total = result.getTotal(); long limit = result.getLimit(); long offset = result.getOffset(); List&lt;qPost&gt; results = result.getResults(); ``` 서브쿼리(new JPASubQuery().from()…) QItem item = new QItem(\"i\"); QItem itemSub = new QItem(\"isub\"); JPAQuery query = new JPAQuery(em); query.from(item) .where(item.price.eq( new JPASubQuery().from(itemSub).unique(itemSub.price.max()) )) .list(item); 프로젝션과 결과 반환 프로젝션 대상이 하나일 경우 여러 컬럼 반환과 튜플( Tuple 객체 사용. ) 빈 생성 기능 프로퍼티 접근(Setter) Projections.bean(type, ~.as(“프로퍼티명”) …) 필드 직접 접근(private이어도 동작함) Projections.fields(type, .as(“필드명”)) 생성자 사용 Projections.constructor (생성자 파라미터 순서 동일해야함.) 수정 배치 영속성 컨텍스트를 무시하고 직접 데이터베이스에 쿼리한다 JPAUpdateClause 삭제 배치 영속성 컨텍스트를 무시하고 직접 데이터베이스에 쿼리한다 JPADeleteClause 동적 쿼리 BooleanBuilder 사용 booleanBuilder.and(item.name.contains(param.getName())); 메서드 위임 static 메서드를 만들고 @QueryDelegate(적용할엔티티) static 메서드의 파라미터 : (대상 엔티티의 쿼리타입, 필요한 파라미터 …)" }, { "title": "JPA(12)-JPQL", "url": "/posts/JPA(12)-JPQL/", "categories": "jpa", "tags": "jpa, hibernate", "date": "2022-11-18 00:00:00 +0900", "snippet": "JPQL; Java Persistence Query Language 객체지향 쿼리 언어로서, 테이블을 대상으로 하는 SQL과 달리 엔티티 객체를 대상으로 쿼리한다. SQL을 추상화하여 DBMS에 독립적이며, 작성된 JPQL은 SQL로 변환되어 DBMS에 쿼리된다. JPQL은 영속성 컨텍스트에 있는 데이터를 고려하지 않고 데이터베이스에서 데이터를 조회한다. 따라서 JPQL을 실행하기 전에 flush하여 영속성 컨텍스트의 내용을 데이터베이스와 동기화해야 한다. JPQL은 SQL로 변환되어 데이터베이스에 쿼리되는데, 쿼리 결과로 받아온 엔티티가 영속성 컨텍스트에 이미 있으면 쿼리 결과를 버리고 컨텍스트의 기존 엔티티를 반환한다.기본 문법SQL처럼 SELECT, UPDATE, DELETE문을 사용할 수 있으나, persist 메서드로 커버되지 않는 기능이 없어서인지 INSERT문은 없다.SELECT문 SQL의 문법과 유사하나 1) 클래스명이 아닌 엔티티 명을 사용한다는 점, 2) 엔티티와 속성에 한해선 대소문자를 구분한다는 점, 3) 별칭을 필수적으로 주어야 한다는 점 세 가지 특징이 있다. 쿼리 객체(TypeQuery, Query)String q = \"SELECT m FROM Member m\";//두 번째 파라미터로 반환 타입을 명확하게 지정한 경우 TypeQuery를 반환하고,TypedQuery&lt;Member&gt; tQuery = em.createQuery(q, Member.class);// 지정하지 않아 반환 타입이 명확하지 않을 경우 Query를 반환한다.// 프로젝션을 여러개 지정하면 TypeQuery는 사용할 수 없고 Query를 사용해야 한다.// Query객체의 경우 SELECT절의 조회대상이 하나면 Object를, 둘 이상이면 Object[]를 반환한다.q = \"SELECT m.username, m.age FROM Member m\"; Query query = em.createQuery(q) 파라미터 바인딩JDBC의 경우 위치 기준 파라미터 바인딩만을 지원했다면, JPQL은 이름 기준 파라미터 바인딩도 지원한다. SQL Injection 공격 예방을 위해선 SQL문에 파라미터를 직접 더하는게 아니라 파라미터 바인딩 메서드를 이용하자. 파라미터 바인딩을 이용하면 JPA는 파라미터가 달라져도 같은 쿼리로 인식해 SQL로 파싱한 결과를 재사용할 수 있기 때문에 성능측면에서 효율적이므로 필수적으로 사용하도록 한다. String usernameParam = \"User\";//이름 기준 파라미터 바인딩. 파라미터 앞에 :를 사용한다.em.createQuery(\"SELECT m FROM Member m WHERE m.username = :username\", Member.class); .setParameter(\"username\", usernameParam);//위치 기준 파라미터 바인딩. ?다음 위치값을 주면 된다.em.createQuery(\"SELECT m FROM Member m WHERE m.username = ?1\", Member.class); .setParameter(1, usernameParam); 프로젝션SELECT절에 조회할 대상을 지정하는 것을 프로젝션이라고 하며, 프로젝션의 대상은 엔티티, 임베디드 타입, 스칼라 타입(숫자, 문자 등 기본 데이터 타입)이 있다. 엔티티 프로젝션 String memberq = \"SELECT m FROM Member m\"; String teamq = \"SELECT m.team FROM Member m\"; 임베디드 타입 프로젝션 //임베디드 타입은 값에 불과하기 때문에 당연히 시작점이 될 수 없다. String wrongq = \"SELECT a FROM Addrss a\"; //(X) //엔티티가 시작점이 되어야 한다. String rightq = \"SELECT o.address FROM Order o\"; em.createQuery(rightq, Address.class); 스칼라 타입 프로젝션 Double avg = em.createQuery(\"SELECT AVG(o.orderAmount) FROM Order o\", Double.class) .getSingleResult(); NEW 명령어프로젝션이 여러개일 경우 Object[]가 반환되며 iteration을 통해 각 element를 casting해줘야 한다.또한 타입 지정도 되지 않으니 TypeQuery말고 Query를 사용해야 했다.데이터가 단순하다면 모르겠지만 많아지거나 많은 수의 필드를 가진 객체에 바인딩해야 한다면 이런 작업이 의미가 달라지는데, NEW 명령을 통해 귀찮은 작업을 수행하도록 할 수 있다. //1) 패키지 명을 포함한 전체 클래스 명을 입력해야 하며 //2) 해당 클래스에 순서와 타입이 일치하는 생성자가 있어야 한다. TypedQuery&lt;UserDTO&gt; query = em.createQuery(\"SELECT new com.example.dto.UserDTO(m.username, m.age) FROM Member m\" , UserDTO.class); 페이징 API JPA에서는 DBMS별로 문법도 매우 다르며 까다로운 페이징 처리 API를 지원한다. 단, 페이징 SQL을 최적화하기 위해선 네이티브 SQL을 직접 작성해야한다. TypedQuery&lt;Member&gt; query=em.createQuery(\"SQL...\", Member.class); //조회 시작 위치 query.setFirstResult(10); //한 번 조회당 데이터 수 query.setMaxResults(20); //메서드 두개면 된다. JPQL에서의 조인 (+ 경로표현식) INNER JOIN //JOIN시 연관 필드를 사용해야 한다. //INNER JOIN m.team t(O) //INNER JOIN Team t(x) String query = \"SELECT m FROM Member m INNER JOIN m.team t\" + \"WHERE t.name = :teamName\"; em.createQuery(query, Member.class) .setParameter(\"teamName\", \"Team1\"); OUTER JOINSQL의 OUTER JOIN과 같으며 연관 필드를 사용하면 된다. 컬렉션 조인 String query = \"SELECT t, m FROM Team t LEFT JOIN t.members m\"; JOIN ON ON을 통해 조인 대상을 필터링 한 뒤 조인할 수 있다. (WHERE와 ON의 차이) 페치 조인 연관된 엔티티나 컬렉션을 한 번에 조회하는 기능. JOIN 키워드 뒤에 fetch를 붙이면 된다. String sql = \"SELECT m FROM Member m JOIN FETCH m.team\"; 일반조인의 경우 프로젝션으로 지정한 엔티티만 조회하기 때문에 연관관계까지 고려하고 싶다면 페치조인을 사용하면 된다. 페치조인은 엔티티에서 설정한 fetchtype보다 우선하기 때문에 글로벌 전략으로 매핑 어노테이션의 fetch 속성을 사용하고, 개별적으로 필요한 부분에 대하여 페치 조인을 사용하도록 한다. 경로 표현식 .을 통해 객체 그래프를 탐색하는데, 상태 필드, 연관 필드에 따라 주의해야 할 점이 나뉜다. 상태 필드 : 단순한 값을 저장하기 위한 필드로서, 경로 탐색의 끝 연관 필드 : 연관관계를 위한 필드로서, 임베디드 타입 포함한다. 단일 값 연관 필드(@ManyToOne, OneToOne) : 경로 탐색시 연관관계가 있는 엔티티와 내부 조인(묵시적 조인)이 일어난다. 컬렉션값 연관 필드(@OneToMany, @ManyToMany) : 경로 탐색시 연관관계에 있는 엔티티와 내부 조인 일어난다. 별칭을 지정해줘야 더 탐색이 가능하다. ex) \"SELECT t.members.username FROM Team t\" //실패 \"SELECT m.username FROM Team t JOIN t.members m\" //성공 다형성 쿼리JPQL로 부모 엔티티를 조회하게 되면 그 자식 엔티티도 함께 조회된다. TYPE : 엔티티의 상속 구조에서 조회 대상을 특정 자식 엔티티로 한정할 때 사용한다```java //JPQL “SELECT i from Item i WHERE type(i) IN (Book, Movie)”; //SQL “SELECT i FROM Item i WHERE i.dtype IN (‘B’, ‘M’); - TREAT : 부모 타입 -&gt; 자식 타입 캐스팅 ```java //JPQL \"SELECT i FROM Item i WHERE treat(i as Book).author = 'Kim'\"; //SQL \"SELECT i.* FROM Item i WHERE i.dtype='B' AND i.author = 'Kim'\"; 엔티티 직접 사용 ( 기본 키값, 외래 키값) 객체 인스턴스는 참조 값으로 식별하고, 테이블의 로우는 기본키 값으로 식별하는데, JPA에서는 이 차이를 해결해준다. 즉, 기본키 값을 파라미터로 전달해야할 때 인스턴스 자체를 넘기면 거기서 기본키값을 자동 변환해준다. 외래키의 경우도 해당하는 인스턴스 전달하면 된다. Named 쿼리 @NamedQUery 어노테이션과 name, query 속성을 이용해 자바에서 정의해 놓거나,XML 설정파일에서 정의할 수 있다. UPDATE문, DELETE문 : 벌크 연산 벌크 연산은 영속성 컨텍스트를 무시하고 데이터베이스에 직접 쿼리하기때문에 벌크 연산을 먼저 실행하고 조회하거나 em.refresh()를 사용해 새로 조회하도록 한다. " }, { "title": "JPA(11)-값 타입", "url": "/posts/JPA(11)-%EA%B0%92-%ED%83%80%EC%9E%85/", "categories": "jpa", "tags": "jpa, hibernate", "date": "2022-11-18 00:00:00 +0900", "snippet": "값 타입기본값 타입 java primitive type( ex. int, double ..) wrapper class ( Integer, Long ) String임베디드 타입 JPA에서 사용자가 직접 정의하는 값 타입. 복합 값 타입@Entitypublic class Member{ @Id @GeneratedValue private Long id; private String city; private String street; private String zipcode; @Temporal(TemporalType.DATE) private Date startDate; @Temporal(TemporalType.DATE) private Date endDate;}여기서 데이터 타입을 정의하여 묶으면@Entitypublic class Member{ @Id @GeneratedValue private Long id; @Embedded Period workPeriod; @Embedded Address address;}@Embeddablepublic class Period{ @Temporal(TemporalType.DATE) private Date startDate; @Temporal(TemporalType.DATE) private Date endDate;}@Embeddablepublic class Address{ private String city; private String street; private String zipcode;} 어노테이션 및 특징, 주의사항 어노테이션 @Embedded : 값 타입을 사용하는 곳에 사용 @Embddable : 값 타입을 정의하는 곳에 사용 둘 중 하나는 생략 가능하다 특징 임베디드 타입은 기본 생성자가 필수 기본 값 타입 뿐만 아니라 임베디드 타입과 같은 모든 값 타입은 엔티티의 생명주기에 의존한다. 임베디드타입의 값을 null로 주면 매핑된 컬럼의 값은 모두 null이 된다. 임베디드 타입은 값일 뿐이기 때문에 테이블이 생기는게 아니라 엔티티와 매핑된 테이블 안에 attribute로 포함된다. (값 타입 컬렉션의 경우는 다르다.) 주의사항 임베디드 값 타입을 공유해선 안된다. 기본 자료형과 달리 임베디드 값 타입은 객체 인스턴스이기 때문에 공유하게 되면 컨텍스트에 의해 하나의 인스턴스를 같이 참조하게 된다. 이에 따라 같은 참조변수에 대해 값을 변경하거나 하면 dirty checking에 의해 다른 엔티티에 대해 update sql이 날아간다. 따라서 인스턴스를 clone해서 사용해야 한다.애초에 이런 부작용을 막으려면 setter 메서드를 제거하도록 한다.따라서 객체를 불변객체로서 설계하도록 한다. 즉, 생성자로 초기값을 설정한 뒤 setter를 없애고 getter만 노출시킨다 equals와 hashcode 오버라이드 필수 값 타입은 불변하여 수정이 불가하기 때문에 변경하려면 삭제하고 다시 등록해야 한다. 따라서 비교가 수반되므로 equals와 hashcode를 반드시 구현해야 한다. @Entitypublic class Member{ @Embedded Address address; //임베디드 타입 포함 @Embedded PhoneNumber phoneNumber;//임베디드 타입 포함}@Embeddablepublic class Address{ String street; String city; String state; @Embedded Zipcode zipcode;//임베디드 타입 포함}@Embeddablepublic class Zipcode{ String zip; String plusFour;}@Embeddablepublic class PhoneNumber{ String areaCode; String localNumber; @ManyToOne PhoneServiceProvider provider; //엔티티 참조}@Entitypublic class PhoneServiceProvider{ @Id String name;} @AttributeOverride 매핑정보 재정의 @AttributeOverrides는 엔티티에 설정해야 한다. public class Member{ @Id @GeneratedValue private Long id; @Embedded Address homeAddress; @Embedded Address companyAddress; //컬럼이 중복될 것이다.}//@AttributeOverride 사용public class Memer{ @Id @GeneratedValue private Long id; @Embedded Address homeAddress; @Embedded @AttributeOverrides({ @AttributeOverride( name = \"city\", column = @Column( name = \"company_city\" )), @AttributeOverride( name = \"street\", column = @Column( name = \"company_street\" )), @AttributeOverride( name = \"zipcode\", column = @Column( name = \"company_zipcode\" )) }) Address companyAddress}CREATE TABLE member( company_city VARCHAR(255) , company_street VARCHAR(255) , company_zipcode VARCHAR(255) , city VARCHAR(255) , street VARCHAR(255) , zipcode VARCHAR(255)) 값 타입 컬렉션 값 타입을 하나 이상 저장하려면 컬렉션을 사용한 뒤 @ElementCollection, @CollectionTable 어노테이션을 사용한다. DB 테이블 안에는 컬렉션을 포함시킬 수 없기 때문에 별도의 테이블을 추가하고 @CollectionTable을 통해 매핑해준다. @Entitypublic class Member{ ... //값 타입 컬렉션도 조회시 페치 전략을 정할 수 있다. 기본값은 LAZY. @ElementCollection( fetch=FetchType.LAZY) @CollectionTable( name=\"FAVORITE_FOODS\" , joinColumns = @JoinClumn( name=\"MEMBER_ID\") ) @Column( name=\"FOOD_NAME\" ) private Set&lt;String&gt; favoriteFoods = new HashSet(); @ElementCollection @CollectionTable( name=\"ADDRESS\" , joinColumns = @JoinColumn( name=\"MEMBER_ID\") ) private List&lt;Address&gt; addressHistory = new ArrayList();}@Embeddablepublic class Address{ private String city; private String street; private String zipcode;} 특정 엔티티 하나에 속한 값 타입은 변경되어도 자신이 속한 엔티티를 찾아 값을 변경하면 되지만, 값 타입 컬렉션에 보관된 값 타입들은 별도의 테이블에 보관되기 때문에, 값 타입의 값이 변경되면 원본 데이터를 찾기 어렵다. 따라서 JPA 구현체들은 값 타입 컬렉션에 변경 사항이 발생하면 해당 타입 컬렉션이 매핑된 테이블의 모든 연관된 데이터를 삭제하고 다시 모든 값을 저장한다. 결국 값 타입 컬렉션이 매핑된 테이블에 데이터가 많다면, 값 타입 컬렉션 대신 일대다 관계를 고려해야 할 수도 있다.- 값 타입 컬렉션을 사용하는 대신 새로운 엔티티를 만들어 일대다 관계로 설정하고 영속성 전이(cascade)와 고아 객체 제거(orphan remove) 기능을 추가하면 값 타입 컬렉션처럼 사용할 수 있다. 값 타입과 엔티티의 구별 식별자가 필요하고 지속적으로 값을 추적하고 구분하고 변경해야 한다면 값이 아닌 엔티티이다. 값 타입 컬렉션을 매핑하는 테이블은 모든 컬럼을 묶어서 기본 키를 구성해야 한다.@Entitypublic class Member{ @Id @GeneratedValue private Long id; @Embedded private Address homeAddress; @ElementCollection @CollectionTable( name = \"favorite_foods\" , joinColumns = @JoinColumn ( name = \"member_id\" ) ) @Column( name = \"food_name\" ) //사용되는 컬럼이 하나일 경우 지정 private Set&lt;String&gt; favoriteFoods = new HashSet(); @ElementCollection @CollectionTable( name = \"address\" , joinColumns = @JoinColumn ( name = \"member_id\" )) private List&lt;Addrss&gt; addressHistory = new ArrayList();}@Embeddablepublic class Addrss{ @Column private String city; private String street; private String zipcode;} 값 타입 컬렉션은 cascade + orphan remove 기능을 필수로 가진다. 페치 전략은 lazy가 기본값이다." }, { "title": "JPA(10) - 영속성 전이와 고아 객체", "url": "/posts/JPA(10)-%EC%98%81%EC%86%8D%EC%84%B1-%EC%A0%84%EC%9D%B4%EC%99%80-%EA%B3%A0%EC%95%84-%EA%B0%9D%EC%B2%B4/", "categories": "jpa", "tags": "jpa, hibernate", "date": "2022-11-18 00:00:00 +0900", "snippet": "영속성 전이 엔티티 영속화시 연관된 엔티티도 함께 영속상태로 만드는 기능. by CASCADE. 예를 들어 부모 엔티티를 저장할 때 자식 엔티티도 같이 저장하고 싶다면 영속성 전이를 사용하면 된다. CascadeType ALL : 모두 적용 PERSIST : 영속 MERGE : 병합 REMOVE : 삭제 REFRESH : refresh DETACH : detach cascadeType 없이 영속성 전이를 위해선 각 엔티티에 대해 전부 persist 필요. 하지만 cascadeType persist를 이용하면 엔티티 하나에 대해 한 번만 persist 수행하면 됨. 단, 영속화 과정에서의 편의만 제공해주는 것이고 연관관계 매핑 설정은 필요하다. ex)main(){ //1. 영속성 전이 사용 X //부모 저장 Parent parent = new Parent(); em.persist(parent); //자식 저장 Child child1 = new Child(); child1.setParent(parent); parent.getChildren().add(child1); em.persist(child1); Child child2 = new Child(); child.setParent(parent); parent.getChildren().add(child2); em.persist(child2); //2. 영속성 전이 사용 O //@OneToMany.cascade = CascadeType.PERSIST Parent parent = new Parent(); Child child1 = new Child(); child1.setparent(parent); parent.getChildren().addChild(child1); Child child2 = new Child(); child2.setparent(parent); parent.getChildren().addChild(child2); //한 번에 저장 em.persist(parent); //persist뿐만 아니라 엔티티 삭제의 경우에도 //영속성 전이를 통해 em.remove() 한 번만 호출하면 된다.} persist와 remove는 persist(), remove() 실행만으론 전이가 발생하지 않고 플러시 호출시 전이가 발생한다.고아 객체 부모 엔티티와 연관관계가 끊어진 자식 엔티티를 자동으로 삭제하는 기능도 제공된다.(고아 제거) 따라서 부모 엔티티 컬렉션에서 자식 엔티티에 대한 참조만 제거하면 자식 엔티티가 자동으로 삭제되도록 할 수 있다. @OneToMany( … orphanRemovla = true ) 영속성 컨텍스트를 플러시할 때 적용된다. collection.remove()를 통해 특정 엔티티만 제거하도록 할 수도 있고 collection.cleart()를 통해 모든 자식 엔티티를 제거할 수도 있다. orphanRemoval은 @OneToOne, @OneToMany에만 사용할 수 있다. 참조가 제거된 엔티티는 다른 곳에서 참조하지 않는다고 보고 제거하는 것이기 때문에 특정 엔티티에서만 참조할 때 사용해야 한다. CascadeType.ALL + orpanRemoval = true : 부모 엔티티를 통해 자식 엔티티의 lifecycle을 관리할 수 있다." }, { "title": "JPA(09) - 지연로딩과 프록시", "url": "/posts/JPA(9)-%EC%A7%80%EC%97%B0%EB%A1%9C%EB%94%A9%EA%B3%BC-%ED%94%84%EB%A1%9D%EC%8B%9C/", "categories": "jpa", "tags": "jpa, hibernate", "date": "2022-11-17 00:00:00 +0900", "snippet": "지연 로딩과 프록시 @Entity public class Posts{ @Id @GeneratedValue @Column( name= \"post_id\" ) private Long id; @OneToMany( mappedBy=\"post\" ) private List&lt;Reply&gt; replies; } @Entity public class Reply{ @Id @GeneratedValue @Column( name= \"reply_id\" ) private Long id; @ManyToOne( optional=false ) @JoinColumn( name=\"post_id\", nullable=false ) private Post post; }게시글(Post)와 댓글(Reply) 두 엔티티가 있다.게시글에 대한 데이터와 댓글에 대한 데이터를 함께 필요한 경우도 있겠지만, 그렇지 않고 게시글에 대한 정보만 필요한 경우 그와 연관관계를 맺고 있는 댓글까지 조회하는 것은 비효율적일 것이다.JPA에서는 이러한 문제에 대해 즉시로딩/지연로딩 기능을 제공한다.즉시 로딩 엔티티를 조회할 때 연관된 엔티티까지 함께 조회하는 방식. 연관관계 매핑 어노테이션의 fetch 속성 이용. ex) fetch = FetchType.EAGER 참고사항 즉시로딩의 경우 최적화를 위해 조인 쿼리를 사용한다. 외래 키가 Nullable일 경우 JPA는 값이 없을 경우를 대비해 OUTER JOIN을 수행한다.(INNER JOIN을 하면 다른 데이터 또한 누락될 것이기 때문에 이를 방지하고자.) 성능 및 최적화 측면에서 유리한 INNER JOIN을 수행하게 하려면 외래키에 NOT NULL 제약조건을 걸어주고 JPA에게 이를 알려주면 된다. @JoinColumn(nullable=false)를 하거나, @ManyToOne.optional=false를 주면 된다. 지연 로딩 연관 엔티티는 실제 사용될 때까지 조회를 지연하는 방식. 연관관계 매핑 어노테이션의 fetch 속성 이용. ex) fetch= FetchType.LAZY 연관 엔티티는 사용 시점에 조회하는 것이기 때문에 조회 지연에 필요한 것이 프록시 객체이다. 즉, Reply에 대한 조회를 할 때 Post 연관 필드에는 프록시 객체가 할당된다. 단, 조회 대상이 컨텍스트에서 관리되고 있다면 프록시 객체가 아니라 실제 객체를 사용한다. JPA 기본 페치 전략 @MayToOne, @OneToOne : EAGER @OneToMany, @ManyToMany : Lazy 일대 다 조인을 하면 당연히 성능 저하로 이어질 수 있다. JPA는 일대다 관계를 즉시로딩할 때 항상 외부 조인을 사용하기 때문에, 컬렉션 즉시 로딩도 항상 외부 조인을 사용한다. @ManyToOne, @OneToOne optional = false : 내부조인 optional = true : 외부조인 @OneToMany, @ManyToMany optional = false : 외부 조인 optional = true : 외부 조인 프록시 객체지연로딩시 실제 엔티티 객체 대신 들어가 데이터베이스 조회를 지연할 수 있게 하는 가짜 객체가 필요한데, 이를 프록시 객체라고 한다.JPA는 지연 로딩에 대한 구현을 구현체에게 위임했고, Hibernate는 이에 대해 1) 프록시 객체, 2) 바이트코드 수정 (문서 참고; hibernate Bytecode Enhancement)두 가지 방법을 제공한다. (바이트코드 수정에 대해선 생략.)프록시는 실제 객체를 상속받아 만들어지기 때문에,실제 클래스와 겉 모양이 같으며 사용하는 입장에선 실제 객체인지 프록시 객체인지 구분하지 않고 사용해도 된다.프록시 객체는 실제 객체에 대한 참조를 보관한다. 그리고 프록시 객체의 메서드를 호출하면 프록시 객체는 실제 객체의 메서드를 호출한다. 이처럼 실제로 사용되는 시점에 프록시 객체는 실제 엔티티 객체를 생성하는데, 이를 프록시 객체 초기화라 한다.1) 엔티티 실제 사용 2) 초기화 요청 to 영속성 컨텍스트 3) DB 조회 4) 실제 엔티티 생성 및 참조 보관 프록시 특징 처음 사용할 때 한 번만 초기화 된다. 프록시 객체가 초기화된다고 해서 프록시 객체가 실제 객체가 되는 것은 아니고, 프록시 객체를 통해 실제 엔티티에 접근할 수 있게 된다. 실제 객체를 상속받은 객체이기 때문에 타입 체크시에 주의해서 사용해야 한다. 영속성 컨텍스트에 찾는 실제 객체가 있으면 DB조회의 필요가 없으므로 getReference()를 호출해도 프록시가 아닌 실제 엔티티를 반환한다. 초기화는 영속성 컨텍스트를 통해 이루어지므로 영속상태가 아닌 준영속상태의 프록시를 초기화하면 문제가 발생한다.(LazyinitilaizationException) getReference시 식별자가 전달되고, 프록시는 이 식별자를 보관하고 있다가 실제 엔티티를 조회할 때 사용한다. 이 부분은 확인 필요. 접근 방식에 따른 초기화 차이는 없었음.getId할 경우 엔티티 접근 방식이 PROPERTY 방식인 경우는 프록시를 초기화하지 않고, FIELD 방식인 경우 getId() 메서드가 id만 조회하는지 내부를 알 수 없으므로 프록시 객체를 초기화 한다. 무엇을 사용해야 하는가? 엔티티와 연관 엔티티를 주로 함께 사용한다면 즉시 로딩을, 그게 아니라면 지연 로딩이 유리할 것이다.컬렉션 래퍼 하이버네이트에선 엔티티를 영속화할 때 엔티티에 컬렉션이 있으면 컬렉션을 추적하고 관리할 목적으로 원본 컬렉션을 하이버네이트 내장 컬렉션으로 변경하는데, 이 내장 컬렉션을 컬렉션 래퍼라고 한다. 엔티티의 지연로딩은 프록시 객체가 처리해주는 것처럼, 컬렉션은 컬렉션 레퍼가 프록시처럼 지연 로딩을 처리해준다. post.getReplies()로는 초기화되지 않고, getReplies().get(0)처럼 실제 데이터를 조회할 때 데이터베이스를 조회하여 초기화한다. @Entity public class Posts{ @Id @GeneratedValue @Column( name= \"post_id\" ) private Long id; @OneToMany( mappedBy=\"post\" fetch=FetchType.Lazy ) private List&lt;Reply&gt; replies; } @Entity public class Reply{ @Id @GeneratedValue @Column( name= \"reply_id\" ) private Long id; @ManyToOne( optional=false, fetch=FetchType.EAGER ) @JoinColumn( name=\"post_id\", nullable=false ) private Post post; }" }, { "title": "JPA(08) - 조인 테이블", "url": "/posts/JPA(8)-%EC%A1%B0%EC%9D%B8%ED%85%8C%EC%9D%B4%EB%B8%94/", "categories": "jpa", "tags": "jpa, hibernate", "date": "2022-11-16 00:00:00 +0900", "snippet": " TODO : 조인테이블 + 한 엔티티에 여러 테이블 매핑하기" }, { "title": "JPA(07) - 복합키와 식별관계", "url": "/posts/JPA(7)-%EB%B3%B5%ED%95%A9%ED%82%A4%EC%99%80-%EC%8B%9D%EB%B3%84%EA%B4%80%EA%B3%84/", "categories": "jpa", "tags": "jpa, hibernate", "date": "2022-11-16 00:00:00 +0900", "snippet": " 자바 ORM 표준 JPA 프로그래밍 복합키 : 하나로는 기본키가 될 수 없는 컬럼을 두 개 이상 묶어서 기본키로 사용하는 것. 식별 관계와 비식별 관계 식별 관계 : 부모 테이블의 기본키를 자식 테이블이 자신의 기본키+외래키로 사용하는 관계 비식별 관계 : 부모 테이블의 기본키를 자식 테이블이 외래키로만 사용하는 관계. 필수적 비식별 관계 : 외래키에 NULL 허용X. 연관관계 필수 선택적 비식별 관계 : 외래키에 NULL 허용O. 연관관계 선택적. 복합키 + 비식별 관계 매핑 JPA에서 복합키를 사용하기 위해선 별도의 식별자 클래스가 필요함. persist context에서 엔티티를 관리할 때 엔티티의 식별자로 equals, hashcode를 사용해서 비교하기 때문에 두 개 이상의 식별자는 별도 구현이 필요한 것. JPA는 @IdClass와 @Embedded를 통해 복합키를 지원한다. @IdClass는 RDB스럽고 @Embedded는 객체지향스럽다. @IdClass@Entity@IdClass(ParentId.class)public class Parent{ @Id //복합키에는 @GeneratedValue 사용 불가. @Column ( name = \"parent_id1\" ) //ParentId.id1과 연결 private String id; @Id @Column ( name = \"parent_id2\" ) //ParentId.id2와 연결 private String id2; }public class ParentId implements Serializable{ private String id1; private String id2; public ParentId(){ } public ParentId(String id1, String id2){ this.id1 = id1; this.id2 = id2; } @Override public boolean equals(Object o) { ... } @Override public int hashcode() { ... } }@Entitypublic class Child{ @Id private String id; @ManyToOne @JoinColumns({ @JoinColumn( name = \"parent_id1\", referencedColumnName = \"parent_id1\") , @JoinColumn( name = \"parent_id2\", referencedColumnName = \"parent_id2\" ) }) //joincolumn의 속성 name과 referencedColumnName이 같으면 //referencedColumnName은 생략 가능. private Parent parent;} main(){ Parent parent = new Parent(); parent.setId1(\"1\"); parent.setId2(\"2\"); em.persist(parent); ParentId parentId = new ParentId(\"1\", \"2\"); Parent parent = em.find(Parent.class, parentId) //식별자 클래스를 통해 조회 } 조건 엔티티(Parent)의 식별자 속성명 - 식별자 클래스(ParentId)의 속성명 둘이 같아야함. 그 외에는 식별자 클래스 이용시 조건과 같다. 동작 방식 persist 호출 &gt; 내부에서 ParentId(식별자 클래스) 생성 &gt; Persistence Context 등록@EmbeddedId@Entitypublic class Parent{ @EmbeddedId private ParentId id;}@Embeddablepublic class ParentId implements Serializable{ @Column( name = \"parent_id1\" ) private String id1; @Column( name = \"parent_id2\" ) private String id2; @Override public boolean equals(Object o){ ... } @Overried public int hashcode(){ ... } }main(){ Parent parent = new Parent(); parent.setId(new ParentId(\"1\", \"2\")); em.persist(parent); //조회는 동일. @IdClass방식도 ParentId 직접 이용. } 사용 조건 복합키 컬럼에는 @EmbeddedID, 식별자 클래스에는 @Embeddable 그 외에는 식별자 클래스 이용시 조건과 같다. 동작 @IdClass의 경우 엔티티에 식별자 set 해줬다면 @EmbeddedId는 식별자 클래스 이용. 복합키 + 식별 관계 매핑@IdClass@Entitypublic class Parent{ @Id @Column( name = \"parent_id\" ) private String id;}@Entity@IdClass(ChildId.class)public class Child{ @Id @ManyToOne @JoinColumn( name = \"parent_id\" ) private Parent parent; @Id @Column ( name = \"child_id\" ) private String childId;}public class ChildId implements Serializable{ private String parent; //Child.parent 매핑 private String childId; //Child.childId 매핑 //equals, hashcode 생략}@Entity@IdClass(GrandChild.class)public class GrandChild{ @Id @ManyToOne @JoinColumns({ @JoinColumn( name = \"parent_id\" ), @JoinColumn( name = \"child_id\" ) }) private Child child; @Id @Column( name = \"grandChild_id\" ) private String id;}public class GrandChildId implements Serializable{ private ChildId childId; //GrandChild.child 매핑 private String id; //GrandChild.id 매핑 //equals, hashcode 생략}식별 관계는 기본키와 외래키를 같이 매핑해야 하기 때문에 식별자 매핑인 @Id와 연관관계 및 외래키 매핑 @ManyToOne+@JoinColumn을 같이 사용했다.@EmbeddedId @EmbeddedId로 식별관계 구성시 @MapsId를 사용. 식별관계로 사용할 연관관계의 속성에 @MapsId 사용하면 된다. @IdClass에선 @Id를 사용했다면 여기선 @MapsId 사용. @MapsId 외래 키와 매핑한 연관관계를 기본 키에도 매핑하겠다는 뜻. 속성값으로는 @EmbeddedId를 사용한 식별자 클래스의 기본키 필드를 지정. @Entitypublic class parent{ @Id @Column( name=\"parent_id\" ) private String id;}@Entitypublic class Child{ @EmbeddedId private ChildId id; @MapsId(\"parentId\") //ChildId.parentId 매핑 @ManyToOne @JoinColumn( name = \"parent_id\" ) public Parent parent;}@Embeddablepublic class ChildId implements Serializable{ private String parentId; //@MapsId(\"parentId\")로 매핑 @Column( name=\"child_id\" ) private String id; //equals, hashcode 생략}@Entitypublic class GrandChild{ @EmbeddedId private GrandChildId id; @MapsId( \"childId\" ) @ManyToOne @JoinColumns({ @JoinColumn( name=\"parent_id\" ) , @JoinColumn( name=\"child_id\" ) }) private Child child;}@Embeddablepublic class GrandChildId implements Serializable{ private ChildId childId; //@MapsId(\"childId\")로 매핑 @Column( name=\"grandChild_id\") private String id; //equals, hashcode 생략.}새로운 기본키 + 비식별 관계@Entitypublic class Parent{ @Id @GeneratedValue @Column( name = \"parent_id\" ) private Long id;}@Entitypublic class Child{ @Id @GeneratedValue @Column( name=\"child_id\" ) private Long id; @ManyToOne @JoinColumn( name=\"parent_id\" ) private Parent parent;}@Entitypublic class GrandChild{ @Id @GeneratedValue @Column( name=\"grandchild_id\" ) private Long id; @ManyToOne @JoinColumn( name=\"child_id\" ) private Child child;} 간단하고 깔끔. 복합키보다 쓰기 좋다.일대일 식별 관계@Entitypublic class Board{ @Id @GeneratedValue @Column ( name=\"board_id\" ) private Long id; @OneToOne( mappedBy=\"board\" ) private BoardDetail boardDetail;}@Entitypublic class BoardDetail{ @Id private Long boardId; @MapsId //boardDetail.boardId 매핑 @OneToOne @JoinColumn( name=\"board_id\" ) private Board board;}main(){ Board board = new Board(); board.setTitle(\"제목\"); em.persist(board); BoardDetail detail = new BoardDetail(); detail.setBoard(board); em.persist(detail);}" }, { "title": "JPA(06) - 상속관계", "url": "/posts/JPA(6)-%EC%83%81%EC%86%8D%EA%B4%80%EA%B3%84/", "categories": "jpa", "tags": "jpa, hibernate", "date": "2022-11-16 00:00:00 +0900", "snippet": " 자바 ORM 표준 JPA 프로그래밍RDB에서 상속을 구현하는 방법 상속이라는 개념이 없는 관계형 데이터베이스에서는 대신에 슈퍼타입-서브타입 모델링 기법이 있다. 물리적인 테이블로 구현하는 3가지 방법 1) 각각을 모두 테이블로 만들고 조회할 때 조인을 사용하는 방법 2) 테이블을 하나만 만들어 사용하는 방법 3) 서브타입마다 하나의 테이블을 만들어 사용하는 방법 JPA에서 이 세 가지 방법을 통해 객체의 상속 구조를 데이터베이스의 테이블과 매핑하는데, 1) 조인 전략, 2) 단일 테이블 전략, 3) 구현 클래스마다 테이블 전략 이라고 한다.조인 전략 자식 테이블이 부모 테이블의 기본 키를 받아 조인시 사용한다. 부모테이블의 기본 키를 자신의 기본키 + 외래키로 사용한다. 테이블의 경우 객체와 달리 참조 자료형 개념이 없기 때문에 타입을 구분할 수 있는 컬럼 하나를 추가해준다. 자식 테이블은 부모 테이블의 ID 칼럼명을 그대로 사용하나, @PrimaryKeyJoinColumn( name = “사용할_ID_컬럼명” ) 를 통해 바꿀 수 있음. 장점 테이블이 정규화됨. 외래 키 참조 무결성 제약조건 활용 가능 저장공간 효율적으로 사용 가능 단점 조인 多 -&gt; 성능 저하 조회 쿼리가 복잡 INSERT SQL이 두 번 실행됨.(자식 + 부모) 특징 JPA 표준에서는 구분 컬럼 사용하도록 하지만 hibernate를 비롯한 몇 구현체들은 구분 컬럼 없이도 동작함. 단일 테이블 전략 특징 한 테이블에 모두 담기 때문에 구분 컬럼 필수로 사용해야 함. DiscriminatorValue 생략시 엔티티 이름 사용. 자식 엔티티가 매핑한 컬럼 모두 nullable 이어야 함. 장단점 조인 필요없기 때문에 조회 성능 빠를 수 있으나, 테이블이 커짐에 따라 성능이 오히려 느려질 수도 있음.구현 클래스마다 테이블 전략(추천하지 않는 방법) 자식 엔티티마다 테이블 만듬 장점 서브 타입을 구분해서 처리할 때 효과적 not null 제약조건 사용 가능 단점 여러 자식 테이블을 함께 조회할 떄 성능이 느림.(SQL의 UNION 사용해야) 자식 테이블을 통합해서 쿼리하기 힘듬 특징 구분 컬럼 사용하지 않음. 상속 관계 매핑 예제@Entity//1) JOINED, 2)SINGLE_TABLE, 3)TABLE_PER_CLASS 로,// strategy만 바꿔주면 된다.@Inheritance ( strategy = InheritanceType.JOINED)//DType이 기본값이므로 생략 가능@DiscriminatorColumn( name = \"DType\" )public abstract class Animal{ @Id @GeneratedValue @Column ( name = \"animal_id\" ) private Long id; private String name; private String species;}@Entity@DiscriminatorValue ( \"F\" )//기본값으로 부모 테이블의 ID 컬럼명 사용하는데, 변경하고싶다면@PrimaryKeyJoinColumn( name = \"other_column\" )public class Flying extends Animal{ private boolean hasFeathers; ...}@Entity@DiscriminatorValue ( \"M\" )public class Marine extends Animal{ private boolean isMammalia; ...}@MappedSuperclass 부모 클래스는 데이터베이스의 테이블과 매핑하지 않고 자식 클래스에게 매핑 정보만 제공하고 싶다면 @MappedSuperclass를 사용한다. 자식에게 매핑 정보만 제공하는 것이고 자신은 테이블과 매핑되지 않는다. 테이블과 매핑되지 않기 때문에 컨텍스트의 기능이나 JPQL또한 사용할 수 없다. 직접 사용할 일이 없기 때문에 추상 클래스로 선언한다. @MappedSuperclass public abstract class BaseEntiy{ @Id @GeneratedValue private Long id; private String name; } @Entity //매핑정보 재정의 방법 @AttributeOverrides ({ @AttributeOverride( name = \"id\", column = @Column( name = \"subId1\" ) ), @AttributeOverride( name = \"name\", column = @Column ( name = \"subName1\" )) }) //연관관계 재정의 @AssociationOverride(name = \"부모 필드명\" , joincolumns = @JoinColumn(name = \"재지정할 FK 컬럼명\")) public class SubEntity1 extends BaseEntity { //id와 name은 상속받음 private String data1; } @Entity public class SubEntity2 extends BaseEntity{ //id와 name은 상속받음 private String data2; }" }, { "title": "JPA(05) - 연관관계", "url": "/posts/JPA(5)-%EC%97%B0%EA%B4%80%EA%B4%80%EA%B3%84/", "categories": "jpa", "tags": "jpa, hibernate", "date": "2022-11-16 00:00:00 +0900", "snippet": " 자바 ORM 표준 JPA 프로그래밍연관관계 Concept 방향(Direction) : 단방향, 양방향 단방향, 양방향의 개념은 객체관계에서만 존재하는 것이고, RDB의 테이블 간에는 항상 양방향 관계이다. 다중성(MUltiplicity) : 다대일, 일대다, 일대일, 다대다 연관관계의 주인 : 객체간 양방향 연관관계를 맺기 위해 필요한 작업. 연관관계가 있는 엔티티를 조회하는 방법 두 가지 객체 그래프 탐색(객체 연관관계를 사용한 조회) ex) Member member = em.find(Member.class, \"멤버1\" ) Team team = member.getTeam(); 객체지향 쿼리(JPQL) 사용. ex) String jpql = \"SELECT m FROM member m JOIN m.team t WHERE t.name=:teamname\";List&lt;Member&gt; resultList = em.createQuery(jpql, Member.class) .setParameter(\"teamname\", \"팀1\") .getResultList(); public class Member{ private id; private name; private Team team;}public class Team{ private id; private name; private List&lt;Member&gt; members;}위 예제에서 Member는 Team과 다대일 양방향 연관관계를 맺고 있다고 볼 수 있다.그리고 DB에서는 Member쪽에 Team의 id를 외래 키로 지정하여 연관관계를 맺을 것이다.하지만 테이블의 외래 키를 이용한 연관관계와 객체 내 참조값을 이용한 연관관계는 같다고 볼 수 없다.DB에서는 외래 키 하나만으로 Member JOIN Team, Team JOIN Member가 가능하지만,객체의 경우 Member가 Team을 참조하고 Team이 컬렉션을 통해 Member를 참조하도록 지정해주어야 하기 때문이다.정확히 말하면 Member와 Team은 양방향 관계가 아니라 서로 다른 단방향 연관관계 2개라고 할 수 있다.JPA를 통해 객체 연관관계 방식과 테이블 연관관계 방식의 불일치를 해결 할 수 있다. @Entity public class Member{ @Id @Column( name = \"MEMBER_ID\" ) private Long id; @ManyToOne @JoinColumn( name = \"TEAM_ID\" ) private Team team; } @Entity public class Team{ @Id @Column( name = \"TEAM_ID\" ) private Long id; @OneToMany( mappedBy = \"team\" ) private List&lt;Member&gt; members = new ArrayList&lt;&gt;(); }@JoinColumn을 통해 Team의 id를 외래 키로 매핑한다.그리고 mappedBy를 통해 연관관계의 주인을 Member쪽으로 지정한다.연관관계 주인 외래 키를 통해 양방향 연관관계가 관리되는 것처럼, 객체 양방향 연관관계 또한 외래키 필드 하나로 관리하기 위해 연관관계의 주인을 설정한다. 연관관계의 주인쪽에서만 외래키를 관리(등록, 수정, 삭제)할 수 있고 다른 한 쪽은 읽기만이 가능하다. 연관관계의 주인은 테이블에 외래 키가 있는 곳으로 정해야 한다. 때문에 다대일 관계를 살펴보면 항상 다쪽에서 외래키를 가지므로 ManyToOne은 mappedBy 설정이 불가하다. Convenience Method 연관관계의 주인이 아닌 곳에만 값을 입력하거나, 연관관계의 주인에만 값을 입력해서는 안된다. 연관관계의 주인이 아닌 쪽에서 외래 키는 readonly이므로 별도로 입력하는게 아닌 이상 값이 입력될 수가 없다. 그리고 객체 연관관계 패러다임 상에서는 외래 키를 이용한 메커니즘이 동작하지 않기 때문에 한 쪽에만 값을 넣는다고 해서 다른 쪽에서도 이를 이용해 능동적으로 관리되진 않는다. 따라서 member에 setTeam을 하면서 team에도 member를 넣어주어야 하는데, 이것을 한 쪽에서 관리할 수 있도록 Convenience Method를 구현해주는 것이 좋다.public class Member{ @Id @Column( name = \"member_id\" ) private Long id; @ManyToOne @JoinColumn( name = \"team_id\" ) private Team team; public void setTeam(Team team){ if(this.team != null){ //기존의 연관관계가 있었다면 이를 제거 this.team.getMembers().remove(this); } this.team = team; team.getMembers().add(this); }}public class Team{ @Id @Column( name = \"team_id\" ) private Long id; @OneToMany( mappedBy = \"team\" ) private List&lt;Member&gt; members = new ArrayList();}다양한 연관관계 위의 예제에선 다대 일의 연관관계를 살펴보았다. 다음은 일대일, 다대일, 다대다 연관관계.일대일 연관관계 일대일 관계에서는 어느 쪽에서든 외래 키를 가지고 관리할 수 있다. 주 테이블에 외래 키를 두는 방법, 대상 테이블에 외래 키를 두는 방법 두 가지 중 하나를 택하면 된다. @Entity public class Member{ @Id @GeneratedValue @Column( name = \"member_id\" ) private Long id; @OneToOne @JoinColumn( name = \"locker_id\" ) private Locker locker; } @Entity public class Locker{ @Id @GeneratedValue @Column( name = \"locker_id\" ) private Long id; //양방향으로 하려면 추가 @OneToOne ( mappedBy = \"locker\" ) private Member meber; }일대다 연관관계(단방향)외래키를 가진 테이블이 아닌 다른 테이블에 해당하는 엔티티에서 외래 키를 관리하는 특이한 형태이다. (일대다 양방향의 경우는 존재하지 않음. )```java @Entity public class Team{ @Id @GeneratedValue @Column( name = \"team_id\" ) private Long id; private String name; @OneToMany @JoinColumn( name=\"team_id\" )//이 team_id는 Member의 team_id(fk) private List&lt;Member&gt; members = new ArrayList(); } @Entity public class Member{ @Id @GeneratedValue @Column( name=\"member_id\" ) private Long id; private String name; }``` 이 경우 다른 테이블에 외래키가 존재하다 보니 연관관계를 처리하기 위한 쿼리가 추가적으로 수행되기 때문에 비효율적이라는 단점이 있다.다대다 연관관계단방향 RDB에서 정규화된 테이블 2개로는 다대다 관계를 표현할 수 없기 때문에 다대일, 일대다 관계로 풀어내는 연결 테이블을 사용한다. @ManyToMany를 사용하면 연결 테이블을 자동으로 처리해준다. public class Member{ @Id @GeneratedValue @Column( name = \"member_id\" ) private Long id; @ManyToMany @JoinTable( name = \"member_product\", joinColumns = @JoinColumn( name= \"member_id\" ), inverseJoinColumns = @JoinColumn( name= \"product_id\" ) ) private List&lt;Product&gt; products = new ArrayList(); } public class Product{ @Id @GeneratedValue @Column( name = \"product_id\" ) private Long id; }양방향양방향의 경우 product에 연관관계의 주인이 아님을 명시해주면 된다.convenience method는 생략. public class Product{ @Id @GeneratedValue @Column( name = \"product_id\" ) private Long id; @ManyToMany( mappedBy = \"products\" ) private List&lt;Member&gt; members = new ArrayList(); }그러나 연결 테이블이라도 단순히 아이디 두개만 담는 게 아니라 추가적인 정보가 담길 수도 있다.이러한 경우에는 @ManyToMany는 사용할 수 없고 연결하는 엔티티를 하나 추가하여 일대다, 다대일 관계로 풀어야 한다.복합키 사용 @Entity public class Member{ @Id @GeneratedValue @Column( name = \"member_id\" ) private Long id; @OneToMany ( mappedBy = \"member\" ) private List&lt;MemberProduct&gt; MemberProducts = new ArrayList(); } @Entity public class Product{ @Id @GeneratedValue @Column( name = \"product_id\" ) private Long id; //객체 그래프 탐색 기능이 필요하지 않으면 연관관계를 만들지 않아도 된다. @noeToMany( mappedBy = \"product\" ) private List&lt;MemberProduct&gt; MemberProducts = new ArrayList(); } @Entity @IdClass (MemberProductId.class) public class MemberProduct{ @Id @ManyToOne @JoinColumn( name = \"member_id\" ) private Member member; @Id @ManyToOne @JoinColumn( name = \"product_id\" ) private Product product; private int orderAmoun; ... } public class MemberProductId implements Serializable{ private Long member; private Long product; @Override public boolean equals(Object o){...} @Override public int hashcode(){...} } MemberProduct 엔티티의 기본 키는 member_id와 product_id로 구성된 복합 키이다. 그리고 JPA에서 복합 키를 사용하려면 별도의 식별자 클래스가 필요하기 때문에 MemberProductId를 생성하고 @IdClass를 통해 식별자 클래스임을 명시하였다. 식별자 클래스는 Serializable 구현을 통해 직렬화 가능한 객체로 만들어야 하며, equals, hashcode 메서드를 구현해야 하며 default constructor가 필요하며 class modifier는 public이어야 한다. @EmbeddedId를 이용할 수도 있다. cf) 자신의 부모 테이블(Member, Product)의 기본 키를 받아 자신의 기본 키 + 외래 키로 사용하는 것을 DB에선 식별 관계라고 한다.새로운 기본키 사용(권장) @Entity public class MemberProduct{ @Id @GeneratedValue @Column( name = \"member_product_id\" ) private Long id; //외래 키에서 @Id를 빼고 MemberProduct의 별도 대리키를 구성하도록 한다. @ManyToOne @JoinColumn( name = \"member_id\" ) private Member member; @ManyToOne @JoinColumn( name = \"product_id\" ) private Product product; }" }, { "title": "JPA(04) - 기본 키 매핑", "url": "/posts/JPA(4)-%EA%B8%B0%EB%B3%B8-%ED%82%A4-%EB%A7%A4%ED%95%91/", "categories": "jpa", "tags": "jpa, hibernate", "date": "2022-11-15 00:00:00 +0900", "snippet": " 자바 ORM 표준 JPA 프로그래밍기본 키 매핑JPA가 제공하는 데이터베이스 기본 키 생성 전략 직접 할당 : 기본 키를 애플리케이션에서 직접 할당 자동 생성 : 대리 키 사용 방식(후보 키 중 기본 키가 아닌 것.) IDENTITY : 기본 키 생성을 DB에 위임 SEQUENCE : DB의 시퀀스 사용해 기본 키 할당 TABLE : 키 생성 테이블 사용 hibernate.id.new_generator_mappings=true 설정이 필요하다. 1.  기본 키 직접 할당 전략 @Id 적용 가능한 자바 타입 primitive Wrapper class String java.util.Date java.sql.Date java.math.BigDecimal java.math.BigInteger 2.  기본 키 자동 생성 전략  (1) IDENTITY 전략 기본 키 생성을 DB에 위임. MySQL, PostgreSQL, SQL Sever, DB2 용례 ... @Id @GeneratedValue( strategy = GenerationType.IDENTITY ) private Long id; ... MySQL의 경우 id 컬럼에 auto_increment 적용 되어있어야 한다. 이 전략을 사용하면 JPA는 기본 키 값을 얻어오기 위해 DB를 추가로 조회한다. DB에 INSERT 한 후에 기본 키 값을 조회할 수 있기 때문. hibernate는 JDBC3의 Statement.getGereatedKeys()를 이용하여 저장과 동시에 기본 키 값 얻어옴(?)TODO 엔티티가 영속상태이려면 식별자가 반드시 필요하기 때문에, INSERT가 되어야 식별자를 구할 수 있는 IDENTITY 전략의 경우 SQL 쓰기 지연이 동작하지 않는다. 즉, em.persist()시 곧바로 SQL 날아간다.  (2) SEQUENCE 전략 DB에서 시퀀스는 유일한 값을 순서대로 생성하는 DB Object. Oracle, PostgreSQL, DB2, H2에서 주로 사용 SEQUENCE 전략은 이 시퀀스 이용해 기본 키 생성. 시퀀스 생성 해주어야 하며, ex) CREATE SEQUENCE board_seq START WITH 1 INCREMENT BY 1; @Entity public class Board{ @Id @GeneratedValue(strategy = GenerationType.SEQUENCE, generator = \"board_seq_generator\") @SequenceGenerator( name = \"board_seq_generator\", sequenceName = \"board_seq\", initialValue = 1, allocationSize = 1 ) private Long id; } @SequenceGenerator를 통해 board_seq_generator 시퀀스 생성기 등록 sequenceName인 board_seq는 JPA가 매핑할 데이터베이스의 시퀀스 이름. generator는 방금 생성한 시퀀스 생성기를 지칭함. IDENTITY 전략의 경우 DB에 저장한 후 식별자를 받아오는 방식이었다면, SEQUENCE 전략은 먼저 DB 시퀀스를 사용해 식별자를 조회하고, 조회한 식별자를 엔티티에 할당한 다음 영속성 컨텍스트에 엔티티를 저장한다. 이 후 트랜잭션을 커밋하여 플러시가 일어나면 엔티티가 DB에 저장되는 방식이다.   (3) TABLE 전략 키 생성 전용 테이블을 만들어 이를 활용하는 방식.( @TableGenerator ) CREATE table my_sequences ( sequence_name VARCHAR(255) NOT NULL, next_val BIGINT, PRIMARY KEY ( sequence_ name ) ) @Entity @TableGenerator( name = \"board_seq_generator\", table = \"my_sequences\", pkColumnValue = \"board_seq\", allocationSize = 1 ) public class Board{ @Id @GeneratedValue( strategy = GenerationType.TABLE, generator = \"board_seq_generator\") private Long id; }  (4) AUTO 전략 설정에 기술한 Dialect를 기준으로 자동으로 선택하는 전략.(IDENTITY, SEQUENCE, TABLE) Oracle의 경우 SEQUENCE를, MySQL의 경우 IDENTITY를 선택한다. @GeneratedValue( strategy = GenerationType.AUTO ) 식별자 선택 전략 기본 키는 유일성, 불변성, Not Null 세 가지 조건을 모두 만족해야 함.기본 키를 선택하는 전략은 자연 키(주민번호 등 비즈니스에 의미가 있는 키), 대리 키(시퀀스 등 비즈니스와 관계 없이 임의로 만들어진 키, 대체 키)가 있는데, 대리 키가 권장됨. 주민번호와 같이 비즈니스의 영향을 받는 경우 불변성을 완전히 만족한다고 보장할 수 없음. " }, { "title": "JPA(03) - 매핑 어노테이션", "url": "/posts/JPA(3)-Annotation/", "categories": "jpa", "tags": "jpa, hibernate", "date": "2022-11-15 00:00:00 +0900", "snippet": " 자바 ORM 표준 JPA 프로그래밍매핑 어노테이션 객체(Entity)와 테이블(Table) 매핑 기본 키 매핑 필드 - 컬럼 매핑 연관 관계 매핑@Entity Annotation attribute Description DefaultValue @Entity   엔티티 클래스를 테이블과 매핑하겠다.     name 사용할 엔티티의 이름을 지정 클래스명 Default Constructor 필수. Modifier는 public or protected 필드에 final X@Table Annotation attribute Description DefaultValue @Table   엔티티와 매핑할 테이블 지정     name 매핑할 테이블 명 엔티티명   catalog DB가 catalog 기능 있는 경우 매핑     schema DB가 schema 기능 있는 경우 매핑     uniqueConstraints(DDL) DDL 생성시 유니크 제약조건을 만든다. 2개 이상의 복합 유니크 제약조건도 만들 수 있다. 스키마 자동 생성시에만 사용.   @Id Annotation attribute Description DefaultValue @Id   기본 키(primary key) 매핑   적용 가능한 자바 타입 primitive Wrapper class String java.util.Date java.sql.Date java.math.BigDecimal java.math.BigInteger @Column Annotation attribute Description DefaultValue @Column   컬럼 매핑     name 필드와 매핑할 테이블 컬럼 이름 객체의 필드 이름   insertable SQL INSERT문에 해당 필드를 포함할 것인지 여부 true   updatable SQL UPDATE문에 해당 필드를 포함할 것인지 여부 true   table 한 엔티티를 두 개 이상의 테이블에 매핑할 떄 사용 현재 매핑된 테이블   nullable(DDL) null값의 허용 여부 설정 true   unique(DDL) @Table의 uniqueConstraints와 같음.두 컬럼 이상을 조건을 걸어주려면 uniqueConstraints 사용 false   columnDefinition(DDL) 데이터베이스 컬럼 정보를 직접 줄 수 있음. 필드의 자바 타입과 dialect 이용해 적절한 컬럼 타입 생성   length(DDL) 문자 길이 제약 조건 String 타입. 255   precision, scale(DDL) BigDecimal, BigInteger 타입에서 사용. precision은 소수점 포함 전체 자릿수, scale은 소수의 자릿수. double, float 타입은 적용 X. precision = 19, scale = 2 @Column 생략시 속성들은 대부분 기본값으로 설정되는데, int와 같은 primitive 타입은 null이 없기 때문에 not null로 설정된다. DDL 생성 기능 1)  @Column @Column(name=\"user_name\", nullable = false, length = 10) private String userName;2)  @TABLE @Entity(name=\"MEMBER\") @Table(name=\"MEMBER\", uniqueConstraints = {@UniqueConstraint(name = \"name_age_unique\", columnNames = {\"name\", \"age\"} )}) public class Member{ ... } 이런건 그냥 DDL 작성해도 되지만, 이 기능을 사용함으로써 엔티티만 보고도 테이블 스키마 파악 가능하니 사용하는 것이 좋을 것 같다.DB 스키마 자동 생성 JPA는 매핑 정보와 DB Dialect를 활용해 데이터베이스 스키마 생성함. hibernate.hbm2ddl.auto 속성 설정 필요. 다음은 속성 값 create : DROP + CREATE create-drop : DROP + CREATE + DROP (create 속성에 애플리케이션 종료시 생성한 DDL 제거.) update : 데이터베이스 테이블과 엔티티 매핑 정보 비교하여 변경 사항만 수정. validate : 데이터베이스 테이블과 엔티티 매핑 정보 비교하여 변경 사항 있으면 경고와 함께 애플리케이션 실행 X. DDL 건드리지 않음. none : 자동 생성 기능 사용X.(이 값은 유효하지 않은 값으로, 속성 자체를 설정 파일에서 지우거나 유효하지 않은 값을 넣으면 기능 사용 X.) 다만, 운영 환경에서 사용할 정도로 완성도가 높지 않을 수 있음. hibernate.ejb.naming_strategy = org.hibernate.cfg.ImprovedNamingStrategy 자바는 카멜 케이스, 데이터베이스는 언더스코어 표기법 사용하기 때문에 그 차이를 해결해주는 설정. 설정에 위 속성을 추가하면 테이블 혹은 컬럼 명 생략시 언더스코어 표기법으로 DDL 구성. @ManyToOne Annotation attribute Description DefaultValue @ManyToOne   다대일 관계를 알려주는 매핑 정보     optional false시 연관된 엔티티가 항상 있어야 한다. true시에는 엔티티가 없는 경우도 조회한다(Outer Join) true   fetch 글로벌 페치 전략 설정. @ManyToOne=FetchType.EAGER @OneToMany=FetchType.LAZY   cascade 엔티티의 상태 변화를 전파시키는 옵션     targetEntity 연관된 엔티티의 타입 정보를 설정   @OneToMany Annotation attribute Description DefaultValue @OneToMany   일대다 관계를 알려주는 매핑 정보     fetch 글로벌 페치 전략 설정. @ManyToOne=FetchType.EAGER @OneToMany=FetchType.LAZY   mappedBy 연관관계의 주인 필드 지정     cascade 엔티티의 상태 변화를 전파시키는 옵션     targetEntity 연관된 엔티티의 타입 정보를 설정   targetEntity 제네릭으로 타입 정보를 알 수 있기 때문에 사용하지 않아도 됨. ex) @OneToManyprivate List&lt;Memeber&gt; members@OneToMany(targetEntity = Member.class)private List Members; @JoinColumn Annotation attribute Description DefaultValue @JoinColumn   외래 키를 매핑할 때 사용. 생략 가능.     name 외래 키 컬럼명 필드명 + “_” 참조하는 테이블의 기본 키 컬럼 명   referencedColumnName 외래 키가 참조하는 대상 테이블에서의 컬럼명 참조하는 테이블의 기본 키 컬럼명   foreignKey(DDL) 외래 키 제약조건을 직접 지정할 수 있음.     uniquenullableinsertableupdatablecolumnDefinitiontable @Column의 속성과 같음   생략하게 되면 외래 키를 찾을 때 기본 전략 사용. 기본 전략 : 필드명+_+참조하는 테이블의 컬럼명 name과 referencedColumnName의 차이를 설명한 글 : name vs referencedColumnName@SequenceGenerator Annotation attribute Description DefaultValue @SequenceGenerator   시퀀스 생성기 등록     name 식별자 생성기 이름. 필수   sequenceName 데이터베이스에 등록되어있는 시퀀스의 이름.     initialValue 시퀀스 DDL 생성시 처음 시작하는 수 지정.DDL 생성시에만 사용됨. 1   allocationSize 시퀀스 한 번 호출에 증가하는 수 50   catalog, schema 데이터베이스 catalog, schema 이름   allocationSize 기본값이 50인 이유 50씩 증가하면 여러 JVM이 동작하더라도 기본 키 값이 충돌하지 않게 하려고 + 시퀀스 접근 횟수 줄이기 위해(메모리에서 식별자 할당) @TableGenerator Annotation attribute Description DefaultValue @TableGenerator         name 식별자 생성기 이름. @GeneratedValue와 매핑시 사용 (필수)   table DB에 생성한 식별자 테이블 명 hibernate_sequences   pkColumnName table primary key 컬럼명 sequence_name   valueColumnName 마지막 generate값을 갖고있는 컬럼명 next_val   pkColumnValue Key로 사용할 이름 엔티티명   initialValue 초기 값. 0   catalog, schema 데이터베이스 catalog, schema 이름     uniqueConstraints(DDL) 유니크 제약 조건 지정.   @Enumerated Annotation attribute Description DefaultValue @Enumerated   자바 enum 매핑     value - EnumType.ORDINAL : enum의 순서를 저장 - EnumType.STRING : enum의 이름을 저장 ORDINAL EnumType.ORDINAL : enum 순서를 DB에 저장. ex)1, 2, 3…. EnumType.STRING : enum 이름을 DB에 저장. ex)USER, ADMIN @Temporal Annotation attribute Description DefaultValue @Temporal   자바 날짜 타입 매핑(Date, Calendar)     value - TemporalType.DATE : 날짜, DB의 date 타입과 매핑 - TemporalType.TIME : 시간, DB의 time 타입과 매핑 - TemporalType.TIMESTAMP : 날짜와 시간, DB의 timestamp 타입과 매핑 TemporalType은 필수로 지정해야 함. @Temporal 생략시 dialect에 따라 MySQL은 datetime, H2, 오라클, PostegreSQL은 timestamp 타입으로 DDL 생성한다.@Lob Annotation attribute Description DefaultValue @Lob   DB의 BLOB, CLOB 타입과 매핑   속성 없음. 필드 타입이 문자면 CLOB, 나머지는 BLOB@Trnasient Annotation attribute Description DefaultValue @Transient   해당 필드는 DB 테이블의 컬럼과 매핑하지 않겠다는 의미.   @Access Annotation attribute Description DefaultValue @Access   JPA가 엔티티 데이터에 접근하는 방식을 지정.   필드 접근 : AccessType.FIELD 필드에 직접 접근 modifier가 private이어도 상관 없이 접근할 수 있다. 프로퍼티 접근 : AccessType.PROPERTY 접근자(Getter) 사용. @Access 생략시 @Id의 위치를 기준으로 접근 방식을 결정한다 필드 위에 있으면 필드 접근, Getter 위에 있으면 프로퍼티 접근방법을 사용. " }, { "title": "JPA(02) - 영속성 컨텍스트와 엔티티 라이프사이클", "url": "/posts/JPA(2)-%EC%98%81%EC%86%8D%EC%84%B1-%EC%BB%A8%ED%85%8D%EC%8A%A4%ED%8A%B8%EC%99%80-%EC%97%94%ED%8B%B0%ED%8B%B0-%EB%9D%BC%EC%9D%B4%ED%94%84%EC%82%AC%EC%9D%B4%ED%81%B4/", "categories": "jpa", "tags": "jpa, hibernate", "date": "2022-11-14 00:00:00 +0900", "snippet": " 자바 ORM 표준 JPA 프로그래밍영속성 컨텍스트 엔티티 인스턴스들과 라이프 사이클이 관리되는 환경. 엔티티들은 unique한 식별자 값으로 구분되며, 컨텍스는 이 식별자를 이용해 엔티티를 관리하기 떄문에 필수로 있어야 한다. 이 식별자는 Key-Value 형식으로 구성되며 데이터베이스의 primary key와 매핑되어있다. 1차 캐시 : 영속성 컨텍스트는 내부에 1차 캐시(first-level cache)를 가지고 있으며, DB에 저장되거나 DB로부터 받아온 모든 entity들이 이곳에 담긴다. 어떤 엔티티를 조회할 경우 우선 1차 캐시에서 찾고, 없다면 DB로부터 fetch한다. 캐시를 이용한다는 점에서 성능상 이점이 있으며, 인스턴스의 동일성을 보장한다. 쓰기 지연 : persist()시 key(@id)-value(instance)를 1차 캐시에 저장하며, 곧바로 Query가 날아가는게 아니라 INSERT SQL을 쓰기 지연 SQL 저장소에 차곡차곡 모아둔다.(transactional write-behind). 트랜잭션 커밋시 entityManager가 변경 사항(등록, 수정, 삭제)을 DB에 동기화 시킨다.(flush). 그 후 DB의 트랜잭션이 커밋된다. 변경 감지(dirty checking) : 영속성 컨텍스트에는 엔티티의 최초 상태가 저장(스냅샷)되는데, 1) flush 시점에 엔티티와 스냅샷을 비교해 변경된 엔티티를 찾고 2) 변경된 엔티티가 있다면 수정 쿼리를 그때 생성하여 쓰기 지연 SQL 저장소에 보내고, 3) 쓰기 지연 SQL 저장소의 SQL이 DB에 반영된 후 DB 트랜잭션이 커밋된다. 일부 필드만 바뀌어도 전체 필드에 대한 update가 이루어지는 방식이기 때문에 Application 로드시 수정 쿼리를 미리 만들어 재사용한다. @Org.hibernate.annotations.DynamicUpdate를 통해 일부만 업데이트 하는 쿼리를 생성하도록 할 수 있다. cf) @DynamicInsert 변경 감지를 위해선 엔티티가 영속 상태여야 한다. flush 영속성 컨텍스트의 변경 내용을 DB에 반영. 플러시 한다고 영속성 컨텍스트에 보관된 엔티티가 지워지는 건 아니다. DB와 동기화 되는 개념. 지연된 쿼리가 가능한 건 작업 단위인 트랜잭션의 특징 때문.(변경 내용은 커밋 직전에만 동기화 하면 됨.) 플러시 방법 em.flush() 직접 호출 테스트시 사용 트랜잭션 커밋시 플러시 자동 호출 JPQL 쿼리 실행시 플러시 자동 호출 ex) em.persist(member1); em.persist(member2); //JPQL 실행 시점에 플러시 자동 호출. member1, member2도 쿼리의 결과에 포함된다. //식별자를 기준으로 조회하는 find() 메서드 호출시에는 플러시X em.createQuery(\"select m from Member m\", Member.class).getResultList(); 플러시 모드 옵션 javax.persistence.FlushModeType 이용 FlushModeType.AUTO : 커밋이나 쿼리를 실행할 때.(default) FlushModeType.COMMIT : 커밋할 때만 성능 최적화를 위해 사용할 수도 있음. 엔티티 라이프 사이클 엔티티의 상태 4가지 비영속(new/transient) : 영속성 컨텍스트와 전혀 관계가 없는 상태 저장하지 않은 순수한 객체 상태. 영속(managed) ; 영속성 컨텍스트에 저장된 상태 영속성 컨텍스트에 의해 관리되는 상태. ex) em.persist() 후 준영속(detached) : 영속성 컨텍스트에 저장되었다가 분리된 상태 em.detach() 혹은 em.close()를 통해 영속성 컨텍스트를 닫거나, em.clear()로 영속성 컨텍스트 초기화. 삭제(removed) : 삭제된 상태 em.remove(객체) 준영속 영속성 컨텍스트가 관리하는 영속 상태의 엔티티가 컨텍스트에서 분리된 것. 분리되었기 때문에 컨텍스트가 제공하는 기능은 당연히 사용할 수 없다. (변경 감지 X…) how? (1) em.detach(entity) : 특정 엔티티만 준영속 상태로 전환 엔티티를 관리하기 위한 모든 정보가 제거됨. ex) detache(memberA) -&gt; memberA의 1차 캐시 제거 + 관련 SQL 제거 (2) em.clear() : 영속성 컨텍스트 초기화 해당 컨텍스트의 모든 엔티티를 준영속 상태로 만듬. 1차 캐시나 쓰기 지연 SQL 저장소는 남음. (3) em.close() : 영속성 컨텍스트 종료 em.clear에서 1차 캐시, 쓰기 지연 SQL 저장소까지 삭제 비영속과 차이점? 컨텍스트 제공 기능 사용 불가 등 거의 유사하나, 영속 상태였었으므로 반드시 식별자는 가짐. 지연 로딩 X. (지연 로딩은 실제 객체 대신 프록시 객체를 로딩하고 실제로 사용할 때 영속성 컨텍스트를 통해 데이터 불러오는 방법.) 다시 영속 상태로 하려면? 병합 : merge() 사용 ex) Member mergeMember = em.merge(member); 준영속 -&gt; 영속의 경우 프로세스 설명 (1) merge() 실행 (2) merge(member)의 파라미터인 준영속상태 엔티티의 식별자 값으로 1차 캐시에서 엔티티 찾음. (2-1) 1차 캐시에 없다면 DB에서 조회하고 캐시에 저장 (3) 조회한 영속 엔티티(mergeMember)에 member 엔티티의 모든 값을 밀어넣는다. member 엔티티는 merge 하더라도 계속 준영속 상태임. 새로운 Member 인스턴스인 mergeMember를 리턴하는 것. (4) 영속 엔티티(mergeMember) 반환한다. 비영속 -&gt; 영속의 경우 merge는 준영속, 비영속을 가리지 않고 동작하는데, 파라미터로 넘어온 엔티티의 식별자 값으로 1차 캐시에서 조회하고 없으면 DB, DB에도 없으면 새로운 엔티티를 생성해서 병합한다.(save or update 기능) " }, { "title": "JPA(01) - Intro", "url": "/posts/JPA(1)-intro/", "categories": "jpa", "tags": "jpa, hibernate", "date": "2022-11-14 00:00:00 +0900", "snippet": " 자바 ORM 표준 JPA 프로그래밍JPAJava Persistence API,자바 ORM API 표준 명세이다. 다양한 벤더들에서 이 표준에 대한 구현체를 제시하고 있고, 그 중 Hibernate가 많이 쓰인다.1. JPA Architecture EntityManagerFactory : EntitManager 인스턴스 생성하고 관리하는 팩토리 클래스. EntityManager : 객체에 대한 영속성 오퍼레이션들을 관리한다. works like factory for Query instances Entity : 영속성 객체로서, 데이터베이스에 저장된다. EntityTransaction : EntityManager와 일대일 관계를 가진다. 각 엔티티매니저마다의 오퍼레이션들은 이 클래스에 의해 관리된다. Persistence : EntityManagerFactory 인스턴스 생성하는 스태틱 메서드를 가지고 있는 클래스. Query : JPA 벤더에 의해 구현되는 인터페이스로서, 기준을 충족하는 relational object들이 있다.2. 왜 사용하는가? RDBMS 독립적인 프로그래밍이 가능하다. Dialect만 바꿔주면 되기 때문. 객체지향적 모델링과 테이블 모델링간의 간극을 좁힐 수 있다. 책의 저자는 이를 패러다임 불일치라고 소개한다. 덕분에 객체 매핑을 위한 코드도 대폭 감소한다. 3. 예제public class CreateEmployee { public static void main( String[ ] args ) { //설정 파일인 persistence.xml에 대한 내용은 생략. //unique한 이름, jdbc driver, user, password, url, dialect 등의 설정이 필요하다. //Persistence의 static메서드를 통해 EntityManagerFactory 생성 EntityManagerFactory emf = Persistence. createEntityManagerFactory( \"Eclipselink_JPA\" ); //emf를 통해 EntityManager 생성 EntityManager em = emf. createEntityManager( ); //트랜잭션 시작 em.getTransaction( ).begin( );\t\t Employee employee = new Employee( ); employee.setEid( 1201 ); employee.setEname( \"Gopal\" ); employee.setSalary( 40000 ); employee.setDeg( \"Technical Manager\" ); em.persist( employee ); em.getTransaction( ).commit( ); //트랜잭션 종료 //자원 반환 em.close( ); emf.close( ); } } emf는 생성 비용이 매우 크므로 애플리케이션 전역에서 한 번만 생성한 뒤 공유해서 사용한다. 반면 em은 DB Connection과 밀접한 관계이므로 스레드간 공유시 동시성 문제가 발생할 수 있다. em은 DB Connection이 필요한 시점까지 Connection을 얻지 않는다. " }, { "title": "Junit", "url": "/posts/jUnit/", "categories": "Spring, jUnit5", "tags": "jUnit5", "date": "2022-11-13 00:00:00 +0900", "snippet": "jUnit test framework.Architecture jUnit5 = jUnit Platform + jUnit Jupiter + jUnit Vintage jUnit Platform : JVM상에서 실행하기 위한 기초로서, 테스트를 발견 및 실행하는 테스트 엔진 API를 정의하고 있다. jUnit Jupiter : 테스트 엔진 API의 구현체. 테스트와 확장을 위한 programming model과 extension model의 조합임. 테스트 엔진 제공. jUnit Vintage : jUnit3, 4 테스트엔진 API 구현체. AnnotationsjUnit LifeCycle Annotation @Test 해당 메서드가 테스트 메서드임을 명시할 때 사용함. 속성이 없음. test extension들은 자신들 각각의 annotation에 기반해 동작하기 때문. @BeforeEach 해당 메서드가 각 @Test, @RepeatedTest, @ParaemterizedTest, @TestFactory 메서드(이하 테스트 메서드)의 실행 전에 실행되어야 한다는 것을 명시한다. @AfterEach 해당 메서드가 각 테스트 메서드의 실행 후마다 실행되어야 한다는 것을 명시. @BeforeAll 해당 메서드가 모든 테스트 메서드의 실행 전에 딱 한번 실행. @AfterAll 해당 메서드가 모든 테스트 메서드의 실행 후 딱 한번 실행. jUnit Main Annotation @SpringBootTest 통합 테스트 용도로 사용. @SpringBootApplictaion을 찾아가 하위의 모든 Bean을 스캔하여 로드한다. 그 후 Test용 Application Context를 만들어 Bean을 추가하고 MockBean을 찾아 교체 @ExtendWith jUnit4에서의 @RunWith. 메인으로 실행될 Class 지정 가능. @SpringbootTest는 기본적으로 @ExtendWith 추가되어 있다. @WebMvcTest(Controller.class) 매개변수로 지정한 클래스만 실제로 로드되어 테스트가 진행된다. 매개변수 없을시 컨트롤러와 연관된 모든 Bean이 로드된다. @SpringBootTest가 통합 테스트 용도로 사용되었다면, @WebMvcTest는 컨트롤러 테스트를 위해서 사용한다. @Autowired about MockBean 컨트롤러 API 테스트를 위해 MockMvc 객체를 주입받을 떄 사용한다. .andExpect(), andDo(), andReturn() @MockBean 테스트할 클래스에서 주입 받고 있는 객체에 대해 가짜 객체를 생성해주는 어노테이션. 해당 객체는 실제로 동작하는 것이 아니다. @AutoConfigureMockMvc spring.test.mockmvc 설정 로드 + MockMvc 의존성 자동 주입 MockMvc : REST API 테스트 클래스 @Import Configuration component 사용 가능. Test테스트 코드의 필요성 메서드의 분리를 통해 하나의 기능만을 가지도록 구성할 수 있다. 요구사항이 변경되었을 경우 테스트 코드 없이 메서드 변경시 전체 프로세스 차원에서 문제가 발생할 가능성이 있다. 이러한 부분을 단위 + 통합 테스트로 사전에 방지할 수 있음. 방대한 기능의 애플리케이션의 경우 테스트 자동화 실현 가능. 1부터 100까지의 프로세스가 있고, 그 중 40번째의 코드를 수정할 필요가 있다고 할 때, 기능 분리가 가능하기 때문에 1~39의 기능은 메모리에 로드할 필요가 없어 테스트 시간 단축 가능 따라서 효율적이고 효과적인 유지보수가 가능하다. 통합 테스트 전체 비즈니스 로직에 대한 테스트. 모든 의존성을 로드하는 과정을 밟기 때문에 무거운 작업임.단위 테스트 기능별로 진행하는 테스트. 필요한 환경만 메모리에 로드하여 실행한다. ex) @DataJpaTest given/when/then의 프로세스로 진행된다. FIRST 원칙 Fast : 실행은 빠르게 Independent : 독립적인 테스트가 가능해야. Repeatable : 테스트는 매번 같은 결과 Self-Validating : 실행 자체로 결과 확인 가능해야. Timely : TDD원칙에 따라 본 코드 완성 전 구성 및 테스트 가능해야함. 단위 테스트를 위한 가짜 환경 구성하기 예를 들어 서비스 레이어만 테스트 하고 싶은데 서비스 레이어 테스트를 위해선 Repository 레이어에 대한 의존성 문제를 해결해야 할 수 있다. 물론 그 의존성을 DI받아 사용할 수도 있지만, 특정 기능만 분리하여 테스트하는 단위 테스트의 목적과는 맞지 않다. 이러한 문제를 해결할 수 있는 것이 Mockito를 이용하는 것. Mockito는 가짜 객체를 보관하는 환경. 단위 테스트를 위한 테스트 클래스 시그니처 상단에 @ExtendWith() 어노테이션과 매개변수로 MockitoExtension.class를 등록해준다. 그리고 의존성 객체를 필드로 선언하며 @Mock 어노테이션을 붙여주고 의존성을 담을 객체(서비스 레이어를 테스트하는 경우에는 서비스 객체)를 필드로 선언하며 @InjectMocks 어노테이션을 붙여주면,@Mock이 붙은 의존성들을 가짜로 해당 객체에 주입하여 메모리에 로드한다. 이들은 가짜이므로 Stub(행동 정의)를 통해 테스트의 범위를 좁혀줄 필요가 있다. ex) when(실행).thenReturn(실행 결과); etc.트랜잭션클라이언트 -&gt; Controller -&gt; Service -&gt; Repository -&gt; Persistence Context -&gt; DB Controller는 넘어온 data를 파싱, validation check 등 하여 service에게 dto 넘겨줌 Service는 dto를 book entity로 변경 Persistence Context는 1차 캐시 및 DB에서 넘어온 데이터가 있는지 check하고 있으면 update, 없으면 insert Persistence Context는 persist 후 영속화된 객체를 Service에 넘기고 하는 프로세스로 진행되는데, 트랜잭션은 Controller -&gt; Service에서 시작되고 Service -&gt; Controller에서 종료된다. 트랜잭션 종료는 DB에 write할 수 없다는 걸 의미. 하지만 DB Session은 controller단에서 종료된다. 그 말은 Controller에서 Select는 가능하다. 따라서 그대로 영속화된 객체를 넘겨줄 경우, 만약 그 객체가 다른 타입의 엔티티와 연관관계를 맺고 있다면 messageConverter에서 client쪽으로 return하는 과정에서 get하게 되는데, lazy loading 발생하며 Persistence Context에 다른 연관관계를 맺고있는 엔티티를 다시 select하게됨. 그니까 쓸데없는 데이터까지 같이 딸려오게 되는 것. 그렇기 때문에 service에서 영속화된 엔티티를 가지고 필요한 데이터만 추출한 후 response를 위한 새로운 객체(영속화되지 않는 객체)만을 리턴하여 위 과정을 끊어주어야 한다. Test data의 Scope테스트 메서드는 종료될 때 rollback을 통해 데이터가 초기화된다. (@Transactional이 있는 경우). 단, @BeforeEach가 있는 경우에는 beforeEach 메서드부터 테스트 메서드 종료까지.즉, 메서드 실행(트랜잭션 시작) -&gt; 메서드 종료(트랜잭션 종료) -&gt; Rollback의 구조인데, 트랜잭션 종료 후 flush되는 것이 아니라는 것이다.그런데 만약 auto increment가 초기화되지 않는 문제 등으로 인해 @Sql을 수동으로 실행하게 되면 이 부분은 DB에 대해 쿼리가 날아가는 것이기 때문에 이 차이를 이해하고 있어야 한다." }, { "title": "소켓 프로그래밍", "url": "/posts/%EC%86%8C%EC%BC%93-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/", "categories": "CS, Network", "tags": "Socket", "date": "2022-09-06 00:00:00 +0900", "snippet": "소켓이란? 로컬 호스트와 원격 호스트간 양방향 통신을 위한 엔드포인트. IP주소와 포트번호가 조합되어 소켓 주소로 구성되고, 전송계층에서 데이터 전달을 위한 식별자로서 기능한다. TCP 프로토콜을 사용하는 스트림 소켓, UDP를 사용하는 데이터그램 소켓, 원형 그대로의 패킷을 바로 어플리케이션으로 송신하는 로우(Raw) 소켓이 있음.소켓 연결 시나리오 socket() : 소켓과 Socket Descriptor 생성. bind() : Socket Descriptor를 지정된 IP주소/포트번호와 바인딩. listen() : 클라이언트의 접속 요청 대기 accept() : 클라이언트의 접속 허용 connect() : 클라이언트가 서버에 접속 요청 read, write 또는 send, recv : 데이터 송수신 처리 close() : 소켓을 닫음.예제코드(java) 서버 public class ServerSocket{ public static void main(String[] args){ ServerSocket serverSocket = null; Socket socket = null; try{ //[1] 소켓 생성, bind, listen //(1) 포트번호를 생성자로 넘기거나 serverSocket = new ServerSocket(9191) //(2) bind() 호출 serverSocket = new ServeroSocket(); serverSocket.bind(new InetSocketAddress(\"localhost\", 9191)); while(true){ //[2] accept() 는 통신에 사용할 별도의 socket 리턴. socket = serverSocket.accept(); //연결된 클라이언트측 정보를 담은 객체. getPort(), getHostName(), getAddress() InetSocketAddress isa = (InetSocketAddress) socket.getRemoteSocketAddress(); InputStream is = socket.getInputStream(); String message = null; byte[] bytes = new byte[100]; is.read(bytes); message = new String(bytes, \"UTF-8\"); System.out.println(\"클라이언트에서 보낸 데이터 : \" + message); OutputStream os = socket.getOutputStream(); message = \"서버측에서 보내는 데이터\"; os.write(message.getBytes()); os.flush(); is.close(); os.close(); socket.close(); } }catch(Exception e){ } } } 클라이언트 public class ClientSocket{ public static void main(String[] args){ Socket socket = null; try{ socket = new Socket(); //localhost가 들어가는 원래 IP주소와 포트는 클라이언트측에서 알고있는 상태 socket.connect(new InetSocketAddress(\"localhost\", 9191)); byte[] bytes = null; String message = null; OutputStream os = socket.getOutputSteram(); message = \"클라이언트측에서 보내는 메시지\"; os.write(message.getBytes()); os.flush(); InputStream is = socket.getInputStream(); bytes = new byte[100]; is.read(bytes); message = new String(bytes, \"UTF-8\"); System.out.println(\"서버측에서 보낸 데이터 : \" + message); os.close(); is.close(); socket.close(); }catch(Exception e){ e.printStackTrace(); } } }" }, { "title": "OSI 7계층", "url": "/posts/OSI-7%EA%B3%84%EC%B8%B5/", "categories": "CS, Network", "tags": "OSI 7 Layer", "date": "2022-08-17 00:00:00 +0900", "snippet": "OSI 7계층 OSI 7 Layer 네트워크 구성요소를 7개의 계층으로 역할을 나눈 표준 모델. TCP/IP(Transmission Control Protocol/Internet Protocol) 리눅스/유닉스 초기 운영체제에서 서로 연결을 위한 소프트웨어 집합을 만들었는데 그것이 TCP/IP OSI 7계층이 나오기 전 널리 사용되며 사실상 표준 역할을 하였음. OSI 7 Layer이 장비 및 통신의 표준으로서 사용되기는 하나 실질적인 통신은 TCP/IP의 프로토콜을 사용하여 이루어진다. OSI 계층이 양단의 단말기에서 어떤 방식으로 사용되는지 보여주는 예. 데이터를 장치 A에서 장치 B로 보내기 위해선 계층을 거치며 data가 패키징, 언패키징됨.계층별 역할1. 물리 계층(Physical Layer) 물리적인 매체를 통해 데이터가 변환된 전기적 신호를 보내고 받는 계층. 다음과 같은 역할을 한다. (1) 데이터의 송신과 수신의 속도가 같도록 일정 클록으로 비트를 동기화한다. (2) 전기적 신호를 데이터로, 데이터를 전기적 신호로 변환한다. NIC(Network Interface Card) 흔히 랜카드라고도 하며 다음의 기능을 한다. (1) 장비와 LAN 사이의 통신 준비. (+비트 송수신 속도 불일치 조정) (2) 전송될 데이터의 직렬화 (3) 좀 더 빠른 전송 속도를 위한 인코딩 (4) 데이터 수신 및 데이터를 CPU로 전달 (5) 매체 접근 제어(Media Access Control)기능이 구현된 하드웨어와 펌웨어 지님. MAC는 하나의 통신 회선을 여러 단말장치들이 원활하게 공유할 수 있도록 해주는 통신 회선에 대한 접근 방식. cf) MAC 주소는 네트워크 인터페이스에 할당되는 고유 식별자. CSMA 방식, CSMA/CD 방식, 토큰 버스 방식, 토큰 링 방식 등이 있음. CSMA/CD(Carrier Sense Multiple Access/Collision Detection) Carrier Sense : 통신 회선이 사용중인지 점검 Multiple Access : 통신 회선이 비어있으면 누구든지 사용 가능 Collision Detection : 데이터 프레임을 전송하면서 충돌 여부 조사 이더넷 환경에서 적용되고 있는 프로토콜. 2. 데이터 링크 계층(Data Link Layer) 노드대 노드 전달의 책임을 지며 다음의 역할을 한다. (1) 프레임 구성 : 네트워크 계층으로부터 받은 데이터를 프레임 단위로 나눈다. 네트워크 계층으로부터 받은 데이터에 트레일러와 헤더를 덧붙인다. 트레일러에는 흐름, 오류, 접근제어를 위한 정보가, 헤더에는 물리주소(MAC) 등이 담김. 송신측과 반대로 수신측에서는 물리 계층에서 올라온 프레임의 header를 벗겨 어디로 보낼지 파악. (2) 물리주소(MAC address) 할당 : 송신자/수신자의 물리 주소를 헤더에 추가한다. (3) 흐름제어 : 송신측과 수신측간 데이터를 주고받을때, 성능 및 네트워크 환경으로 인해 데이터를 너무 적게 혹은 너무 많게 주고 받지 않도록 데이터 흐름을 적절히 제어. (4) 오류제어 : 손상 또는 손실된 프레임을 발견하고 재전송 (5) 접근제어 : 매체상에 통신 주체가 여럿 존재할때 주어진 어느 한 순간에는 하나의 장치만 동작하도록 제어. 노드대 노드 전달의 책임 이더넷 프레임 Preamble : 송신자와 수신자의 동기화를 위해 사용됨.(7byte) SFD(Start of Frame Delimeter) : 자신의 뒤로 오는 프레임의 내용이 곧 시작된다는 것을 알려줌. DA, SA : 출발지와 목적지의 MAC주소를 담고 있다.(각 6byte -&gt; 앞의 24비트는 제조사 번호, 뒤의 24비트는 랜 카드 일련번호 의미) EtherType/Length : 데이터에 내재된 네트워크 프로토콜 타입 식별 역할.(2byte) Length는 수납되는 LLC 프레임의 길이를 나타냄. Data : 46 ~ 1500 bytes FCS(Frame Check Sequence) : 수신된 전체 프레임에서 손상된 데이터 탐지. 에러 검출.3. 네트워크 계층(Network Layer) 패킷을 발신지-대-목적지전달하는 책임을 가지며 다음의 역할을 한다. 패킷이 데이터링크 계층으로 내려가 패키징되면 프레임으로 지칭한다. (1)논리주소(IP) 지정 : 상위 계층에서 받은 패킷에 발신지와 목적지의 논리주소를 헤더에 추가. (2) 라우팅 : 패킷이 목적지에 도착할 수 있도록 경로를 지정. 발신지 대 목적지 전달 목적지까지 과정에서의 각 노드에서도 네트워크 계층까지는 거친다. 방식에 따라 차이는 있지만 다음 노드의 MAC 주소를 갱신하는 등 해당 노드가 목적지인지 판별하고 다음 경로를 찾기 위함. 네트워크 계층의 주요 프로토콜 ICMP(Internet Control Message Protocol) : 에러 발생시 발생 원인을 알려주거나 네트워크 상태 진단 IGMP(Internet Group Management Protocol) : 멀티캐스팅 멤버십 제어를 위한 그룹 관리용 프로토콜 ARP(Address Resolution Protocol) : 논리적인 IP주소를 이용해 물리적인 MAC 주소를 알아내는 방법. 캐시에 저장. RARP(Reverse Address Resolution Protocol) : ARP 반대로서 MAC주소를 이용해 IP주소 알아내는 방법. 저장 장치가 없는 네트워크 단말기 등의 IP 주소를 얻기 위해 사용한다. IP(Internet Protocol) : 네트워크 기기에서 논리적 식별을 위한 주소. IPv4와 IPv6 각각 40억개, 2의 128제곱의 개수를 가짐. 네트워크 계층의 전달 흐름4. 전송 계층(Transport Layer) 전체 메시지의 프로세스 대 프로세스 전달에 대한 책임을 가진다. 프로세스대 프로세스이기 때문에 포트번호가 필요하다. 네트워크 계층은 개별적인 패킷의 종단간 전송을 담당한 반면, 전송 계층은 전체 메시지가 완전하게 도착하는 것을 보장한다. 기능 (1) 포트 주소 지정 : 네트워크 계층은 개별 패킷을 정확한 컴퓨터에, 전송 계층은 해당 컴퓨터의 정확한 프로세스에 전달하는 역할을 한다. (2) 분할과 재조립 : 네트워크별 최대 전송 단위(MTU; Maximum Transfer Unit)에 따라 패킷을 세그먼트 단위로 나눈다. 각 세그먼트는 순서번호(offset)을 가지며 이를 이용하여 재조립하거나 패킷의 손실여부를 판단한다. (3) 연결제어 (4) 흐름제어 (5) 오류제어 전송 계층의 주요 프로토콜 TCP(Transmission Control Protocol) 연결형 서비스. 가상 회선 방식 사용. 데이터의 신뢰성을 보장하며 3-way handshaking 과정을 통해 연결. 때문에 속도가 느릴 수 있다. 3way handshaking : TCP/IP 프로토콜을 이용한 통신에서 데이터 전송 전에 정확한 전송을 보장하기 위해 상대방 컴퓨터와 사전에 세션을 수립하는 과정을 의미한다. UDP(User Datagram Protocol) 비연결형 서비스. 데이턱그램 방식 제공 영상 스트리밍등 일부 데이터가 도착하지 않는다고 해서 컨텐츠 소비에 큰 지장이 없을 경우에 적합하다. 신뢰성이 낮은 대신 TCP보다 속도가 빠름. SCTP(Stream Control Transmission Protocol) UDP + TCP 다중 연결 지원 메시지의 프로세스대 프로세스 전달 전송계층 ~ 데이터링크 계층 데이터 패키징 5. 응용 계층(Application Layer) 프로그래머의 영역 사용자가 네트워크에 접근할 수 있도록 사용자 인터페이스 제공. FTP, Telnet, SMPT, DNS, DHCP, Ping, Tcpdump, Tracerouter 등 다양한 프로토콜이 존재하며 이러한 상위 프로토콜에 대한 정보가 헤더에 담겨(Message) 전송 계층으로 내려간다." }, { "title": "자료구조(4)__heap", "url": "/posts/%EC%9E%90%EB%A3%8C%EA%B5%AC%EC%A1%B0(4)__Heap/", "categories": "자료구조", "tags": "heap", "date": "2022-08-13 00:00:00 +0900", "snippet": "힙(Heap) 완전 이진 트리 따라서 빈 값이 없는 일차원 배열로 표현이 가능하다. 부모 노드를 기준으로 자식 노드의 인덱스는 왼쪽의 경우 부모 노드의 인덱스X2, 오른쪽의 경우 부모 노드의 인덱스X2 + 1 이다. 최대 힙 부모 노드의 값은 항상 자식 노드보다 크거나 같음. 루트 노드 = 트리의 최댓값 최소 힙 부모 노드의 값은 항상 자식 노드보다 작거나 같음 루트 노드 = 트리의 최솟값 Binary Search Tree와는 다르게 값의 중복을 허용하고, 상하 관계의 값의 제약은 있지만 좌우 관계의 값의 제약은 없다. 최대, 최솟값을 기준으로 데이터를 찾는 연산을 빠르게 수행할 수 있다. 시간복잡도 O(1) 삽입, 삭제의 시간복잡도는 O(log N) 우선순위 큐(Priority Queue) 일반 큐의 경우에는 FIFO 데이터 구조였다면, 우선순위 큐는 데이터가 들어온 순서와 상관없이 우선순위가 높은 데이터를 우선하여 처리한다. 힙 정렬(Heap Sort) 힙 자료구조의 특성을 이용한 정렬 방법. Heapify 힙의 재구조화 데이터 추가/삭제 후에도 힙의 속성을 유지하도록 함. Heap에 데이터 삽입하는 경우 1.완전 이진 트리의 구조를 유지해야 하기 때문에 우선 leaf노드에 삽입한다. 2.해당 Heap이 조건을 만족하는지를 체크한다. 만족하는 경우 추가적인 연산은 이루어지지 않고, 만족하지 않는 경우에는 삽입된 노드와 부모 노드의 값을 바꾼다. 해당 작업 수행 후 2번으로 돌아가 반복한다. Heap에 데이터 삭제하는 경우(ex. Max Heap에서 최댓값 삭제) 마지막 노드를 루트 노드로 가져오며, 기존 루트 노드는 삭제한다. 힙의 조건을 만족하는지 확인한다.. 만족한다면 추가 연산은 이루어지지 않으나, 만족하지 않으면 루트 노드와 자식 노드를 바꾼다. 연산 후 2번의 조건을 체크하는 과정을 다시 반복한다. " }, { "title": "자료구조(3)__tree", "url": "/posts/%EC%9E%90%EB%A3%8C%EA%B5%AC%EC%A1%B0(3)__Tree/", "categories": "자료구조", "tags": "data structure, tree", "date": "2022-08-09 00:00:00 +0900", "snippet": "트리 한 노드가 여러 노드를 가리킬 수 있음. 비선형적 자료구조(데이터의 순서가 중요하지 않음. ) 그래프 데이터 구조의 계층적인 상하관계의 속성을 표현할 때 사용할 수 있음. 기본적인 데이터 단위를 노드라고 하며, 부모가 없는 최상위 노드를 root노드라고 하며 단 하나만 존재할 수 있다. 각 노드는 edge로 연결되어 있음 상대적인 상하관계는 부모노드와 자식노드로 표현하며, 같은 부모를 가진 노드를 형제노드라고 한다. 자식의 개수를 차수(degree)라고 함. 자식이 없는 노드는 leaf 혹은 terminal(단말), external(외부)노드라고 함. 루트노드부터 특정 노드까지의 거리를 depth라고 함. 트리는 서브트리로 구성되어 재귀적인 구조를 가진다.트리의 종류이진 트리 자식 노드가 최대 2개까지만 허용되는 트리 자식 노드는 부모 노드 기준 왼쪽, 오른쪽에 위치할 수 있는데 자식 노드의 위치에 따라 왼쪽 자식노드와 오른쪽 자식노드로 구분됨. 즉, 같은 루트에 같은 자식 노드를 가지고 있더라도 자식노드가 왼쪽에 위치한 경우와 오른쪽에 위치한 경우는 다른 노드로 본다. 정 이진트리(full binary tree), 엄격한(strict) 이진 트리 모든 노드가 2개의 자식을 가지거나 자식이 아예 없을때. 포화 이진트리(perfect binary tree) 모든 노드가 2개의 자식을 가지고, 단말 노드가 같은 레벨일 때. 높이가 h인 포화 이진 트리에서 노드 갯수는 2^h - 1 2^0 + 2^1 + 2^2 + … + 2^h 단말 노드의 갯수는 2^h 완전 이진 트리(complete binary tree) 마지막 레벨을 제외하고 모든 노드가 채워져야 함. 노드는 왼쪽에서 오른쪽으로 채워짐. (따라서 마지막 레벨의 노드가 왼쪽만 있는 경우는 있어도 오른쪽만 있는 경우는 없다.) 이진트리는 일차원 배열로 표현이 가능하다.(왼 -&gt; 오) 이진트리의 응용 힙 이진 탐색 트리(Binary Search Tree) B-Tree AVL 트리 트리의 경우 특성상 선형적인 다른 자료구조와는 달리 트리 탐색이라는 연산이 존재.이진 탐색 트리(Binary Search Tree) 일반적인 트리의 경우 데이터의 특성에 제약이 없음. 따라서 특정 데이터를 찾기 위해선 모든 노드의 탐색이 이루어져야 함. 따라서 트리의 데이터에 제약을 걸어줌으로써 탐색의 시간 복잡도를 O(N)에서 O(log N)으로 줄일 수 있는 것이 이진 탐색 트리. 이진 트리의 구조에서 노드의 왼쪽 서브 트리에는 루트 노드보다 작은 값, 노드의 오른쪽 서브 트리에는 루트 노드보다 큰 값을 위치시킨다. 그리고 서브 트리는 다시 이진 탐색 트리로 구성되며 중복된 값은 없다. 이러한 특성으로 인해 BST의 최솟값은 가장 왼쪽 아래 노드. 최댓값은 가장 오른쪽에 위치. 중위 탐색을 할 경우 모든 데이터를 정렬된 순서로 가져올 수 있음. 삽입 중복된 데이터가 있을 경우에는 삽입을 하지 않고 종료. 추가된 노드는 트리의 leaf에 삽입한다. 삭제 삭제할 데이터의 위치를 찾고, 삭제할 데이터가 leaf노드인 경우, 한개의 자식 노드를 가진 경우, 두개의 자식 노드를 가진 경우로 나뉜다. 삭제할 데이터가 leaf노드인 경우 : 부모 노드가 가진 해당 노드의 데이터를 null로 갱신. 한개의 자식 노드를 가진 경우 : 해당 노드의 자식노드를 해당 노드의 부모노드로 연결시킨다. 두개의 자식 노드를 가진 경우 BST는 한 노드가 왼쪽 서브트리보다는 큰 값을, 오른쪽 서브트리보다는 작은 값을 가진다는 특징을 이용해 해당 노드를 왼쪽 서브트리의 최댓값과 교체하거나 오른쪽 서브트리의 최솟값과 교체하는 방법 두 가지가 있음. 교체 후에는 데이터가 중복되지 않도록 서브 트리의 노드를 지운다. 트리 순회루트노드 방문을 언제 하는가에 따라 전위 탐색(preorder) 루트노드 방문 &gt; 왼쪽 서브트리를 preorder &gt; 오른쪽 서브트리를 preorder 여기서 preorder는 트리의 재귀적인 특성상 재귀호출. 이후의 inorder, postorder도 같은 의미. 중위 탐색(inorder) 왼쪽 서브트리를 inorder &gt; 루트노드 방문 &gt; 오른쪽 서브트리 inorder 후위 탐색(postorder) 왼쪽 서브트리를 postorder &gt; 오른쪽 서브트리를 postorder &gt; 루트노드 방문 트리 순회 예시 전위 탐색 : F - B - A - D - C - E - G - I - H 중위 탐색 : A - B - C - D - E - F - G - H - I 후위 탐색 : A - C - E - D - B - H - I - G - F 트리 순회 방법에 따라 데이터의 순서가 달라지며, 중위 탐색의 경우 F를 기준으로 왼쪽 오른쪽으로 나뉨. " }, { "title": "Comparator와 Comparable", "url": "/posts/comparator%EC%99%80-comparable/", "categories": "Java", "tags": "comparator, comparable", "date": "2022-08-09 00:00:00 +0900", "snippet": "Comparator와 ComparableComparator와 Comparable은 둘 다 인터페이스로서, 이를 사용하고자 한다면 내부에 선언되어있는 추상메서드를 반드시 구현해야 한다.Arrays.sort 메서드를 보면 원시타입의 배열 외에도 참조 타입의 배열이 들어갈 수 있도록 매개변수를 Object[]를 받는 경우가 있는데, 위 두 인터페이스의 필요성은 참조 타입의 정렬이 어떤 기준으로 이루어지는지에 대한 의문부터 시작한다. class Student{ int studentId; String name; int age; }원시타입의 경우에는 부등호를 통해 단순한 대소비교가 가능하지만 학생이라는 객체의 배열을 정렬하기 위해선 기준점이 필요한데, 이를 Comparable 혹은 Comparator를 통해 지정해주는 것. 용법//Comparable class Student implements Comparable{ int studentId; String name; int age; @Override public int compareTo(Student o) { return Integer.compare(this.studentId, o.studentId); } } //Comparator class foo{ private static Comparator&lt;Student&gt; idComparator = ((o1, o2)-&gt;{ return Integer.compare(o1.studentId, o2.studentId); }); public void studentSort(Student[] arr){ Arrays.sort(arr, idComparator); } }CompareTo메서드는 자기 자신과 인자로 들어오는 다른 객체를 비교하는 반면,Compare 메서드는 인자로 들어오는 두 객체를 비교하게 됨." }, { "title": "자료구조(2)__hash", "url": "/posts/%EC%9E%90%EB%A3%8C%EA%B5%AC%EC%A1%B0(2)__Hash/", "categories": "자료구조", "tags": "data structure, hash", "date": "2022-08-02 00:00:00 +0900", "snippet": "Hash란 임의의 길이를 가진 원 데이터가 매핑된 특정한 길이의 데이터. 해시값, 해시코드 등으로도 지칭. 매핑은 해시 함수를 통해 이루어지며 이러한 과정을 해싱이라고 하는듯. 해싱의 과정 키(Key) -&gt; 해시 함수 -&gt; 해시값 Key Value 형식의 데이터가 있을 때, Key는 해시 함수(Hashing)를 통해 데이터가 있거나 저장될 해시 테이블의 주소(해시값)를 계산하게 된다. 빠른 속도로 데이터 접근 및 저장 가능. 이는 다른 선형 자료 구조가 탐색이나 삽입에 시간이 소요되는 것과 비교됨. Hashing &amp; Hash Function : 상기한 내용을 통해 알 수 있듯이, 해시 함수 혹은 해싱이라는 과정을 통해 Key라는 원 데이터를 고정된 길이의 해시값으로 바꾸게 된다. 좋은 해싱 키 값을 고르게 분포시킴. 특정 위치에만 밀집(clustering)되면 충돌 가능성이 높아지거나 재탐색의 시간이 소요될 수 있기 때문. 빠른 계산 해시충돌의 최소화 해시충돌이란 키 값이 다르지만 해시 함수의 결과값이 동일한 경우를 의미. Key를 기준으로 데이터가 관리되기 때문에 순서가 존재하지 않으며, Key는 중복되지 않는 고유한 값을 사용해야 한다. HashTable : Key값을 변환시킨 해시값을 index로 삼아 원데이터(Key &amp; Data)를 저장하는 자료구조. 해시테이블에 있어서 중요한 것은 충돌을 최소화 해야 한다는 것. 해시테이블의 장점은 빠른 데이터 접근 및 저장이 가능하다는 점(시간복잡도 : O(1))인데, 충돌이 발생하게 되면 탐색 및 삭제 연산이 최악의 경우 O(N)이 될 수도 있음.(모든 원 데이터의 키값이 하나의 동일한 해시값으로 매핑된 경우). 비둘기 집 원리 : N+1개의 물건을 N개의 상자에 넣었을 때, 적어도 한 상자에는 두 개 이상의 물건이 들어있다. Birthday Problem : 사람이 임의로 모였을 때, 생일이 같은 두 명이 존재할 확률을 구하는 문제 생일이 가능한 가짓수는 윤달의 경우를 포함하여 366개. 367명 이상의 사람이 모인다면 비둘기집 원리에 따라 생일이 같은 두 명이 반드시 존재하며, 23명 이상만 모여도 그 중 두명이 생일이 같을 확률은 1/2를 넘음. 따라서 데이터가 많아질수록 충돌 발생 가능성도 높아지기 때문에 충돌을 최소화하여 연산 속도를 빠르게 하는 것이 관건이며, 충돌 최소화를 위해선 해시테이블의 구조 개선, 해시 함수 개선이 있음. 해시테이블의 구조 개선 Chaining 충돌 발생하더라도 동일한 버킷에 저장하는데, 이 때 Linked List나 Tree를 이용해 데이터를 저장함. 충돌이 다수 발생하면 최악의 경우 O(N)의 시간복잡도가 소요될 수 있음. Open Addressing Linear Probing : 해시 충돌시 n칸을 건너뛴 다음 버킷에 저장 계산 단순 검색 시간이 많이 소요. n칸을 건너 뛰었음에도 다음 인덱스에 데이터가 있다면 이 과정을 반복하게 됨. 데이터들이 특정 위치에만 밀집(clustering) Quadratic Probing : 해시 충돌시 n^2칸을 건너뛴 다음 버킷에 저장 clustering 문제를 해결. but 해시값이 같다면 이 방법도 clustering 문제를 효과적으로 해결하기 어려움. Double Hashing : 해시 값에 다른 해시 함수를 한번 더 적용 최초의 해시 값을 구하고, 해시 충돌 발생시 이동 폭을 구함. 최초 해시 값이 같더라도 이동 폭이 다르기 때문에 clustering 문제 해결 가능. 해시 함수 개선 나눗셈법(Division Method) 해시테이블의 크기를 아는 경우, 테이블의 크기로 키 값을 나눈 나머지를 해시값으로 하는 방법 나눌 때에는 나누는 수를 짝수는 피하고 되도록 소수를 사용하는 것이 좋음. 곱셈법(Multiplication Method) 숫자로 된 키가 k이고, A는 0과 1 사이의 실수일 때 다음과 같이 정의되며, m의 크기는 중요하지 않으며 보통 2의 제곱수로 정한다고 함. 나눗셈법보다는 느림. h(k)=(kAmod1)*m Reference 해쉬 테이블(Hash Table)이란? " }, { "title": "자료구조(1)__list", "url": "/posts/%EC%9E%90%EB%A3%8C%EA%B5%AC%EC%A1%B0(1)__List/", "categories": "자료구조", "tags": "data structure, list, stack, queue", "date": "2022-07-19 00:00:00 +0900", "snippet": "List 선형적인 자료구조로서, 데이터간의 순서가 존재. 종류 ArrayList LinkedList 데이터간의 연결 방식에 따라 Single Linked List Double Linked List ArrayList 배열 기반의 리스트 단, 배열과 달리 저장 공간이 가변적임. 메모리 공간을 연속적으로 사용. 컴퓨터가 연산하기 쉬운 구조. 삽입, 삭제 중앙에 데이터를 삽입, 삭제한다고 했을 때, 수정 요소의 뒤쪽을 뒤로 밀거나 앞으로 당겨야 하기 때문에 시간복잡도는 O(N) 탐색 Random Access이므로 시간복잡도는 O(1) LinkedList 컴퓨터 메모리상 공간을 연속적으로 차지하고 있지 않으며, 데이터를 논리적으로 연결시킨 자료구조. 노드를 구성 요소로 하는데, 노드는 데이터와 다음 노드를 가리키는 포인터로 구성되어 있다. 가장 앞의 노드를 Head, 가장 마지막의 노드를 Tail. Tail의 포인터는 다음 노드가 없으므로 Null ArrayList와 LinkedList의 시간복잡도 비교 장점 배열의 복사나 재할당 없이 데이터를 손쉽게 추가할 수 있음. 포인터를 이용하기 때문에 유연한 공간 단점 데이터 접근에 대한 시간이 늘어남 검색에 있어서는 ArrayList가, 추가 및 삭제에 있어서는 LinkedList가 적절해보임.DoubleLinkedList LinkedList와 달리 한 노드에서 앞 뒤 노드의 포인터를 모두 가지고 있음. Head 노드와 Tail 노드 양쪽에서 데이터 접근이 가능하기 때문에 탐색 작업이 반으로 줄어들 수 있음. 단점은 양방향 연결을 위한 작업이 필요하다는 것. 스택과 큐는 구현 방식에 있어서 리스트와 관련있기에 같이 분류.Stack 데이터를 쌓아 올리는 방식의 자료구조 LIFO(Last In First Out : 후입선출) top에서만 모든 input(push)과 output(pop)이 이루어짐. 주로 LinkedList or Array 이용하여 구현. 함수 실행 컨텍스트를 저장하는 등의 용도로 사용.Queue 대기열 형태의 자료구조 FIFO(First In First Out : 선입선출) front(처음)에서 output(dequeue)이, rear(끝)에서 input(enqueue)이 이루어짐 순서가 보장된다는 특징이 있음. Linked List를 이용한 구현과, 배열을 이용한 구현이 있음.Linear Queue 배열을 이용한 선형 큐. 배열을 이용했기 때문에 dequeue시 데이터를 한 칸씩 옮겨주는 작업이 필요. 시간복잡도 O(N). 비효율적Circular Queue 배열을 이용한 큐 구현시 Linear Queue의 단점을 보완한 원 형식의 큐 고정된 크기의 배열로 구현. front 혹은 rear의 index를 capacity로 나누는 아이디어를 통해 데이터 dequeue, enqueue시 index를 별도로 관리하지 않아도 되도록 함." }, { "title": "자료구조(0)", "url": "/posts/%EC%9E%90%EB%A3%8C%EA%B5%AC%EC%A1%B0(0)/", "categories": "자료구조", "tags": "data structure", "date": "2022-07-19 00:00:00 +0900", "snippet": "자료구조란? 데이터의 효율적인 접근 및 수정을 목적으로 데이터를 구조적으로 관리하는 방식. 문제 상황에 있어서 효과적인 자료구조의 선택은 효율적인 연산 수행으로 이어짐. 자료구조를 학습할 때 중요한 점은, 자료구조의 장점과 한계를 논리적으로 설명할 수 있어야 한다는 것. 자료구조는 크게 리스트, 스택, 큐, 해시, 트리, 힙, 그래프 등이 있음. 보통 문제 해결을 위한 방법(알고리즘)에는 여러가지가 존재하기 때문에 효율적인 방법을 찾으려면 비교를 위한 지표가 필요한데, 그 지표로서 복잡도가 있음.복잡도 복잡도를 단순화 하여 표현할 때 사용하는 것이 점근 표기법인데, 점근 표기법에는 세타 표기법(상한/하한 점근), 오메가 표기법(하한 점근), 빅오 표기법(상한 점근) 등이 있음. 대표적으로 많이 사용되는 것이 빅오 표기법으로, 컴퓨터가 처리해야 하는 연산의 개수를 세는 방법으로 측정함. 복잡도를 통해 알고리즘의 비용을 시간과 공간 측면에서 비교. 특징 가장 큰 영향력이 있는 항만 표시함. 예를 들어, O(N^3 + N^2)일 경우 가장 큰 영향력이 있는 항은 N^3이므로 O(N^3)으로 표시. 상수는 무시함 빅오 표기법을 통해 공간 복잡도와 시간 복잡도를 설명 공간 복잡도 : 데이터 관리에 필요한 공간.(예상 소요 공간) 시간 복잡도 : 데이터 처리에 소요되는 시간. O(1) : 입력 데이터의 크기와 상관없이 항상 일정한 시간이 걸리는 알고리즘 배열의 Random Access(인덱스만 알면 해당 원소로 바로 접근할 수 있음&lt;-&gt; sequential access는 데이터의 위치까지 맨 앞부터 차례로 탐색) Hash O(N) : 입력 데이터의 크기에 비례해서 시간이 소요되는 알고리즘 for문 O(N^2) : 입력 데이터의 제곱에 비례해서 시간 소요되는 알고리즘 이중 for문 O(logN) binary search 증명 n이 반씩 줄어들다 보면 k번째에서 1이 된다고 가정. n*(1/2)^k = 1 n = 2^k log n = log(2^k) log n = k " }, { "title": "Enum", "url": "/posts/enum/", "categories": "Java", "tags": "enumeration", "date": "2022-05-31 00:00:00 +0900", "snippet": "enum1. enum이란서로 연관된 상수들의 집합 java에서는 final을 이용해 값을 고정시킨 상수를 사용하는데, 어떤 클래스가 상수만으로 이루어져있는 경우 굳이 class로 선언하는 대신 enum으로 선언하면 해당 객체는 상수의 집합이라는 것을 명시적으로 나타내게 됨. enum클래스는 java 1.5 부터 지원하며, 이전에는 static final을 통해 메모리에 한번만 로드되며 값이 변경되지 않도록 하는 방식 혹은 public static final이 생략되는 interface의 특징을 이용한 방식 등이 있음. 추가 기본적으로 java에서 enum은 추상 클래스이며, 그 하위에 선언된 각 열거형 변수는 enum의 타입을 상속받은 하위 클래스이다. 따라서 다른 클래스로부터 상속을 받을 순 없지만 인터페이스 구현은 가능. //1 class Days1{ private static final int SUN = 1; private static final int MON = 2; private static final int TUE = 3; private static final int WED = 4; private static final int THU = 5; private static final int FRI = 6; private static final int SAT = 7; } //2 interface Days2{ int SUN = 1; int MON = 2; int TUE = 3; int WED = 4; int THU = 5; int FRI = 6; int SAT = 7; } //3. enum enum Days3 { MON(1), TUE(2), WED(3), THU(4), FRI(5), SAT(6), SUN(7); //()안의 값과 하단의 3개 행은 불규칙한 값을 지정할 필요가 있을 때 사용. private static final int label; public Days3(int label){ this.label = label; } public int label(){ return this.label; } }" }, { "title": "Jvm", "url": "/posts/JVM/", "categories": "Java", "tags": "JVM", "date": "2022-05-31 00:00:00 +0900", "snippet": "Java Virtual Machine1. JVM이란 자바를 실행하기 위한 가상 기계(머신)로서, 바이트 코드를 실행할 수 있는 주체. 그리고 자바 바이트 코드를 OS에서 어떻게 실행할지에 대한 표준 스펙. JVM 자체는 OS에 종속적임. 가상 머신이란? 소프트웨어로 구현된 하드웨어를 뜻하는 넓은 의미의 용어. 프로그램의 실행을 위해 물리적 머신과 유사한 머신을 소프트웨어로 구현한 것. 자바는 WORA(Wirte Once Run Anywhere)를 위해 이러한 가상 머신을 기반으로만 동작하도록 설계되었음. 2. 자바 프로그램의 실행과 JVM 구조 JVM은 크게 Class Loader와 Execution Engine, Runtime Data Area로 나누어짐.2.1 자바 프로그램의 실행 과정(1) 프로그램 실행시 JVM은 OS로부터 프로그램이 필요로 하는 메모리를 할당받고, JVM은 이러한 메모리를 용도에 따라 여러 영역으로 나누어 관리함.(2) 자바 컴파일러(javac)는 자바 소스코드(.java)를 읽어들여 자바 바이트코드(.class)로 변환시킴.(3) Class Loader를 통해 class 파일들을 JVM으로 로딩.(4) 로딩된 class파일들은 Execution Engine을 통해 해석됨.(5) 해석된 바이트코드는 Runtime Data Areas에 배치되어 실질적인 수행이 이루어지며,(6) 이러한 실행과정 속에서 JVM은 필요에 따라 Thread Synchronization과 GC같은 관리작업을 수행함.2.2 JVM 구조1. Class Loader JVM내로 클래스(.class)를 로드하고 링크를 통해 배치하는 작업을 수행하는 모듈. 로딩(Loading) 클래스 로더가 .class인 파일의 위치를 찾아 JVM에 올려놓는 과정. 그 내용에 따라 적절한 바이너리 데이터를 만들고 Method Area에 저장하는데, 저장되는 데이터로는 Data Type, 메서드와 변수, FQCN이 있음. TODO : 3가지 클래스 로더와 작동 원칙은 추후 포스트 링킹(Linking) .class 파일 형식이 유효한지 체크하는 Verify, 클래스 변수와 기본값에 필요한 메모리를 준비(메모리 할당과 기본값으로 세팅)하는 Prepare, 그리고 *심볼릭 레퍼런스를 메모리 영역에 있는 실제 레퍼런스로 교체하는 Resolve(optional). *심볼릭 레퍼런스 : 기본 자료형을 제외한 모든 타입을 명시적인 메모리 주소 기반의 레퍼런스가 아니라, 실행시 링크할 수 있도록 심볼릭 레퍼런스(참조하는 대상의 이름)만을 가지고 있고 런타임 시점에 실제 물리적인 주소로 대체됨 초기화(Initialization) Prepare 단계에서 확보한 메모리 영역에 클래스의 static 값들을 할당하는 단계.(슈퍼 클래스 및 정적 필드의 초기화) 2. Execution Engine 클래스를 실행시키는 역할(런타임 모듈). 클래스 로더가 JVM 내의 런타임 데이터 영역(Method Area)에 배치한 바이트 코드를 실행. 실행 방식을 기준으로 두 가지가 있음. Interpreter 방식 실행 엔진은 자바 바이트코드를 명령어 단위로 읽어서 실행하는데, 바이트 코드를 한 라인씩 읽고 운영체제가 실행할 수 있도록 기계어로 변경. 이 과정에서 속도 문제가 발생. JIT(Just In Time) 방식 인터프리터 방식의 단점을 보완. 인터프리터 방식으로 실행하다가 적절한 시점에 바이트코드 전체를 컴파일하여 네이티브 코드로 변경. TODO : 컴파일 임계치 등 보완. Garbage Collector(GC) Runtime Data Area중 Heap 영역에 더이상 사용하지 않고 자리만 차지하고 있는 객체들을 제거하는 역할. GC 수행하는 도안 GC 실행 쓰레드 외 모든 쓰레드가 일시정지. TODO : 추후 별도 포스트 3. Runtime Data AreaJVM이 프로그램을 수행하기 위해 운영체제로부터 할당받는 메모리 영역. 목적에 따라 5개의 영역으로 나뉘며 크게 두 가지로 분류됨.각 쓰레드별로 생성, 소멸되는 PC Register, JVM Stacks, Native Method Stack JVM 시작시 생성되며 종료시 소멸되는 Method Area, Heap. (모든 쓰레드간 자원 공유) PC Registers&lt;!– 우선 프로그램의 실행은 CPU에서 instruction을 수행함으로써 이루어지는데, 이 명령(instruction)은 더하기 빼기와 같은 opcode와 0개 이상의 피연산자 operand로 구성된다. 이러한 요소들을 임시로 저장하기 위한 CPU 내의 기억장치를 레지스터라고 하는데,JMV은 Stack-Base로 작동함. (non Register-Base). 즉 CPU에 직접 instruction 수행하지 않고 Stack에서 Operand를 뽑아내 Runtime Data Area의 PC register라는 별도 공간에 저장하는 방식을 취하고 있는 것.(?) –&gt;JVM은 여러 쓰레드의 동시 실행을 지원하는데, 각각의 쓰레드는 자신의 프로그램 카운터를 가지고 있음. 프로그램 카운터는 다음 번에 실행할 명령어 주소를 기억하는 레지스터. JVM 쓰레드는 어느 시점에서든 단일 메서드의 코드, 즉 해당 스레드의 현재 메서드를 실행함.(?) 만약 메서드가 native 하지 않다면, PC 레지스터는 실행중인 JVM 명령의 주소값을 저장한다. 쓰레드에서 수행되는 메서드가 native 하다면, JVM PC register의 값은 undefined가 저장된다. 또한 PC register는 복귀할 위치의 주소값 혹은 특정 플랫폼의 native pointer 저장할 수 있음. JVM StacksJVM 쓰레드는 각각이 private한 JVM stack을 가지고 있는데, 이곳에 primitive type의 데이터가 값과 같이 할당되고 Heap 영역에 있는 객체 데이터의 참조 값이 할당된다. 또한 메서드가 수행될 때마다 생성되며 메서드 수행 완료시 destroy됨(지역변수). Native Method StacksJava 외의 언어로 작성된 네이티브 코드를 위한 메모리 영역으로서, 보통 C/C++ 등의 코드를 수행하기 위한 스택. Java Native Interface(JNI)를 통해 바이트 코드로 전환해 저장함. Heap모든 JVM 쓰레드들이 공유하는 메모리 영역. heap은 클래스의 인스턴스 혹은 배열이 할당되는 run-time 메모리 영역. 객체 내부에는 클래스의 멤버(필드, 메서드, 이너 클래스. stack 영역에는 참조 값이 저장되었다면, Heap 영역에는 해당 참조값이 가리키는 실제 데이터가 저장됨)가 위치함. JVM이 시작될 때 생성되며 GC에 의해 관리됨. GC는 예측할 수 없으며 수행하는 시스템의 사양에 따라 동작. Method Area클래스, 메서드, 정적 필드와 정적 메서드, 상숫값이 저장됨. 이렇게 여러 데이터가 저장되기 때문에 Class Area, Static Area, Constant Area 같이 여러 이름으로 불림. Referencehttps://docs.oracle.com/javase/specs/jvms/se8/html/jvms-2.html#jvms-2.5.1" }, { "title": "제네릭", "url": "/posts/%EC%A0%9C%EB%84%A4%EB%A6%AD/", "categories": "Java", "tags": "generic", "date": "2022-05-25 00:00:00 +0900", "snippet": "제네릭 개인적으로 이해한 바로는 다형성 측면에서 효율적인 객체 및 메서드 설계를 위한 문법 요소라고 생각함. 컴파일시 강한 타입 체크를 통해 에러 사전 방지, 캐스팅 생략 등의 이점도 있음. 과일을 관리하는 객체 Fruit에 특정 과일을 저장한다고 했을 때, class Fruit{ Object f; //Constructor, Getter, Setter는 생략 } 여러 과일을 멤버로서 관리하기 위해서는 최상위 객체인 Object로 선언된 변수에 담는 방법이 있음. 하지만 이 방법의 문제점은, 저장 후 다시 꺼내올 때 캐스팅이 필요하며 저장된 객체의 구체적인 타입을 알고 있어야 하고, 약한 타입 체크로 인한 오류 발생 가능성 존재한다는 것이다. 제네릭 클래스 및 제네릭 인터페이스 문법 접근 지정자 class 클래스명&lt;T&gt; 접근 지정자 interface 인터페이스명&lt;T&gt; 제네릭 타입 변수의 관례적 표기 및 의미 제네릭 타입 변수 의미 T 타입 K 키 V 값 N 숫자 E 원소 제네릭 클래스의 객체 생성 클래스명&lt;실제 제네릭 타입&gt; 참조 변수명 = new 클래스명&lt;실제 제네릭 타입&gt;(); //제네릭 타입은 양쪽이 항상 동일하기 때문에 //뒤의 &lt;&gt; 안은 생략 가능. 이렇게 하면 클래스 정의 시점이 아닌 객체 생성시 타입을 지정할 수 있게 된다. &lt;&gt; 안의 제네릭 타입 변수 생략시엔 해당 변수에 올 수 있는 타입 중 최상위 클래스가 대입된다. (Object) A a = new A();와 A&lt;Object&gt; a = new A&lt;Object&gt;();는 동일한 의미.제네릭 메서드 클래스 말고 특정 메서드만 제네릭으로 선언할 수 있는데, 리턴 타입 또는 입력매개변수의 타입을 제네릭으로 선언 가능. 제네릭 클래스의 경우 객체를 생성하는 시점에 실제 타입을 지정했는데,제네릭 메서드는 호출되는 시점에 실제 제네릭 타입을 지정. 3가지 경우의 문법 구조 매개변수에만 제네릭 사용 : 접근지정자&lt;T&gt; void 메서드명(T t){ } 리턴 타입에만 제네릭 사용 : 접근지정자&lt;T&gt; T 메서드명(){ } 둘 다, 제네릭 2개 사용 : 접근 지정자&lt;T, V&gt; T 메서드명(T t, V v){ } 접근 지정자 &lt;제네릭 타입&gt; 리턴타입 메서드명(매개변수) 호출 문법 구조 참조 객체.&lt;실제 제네릭 타입&gt;메서드명(매개변수) 입력매개변수를 보고 제네릭 타입 변수의 실제 타입을 예측할 수 있다면 메서드 호출시 제네릭 타입 부분을 생략할 수 있다. 제네릭 타입 범위 제한 제네릭 메서드 내에서 매개변수로 전달된 객체의 메서드를 호출하고자 하는데,제네릭 메서드는 호출되는 시점에 실제 제네릭 타입이 지정되므로, 호출 전까지는 의도한 타입의 메서드를 호출할 수 없다. 제네릭 클래스의 경우도 객체가 생성되는 시점에 실제 제네릭 타입이 지정되므로 마찬가지 문제가 있다. 제네릭 타입의 범위를 제한(bound)하여 이러한 문제를 해결할 수 있다. 제네릭 클래스 타입 제한 문법 구조접근 지정자 class 클래스명&lt;T extends 최상위 클래스/인터페이스명&gt;{ } 제네릭 메서드의 타입 제한 문법 구조접근 지정자 &lt;T extends 최상위 클래스/인터페이스명&gt; T 메서드명(T t){ } 클래스, 인터페이스 상관없이 extends 사용.(implements X) 이렇게 하면 적어도 최상위 클래스/인터페이스의 멤버를 사용할 수 있게 된다. 메서드 매개변수인 제네릭 클래스의 타입 제한 리턴 타입 메서드 명(제네릭 클래스명&lt;? super 하위 클래스/인터페이스&gt; 참조 변수명) { } 리턴 타입 메서드 명(제네릭 클래스명&lt;? extends 상위 클래스/인터페이스&gt; 참조 변수명) { } 제네릭의 상속 제네릭 클래스의 상속 부모 클래스의 제네릭을 자식 클래스도 상속 받으며, 제네릭 타입 변수를 추가해 정의할 수도 있다. 따라서 자식 클래스의 제네릭 타입 변수는 항상 부모보다 많거나 같음. 제네릭 메서드의 상속 부모 클래스 내의 제네릭 메서드 또한 그대로 자식 클래스로 상속된다. Reference Do it! 자바 완전 정복" }, { "title": "Operator", "url": "/posts/operator/", "categories": "Java", "tags": "operator", "date": "2022-05-25 00:00:00 +0900", "snippet": "연산자 연산자의 종류 자료형 연산 기호 기능 결과 산술 연산자 +, -, *, /, % 사칙 연산 및 나머지 연산 값 증감 연산자 ++, – 값이 1씩 증가 또는 감소 값 비트 연산자 &amp;, |, ~, ^ 비트 AND, OR, NOT, XOR 값 시프트 연산자 &lt;&lt;, &gt;&gt;, &gt;&gt;&gt; 비트 단위의 이동 값 비교 연산자 &lt;, &gt;, &lt;=, &gt;=, !=, == 크기 비교 참 거짓 대입 연산자 =, +=, -=, *=, /=, &amp;=, |=, »=, «=, »&gt;= 산술 연산 결과의 대입(‘연산자’ + ‘=’의 축악 표현) 실행 삼항 연산자 (참 또는 거짓) ? x : y 참일때 x, 거짓일때 y 실행 비트 연산자 AND(&amp;), OR(|), XOR(^), NOT(~) &amp; : 두 값이 모두 1일 때만 1 | : 두 값이 모두 0일 때만 0 ^ : 두 값이 같을 때 0, 다를 때 1 ~ : 0은 1, 1은 0으로 반전하는 연산자(부호 비트 포함) 실제 비트 연산 수행시 최소 단위는 int(4byte = 32bit)임. 32자리. 값의 첫 번째 비트는 부호 비트로서 1 : 음수 0 : 양수. int a = 3; int b = 10; //앞의 0은 생략 //11 &amp; 1010 //0011 //1010 // a&amp;b : 10 =&gt; 2 // a|b : 1011 =&gt; 11 // a^b : 1001 =&gt; 9 // ~a : -4 시프트 연산자 비트의 위치를 좌우로 이동하는 연산자. 산술 시프트(&lt;&lt;, &gt;&gt;)와 논리 시프트( &gt;&gt;&gt; ) 산술 시프트 : 부호 비트는 유지하면서 나머지 비트를 왼쪽(«) 또는 오른쪽(»)으로 이동하는 연산자. 부호비트를 제외한 나머지 전체 비트가 왼쪽으로 1bit씩 이동할 때마다 ×2의 효과가, 오른쪽으로 이동할 때마다 ÷2의 효과가 있다. &gt;&gt; 의 경우 양수일 때에는 ÷2시 소수 버림. 음수일 때에는 소수 올림. 논리 시프트 : 부호 비트를 포함해 전체 비트를 오른쪽으로 이동. 나머지 빈칸은 모두 0으로 채움. 따라서 음수일 때 논리 시프트 이후에는 양수로 바뀜. " }, { "title": "이너 클래스와 이너 인터페이스", "url": "/posts/%EC%9D%B4%EB%84%88-%ED%81%B4%EB%9E%98%EC%8A%A4%EC%99%80-%EC%9D%B4%EB%84%88-%EC%9D%B8%ED%84%B0%ED%8E%98%EC%9D%B4%EC%8A%A4/", "categories": "Java", "tags": "innerclass", "date": "2022-05-18 00:00:00 +0900", "snippet": "이너 클래스이너클래스는 접근 지정자와 상관없이 아우터 클래스의 멤버를 사용할 수 있다는 점을 활용하기 위해 일반적으로 이너클래스를 사용한다.클래스 내부에 포함되는 이너 클래스는1. 인스턴스 멤버 이너 클래스2. 정적 멤버 이너 클래스3. 지역 이너 클래스로 나뉨.1과 2는 필드나 메서드처럼 클래스의 멤버인 반면,3은 메서드 내에서 정의되며, 지역 변수처럼 메서드 내부에서만 한정적으로 사용된다.1. 인스턴스 멤버 이너 클래스- 특징 인스턴스 멤버 이너 클래스(이하 이너클래스)는 아우터 클래스의 멤버로서, 컴파일시 아우터클래스$이너클래스.class 파일이 생성되며, 이너클래스는 독립적으로 사용할 수 없고 아우터 클래스를 통해서만 사용할 수 있음.- 객체 생성하기Outer outer = new Outer();Outer.Inner inner = outer.new Inner();//이너클래스의 자료형은 Inner가 아니라 Outer.Inner 임- 아우터 클래스 객체 참조하기. 이너클래스에서는 접근 지정자와 상관없이 모든 아우터 클래스의 멤버를 접근하여 사용할 수 있다. 이름이 같다면 이너 클래스의 변수를 참조하며(컴파일러는 참조 변수 없이 멤버를 사용하면 this. 을 붙임), 명시적으로 아우터 클래스를 참조하고자 한다면 아우터 클래스명.this.~을 통해 접근한다.2. 정적 멤버 이너 클래스static의 특성상 정적 멤버 이너 클래스(이하 이너 클래스)는 아우터 클래스의 정적 멤버만을 사용할 수 있다.- 객체 생성하기Outer.Inner inner = new Outer.Inner();3. 지역 이너 클래스 메서드 내에서 정의되는 클래스이기 때문에, 선언 이후 바로 객체를 생성해 사용한다. 메서드가 호출될 때 메모리에 로드되므로 지역 이너 클래스는 정적 클래스로 지정할 수 없음. 객체 생성은 클래스 정의 후 일반적인 방법으로 생성하면 된다.익명 이너 클래스정의된 위치에 따라 클래스의 중괄호 아래에 사용했을 때에는 인스턴스 익명 이너 클래스,메서드 내부에서 사용했을 때는 지역 익명 이너 클래스를 의미한다.정적 익명 이너 클래스는 존재할 수가 없음. 객체 생성 없이 클래스명만으로 사용하고자 하는게 static인데, 익명 이너 클래스는 이름이 없기 때문.일반적인 인터페이스 구현체와 익명 이너클래스public class test { interface A{ void abc(); } class B implements A{ @Override public void abc() { System.out.println(\"B implements A : b.abc()\"); } public void xyz(){ System.out.println(\"B implements A : b.xyz()\"); } } A a = new A(){ @Override public void abc() { System.out.println(\"anonymous Class a : a.abc()\"); } public void xyz(){ System.out.println(\"anonymous Class a : a.xyz()\"); } }; public static void main(String[] args) { test t = new test(); B b = t.new B(); b.abc(); // (O) b.xyz(); // (O) t.a.abc(); // (O) t.a.xyz(); // 선언한 A에 없는 메서드이므로 사용불가. }}익명 이너 클래스를 활용하여 인터페이스 타입의 매개변수 전달interface A{ void abc();}class B{ void abc(A a){ a.abc(); }}//일때, abc의 매개변수 a 전달하는 방법 4가지.B b = new B();//1.A a1 = new C(); //C는 abc를 override하여 사전에 정의하여야 함.b.abc(a1);//2.b.abc(new C());//3.A a3 = new A(){ public void abc(){ //... }};b.abc(a3);//4. 이벤트 처리시 많이 쓰는 형식.b.abc(new A(){ // ...}); 여러번 사용될 때에는 따로 정의하여 갖다 쓰는 것이 좋겠지만, 그것이 아니라면 굳이 클래스를 정의한 뒤 사용하는 수고를 할 필요 없이 곧바로 사용하는 것이 좋겠다.이너 인터페이스 한 클래스가 다른 클래스에 의존적인 기능을 수행할 때 인터페이스를 해당 클래스 내부에 정의하는 방법을 고려해볼 수 있다. 예를 들어 버튼 클릭시 버튼 클릭을 감지하는 인터페이스는 버튼 클래스 내부에 위치하는 것이 적절해 보인다.(이처럼 이벤트 감지를 위한 인터페이스를 리스너라고 함.) 특징 이너 인터페이스는 정적 이너 인터페이스만 존재할 수 있으며, static 생략시 컴파일러가 자동으로 추가한다.class A{ //... static interface B{ void bcd(); }} 이너 인터페이스도 인터페이스이기 때문에 자체적으로 객체 생성은 불가. 이너 인터페이스 구현체를 정의하여 사용하거나, 익명 이너클래스를 활용한다. 객체 타입은 아우터 클래스명.이너 인터페이스명이다. 이벤트 처리 예제 class Button{ OnClickListener ocl; void setOnClickListener(OnClickListener ocl){ this.ocl = ocl; } static interface OnClickListener{ void onClick(); } void click(){ ocl.onClick(); } } class test{ public static void main(String[] args){ Button btn1 = new Button(); btn1.setOnClickListener(new Button.OnClickListener(){ @Override public void onClick(){ System.out.println(\"btn1 클릭\"); } }); //with lambda //btn1.setOnClickListener(() -&gt; System.out.println(\"btn1 클릭\")); btn1.click(); } }" }, { "title": "Spring Web Mvc", "url": "/posts/Spring-Web-MVC/", "categories": "Spring, MVC", "tags": "spring, springmvc", "date": "2022-05-18 00:00:00 +0900", "snippet": " Spring Web MVC 1.1 DispatchServlet DispatcherServlet은 다른 Servlet처럼 Java config 혹은 web.xml을 통해 선언되고 mapping 되어야 한다. 차례로 DispatcherServlet은 요청 매핑, 뷰 결정, 예외 처리 등등을 위해 필요한 위임 요소들을 찾기 위해 스프링 설정을 이용한다. DispatcherServlet의 등록 및 초기화를 위한 Java config 예제 public class MyWebApplicationInitializer implements WebApplicationInitializer{ @Override public void onStartup(ServletContext servletContext){ // Load Spring web application configuration AnnotationConfigWebApplicationContext context = new AnnotationConfigWebApplicationContext(); context.register(AppConfig.class); // Create and register the DispatcherServlet DispatcherServlet servlet = new DispatcherServlet(context); ServletRegistration.Dynamic registration = servletContext.addServlet(\"app\", servlet); registration.setLoadOnStartup(1); registration.addMapping(\"/app/*\"); } } 게다가 ServletContext API를 사용함으로써, AbstractAnnotationConfigDispatcherServletInitializer를 상속받고 특정 메서드들을 오버라이드 할 수 있다. 프로그래밍적인 사용 사례의 경우에는(?), GenericWebApplicationContext이 AbstractAnnotationConfigDispatcherServletInitializer의 대안이 될 수 있다. DispatcherServlet의 등록 및 초기화를 위한 web.xml 설정 예제 &lt;web-app&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;/WEB-INF/app-context.xml&lt;/param-value&gt; &lt;/context-param&gt; &lt;servlet&gt; &lt;servlet-name&gt;app&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;app&lt;/servlet-name&gt; &lt;url-pattern&gt;/app/*&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;/web-app&gt; 스프링부트는 다른 초기화 과정을 따르는데, 서블릿 컨테이너의 라이프사이클보다는 스프링 configuration을 사용하여 자기자신과 내장 서블릿 컨테이너를 등록한다. 1.1.1 Context Hierarchy DispatcherServlet은 WebApplicationContext를 자신의 설정으로 간주한다. 하나의 WebApplicationContext를 사용할 수도 있고, root WebApplicationContext를 공유하고 각각 자신의 WebApplicationContext 설정을 가진 DispatcherServlet들에게 공유시킬 수도 있다. root WebApplicationContext는 주로 data repository, business service와 같이 여러 servlet 인스턴스들에게 공유될 기초적(기반적) bean들을 포함하고 있다. WebApplicationContext 계층구조 설정 예제 Java방식 public class MyWebAppInitializer extends AbstractAnnotationConfigDispatcherServletInitializer { @Override protected Class&lt;?&gt;[] getRootConfigClasses() { return new Class&lt;?&gt;[] { RootConfig.class }; } @Override protected Class&lt;?&gt;[] getServletConfigClasses() { return new Class&lt;?&gt;[] { App1Config.class }; } @Override protected String[] getServletMappings() { return new String[] { \"/app1/*\" }; } } xml방식 &lt;web-app&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;/WEB-INF/root-context.xml&lt;/param-value&gt; &lt;/context-param&gt; &lt;servlet&gt; &lt;servlet-name&gt;app1&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;/WEB-INF/app1-context.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;app1&lt;/servlet-name&gt; &lt;url-pattern&gt;/app1/*&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;/web-app&gt; 계층구조가 필요 없다면 java설정의 경우에는 getRootConfigClasses()를 통해 모든 설정을 받고 getServletConfigClasses()는 null을 리턴하도록 할 수 있으며, xml 설정의 경우에는 root context만 사용하고 contextConfigLocation을 비워두도록 한다. //TODO..정리필요 1.1.2 Special Bean Types link 1.1.3 Web MVC Config 애플리케이션은 상기한 Special Bean Types에 있는, 요청을 처리하는데 있어서 필요한 구조적 Bean들을 선언할 수 있다. DispatcherServlet은 WebApplicationContext에서 각각의 special bean을 확인한다. 만약 일치하는 bean type이 없다면, DispatcherServlet.properties에 있는 default types로 돌아온다. 대부분의 경우, MVC Config는 최고의 시작점이다. Java 혹은 XML에 필요한 bean들을 선언하고, 상위 수준의 설정 callback API을 커스터마이즈 할 수 있게 한다. 스프링부트에서는 Java bean 설정을 사용하며 추가적인 여러 편의성 옵션들을 제공한다. 1.1.4 Servlet Config Servlet3.0 이상의 환경에서, 서블릿 컨테이너를 web.xml 대신 프로그래밍적으로(자바 빈을 말하는듯) 구성할지, web.xml과 같이 할지를 선택할 수 있음. 다음은 DispatcherServlet을 등록하는 예제임. import org.springframework.web.WebApplicationInitializer; public class MyWebApplicationInitializer implements WebApplicationInitializer{ @Override public void onStartup(ServletContext container){ XmlWebApplicationContext context = new XmlWebApplicationContext(); context.setConfigLocation(\"/WEB-INF/spring/dispatcher-config.xml\"); ServletRegistration.Dynamic registration = container.addServlet(\"dispatcher\", new registration.setLoadOnStartup(1)); registration.addMapping(\"/\"); } } WebApplicationInitializer는 Spring MVC에서 지원하는 인터페이스로서, 당신의 구현체들이 탐지되고 서블릿 컨테이너의 초기화에 자동적으로 사용된다는 것을 보증합니다. WebApplicationInitializer의 디폴트 구현체인 AbstractDispatcherServletInitializer는 서블릿 매핑과 디스패쳐 서블릿의 위치를 특정하는 메서드를 오버라이딩 함으로써 디스패쳐 서블릿을 좀 더 손쉽게 등록할 수 있도록 해줍니다. 다음은 추천하는 자바 빈 기반의 설정 방식의 예 입니다. public class MyWebInitializer extends AbstractAnnotationConfigDispatcherServletInitializer{ @Override protected Class&lt;?&gt;[] getRootConfigClasses() { return null; } @Override protected Class&lt;?&gt;[] getServletConfigClasses() { return new Class&lt;?&gt;[] { MyWebConfig.class }; } @Override protected String[] getServletMappings() { return new String[] { \"/\" }; } } 만약 당신이 XML 기반의 스프링 설정을 사용하고 있다면, 다음처럼 AbstractDispatcherServletInitializer를 직접적으로 상속받으세요. public class MyWebAppInitializer extends AbstractDispatcherServletInitializer { @Override protected WebApplicationContext createRootApplicationContext() { return null; } @Override protected WebApplicationContext createServletApplicationContext() { XmlWebApplicationContext cxt = new XmlWebApplicationContext(); cxt.setConfigLocation(\"/WEB-INF/spring/dispatcher-config.xml\"); return cxt; } @Override protected String[] getServletMappings() { return new String[] { \"/\" }; } } 또한 AbstractDispatcherServletInitializer는 Filter 인스턴스들을 DispatcherServlet에 자동적으로 매핑될 수 있도록 편리한 방법을 제공하는데, 다음이 그 예시입니다. public class MyWebAppInitializer extends AbstractDispatcherServletInitializer { // ... @Override protected Filter[] getServletFilters() { return new Filter[] { new HiddenHttpMethodFilter(), new CharacterEncodingFilter() }; } } 각각의 필터는 그것의 구체적인 타입을 기반으로 한 이름으로 등록되고, 자동적으로 DispatcherServlet에 매핑됩니다. AbstractDispaterServletInitializer의 protected method isAsyncSupported는 비동기적인 지원을 가능하게 하는 단일 공간(?)을 DispatcherServlet에게 제공하며, 모든 필터들이 매핑됩니다. zero config는 true. 마지막으로, DispatcherServlet을 커스터마이즈 할 필요가 있다면 createDispatcherServlet 메서드를 오버라이드 하세요. Referencehttps://docs.spring.io/spring-framework/docs/5.3.19/reference/html/web.html#mvc" }, { "title": "순서도", "url": "/posts/%EC%88%9C%EC%84%9C%EB%8F%84/", "categories": "algoritm", "tags": "flowchart", "date": "2022-05-16 00:00:00 +0900", "snippet": " 순서도 기호 Referencehttps://booksr.tistory.com/13" }, { "title": "Printf", "url": "/posts/printf/", "categories": "Java", "tags": "printf", "date": "2022-05-16 00:00:00 +0900", "snippet": "출력 서식%[-][0][n][.m]지시자 출력 서식의 지시자를 제외한 나머지는 모두 생략 가능. - : 전체자리수가 지정된 경우 왼쪽 정렬하고 빈칸에 공백 출력 0 : 전체자리수가 지정된 경우 왼쪽의 남는 자리에 0을 출력 n : 출력할 전체 자리 수 지정(미지정 : 왼쪽정렬, 지정 : 오른쪽 정렬) .m : 소수점아래 자리수 지정. 잘리는 소수점 자리수는 반올림. 문자열의 경우에는 n만큼의 자리를 확보하고 m개의 문자를 우측 정렬 형태로 출력한다.지시자 지시자 설명 %b boolean 형식 출력 %d 정수 형식 출력 %o 8진수 정수 %x \\| %X 16진수 정수 %f 소수점 %c 문자 %s 문자열 %n 개행 %e \\| %E 지수 표현식 " }, { "title": "Algoritm", "url": "/posts/algoritm/", "categories": "algoritm", "tags": "", "date": "2022-05-16 00:00:00 +0900", "snippet": "Ch01. 기본 알고리즘 구조적 프로그래밍(Structured Programming) 하나의 입구와 하나의 출구를 가진 구성 요소만을 계층적으로 배치하여 프로그램을 구성하는 방식 제어 흐름 : 순차, 선택, 반복 드모르간 법칙 각 조건을 부정하고 논리곱(AND)을 논리합(OR)으로, 논리합을 논리곱으로 바꾸고 다시 전체를 부정하면 원래의 조건과 같다는 법칙 Ch02. 기본 자료구조 다차원 배열 clone : 최상위의 1레벨만 수행하며, 그 아래 레벨의 배열은 참조를 공유한다.Ch03. 검색03-1 검색 알고리즘TODO 선형 검색 : 무작위로 늘어놓은 데이터 집합에서 검색 수행. 이진 검색 : 일정한 규칙으로 늘어놓은 데이터 집합에서 아주 빠른 검색 수행. 해시법 : 추가, 삭제가 자주 일어나는 데이터 집합에서 아주 빠른 검색 수행.    - 체인법 : 같은 해시 값의 데이터를 선형 리스트로 연결하는 방법    - 오픈 주소법 : 데이터를 위한 해시 값이 충돌할 때 재해시 하는 방법 데이터의 집합에 대한 검색, 추가, 삭제 등의 작업에 소요되는 비용을 종합적으로 판단하여 알고리즘 선택해야 한다.03-2 선형 검색(linear search) 직선으로 늘어선 요소들에 대해 검색을 할 때, 원하는 요소를 찾을 때까지 맨 앞부터 순차적으로 검색. 선형 검색(linear search), 순차 검색 알고리즘(sequential search) 검색 종료 조건 검색 값을 발견하지 못하고 배열의 끝을 지나간 경우 검색할 값과 같은 요소를 발견한 경우 //선형 검색 while static int seqSearchW(int[] arr, int n, int key){ while(true){ if(i == n) return -1; if(a[i]==key) return i; i++; } } static int seqSearchF(int[] arr, int n, int key){ for(int i=0; i&lt;n; i++){ if(a[i] == key) return i; return -1; } } 보초법 선형 검색은 검색시 상기의 종료 조건 1, 2를 모두 판단하는데, 이 과정에서 소요되는 비용을 반으로 줄이는 방법. 검색하고자 하는 요소값을 배열의 맨 마지막 요소로 넣는다. 이렇게 하면 종료조건 1을 무시하고 2만 판단하면 됨. 즉, 보초법은 반복이 종료되는 조건에 해당하는 값을 이용해 둘의 종료 조건을 하나로 줄이는 것에 의미가 있음. static int seqSearchSen(int[] arr, int n, int key){ int i=0; a[n] = key; while(true){ if(a[i] == key) break; i++; } return i == n ? -1 : i;} TODO 판단 횟수 : 배열의 요솟수가 n개라면 평균 n/2회. 원하는 값이 배열에 존재하지 않는 경우 조건 1은 n+1, 2는 n회03-3 이진 검색(binary search) 데이터가 키 값으로 이미 정렬되어 있어야 한다. 오름차순 혹은 내림차순으로 정렬된 배열에서 검색하는 알고리즘. linear search보다 검색이 좀 더 빠르다. 검색방식 정렬된 배열의 정중앙 요소부터 검색을 시작한다. 해당 요소와 검색할 요소의 크기를 비교함으로써 범위가 반으로 줄어든다. 오름차순으로 정렬된 배열을 기준으로, 검색 범위의 맨 앞 인덱스를 L, 맨 끝 인덱스를 R, 중앙을 C라고 할 때, n개의 요소를 가진 배열의 검색 시작시 L 은 0, R은 n-1, C는 (n-1)/2로 초기화 되며 배열[C] &gt; key일때 검색 대상은 왼쪽 영역에 있는 것이 분명하므로, 배열[L] ~ 배열[C-1] 로 검색범위를 좁히며 R은 C-1로 업데이트 됨. 반대로 배열[C] &lt; key일때 검색범위는 배열[C+1] ~ 배열[R], L은 C+1 해당 과정을 반복한다. 검색 대상이 2개로 좁혀졌을 때에는 둘 중 앞의 값을 선택한다. 검색 종료 조건 조건 1 : 배열[C]와 key가 일치하는 경우 조건 2 : 검색 범위가 더이상 없는 경우 ex) L이 R보다 커지는 경우 혹은 R이 L보다 작아지는 경우 비교횟수 평균값 : log n 검색 실패시 log(n+1)회, 성공시 log n-1 회. static int binarySearch(int[] arr, int n, int key){ int l = 0; int r = n-1; do{ int c = (l + r)/2; if(arr[c] == key) return c else if(arr[c] &lt; key) l = c + 1; else r = c - 1; }while(l &lt;= r); return -1;} 복잡도 알고리즘의 성능을 객관적으로 평가하는 기준으로서 시간 복잡도(실행에 필요한 시간)와공간 복잡도(기억 영역과 파일 공간이 얼마나 필요한가) 두 가지 요소 지님. 시간 복잡도 단순히 값을 반환, 대입하는 일회성 실행의 경우에는 O(1)로 표기 실행 횟수가 비례하여 증가하는 경우에는 복잡도를 O(n)으로 표기. O(f(n))과 O(g(n))의 복잡도 계산 방법 O(f(n)) + O(g(n)) = O(max(f(n), g(n))) max(a, b)는 a와 b가운데 큰 쪽을 나타내는 메서드. for문을 이용한 선형 검색 코드를 기준으로 시간 복잡도를 나타내보면, int i를 선언하고 할당하는 부분은 한 번만 수행되므로 O(1) 대소 비교 부분의 평균 실행 횟수는 n/2 증가 연산자도 n/2 a[i] == key 부분도 n/2 i 리턴은 한 번만 수행되므로 O(1) 검색 실패시 -1 리턴은 한 번만 수행되므로 O(1) 컴퓨터에게 n/2나 n이나 차이 없으므로 O(1) + O(n) + O(n) + O(1) + O(n) + O(1) = O(max(1, n, n, 1, n, 1)) = O(n) Arrays.binarySearch에 의한 이진 검색 java.util.Array 클래스의 binarySearch 메서드는 오름차순으로 정렬된 배열 a를 가정하고, 키 값이 key인 요소를 이진검색 함. 자료형에 따라 오버로딩 되어있음. 타입 : byte[], char[], double[], float[], int[], long[], short[], Object[], 제네릭 검색 성공시 key와 일치하는 요소의 인덱스를 리턴하는데, 여러개일 경우 무작위 인덱스 반환. 검색 실패시 삽입 포인트(key보다 큰 요소 중 첫 번째 요소의 인덱스)를 x라고 했을 때, -x-1 반환. 객체의 배열에서 검색 static int binarySearch(Object[] a, Object key) 자연 정렬이라는 방법으로 요소의 대소 관계를 판단. 정수 배열, 문자열 배열에서 검색시 적절. 자연 정렬과 문자열 정렬 문자열 정렬은 동일한 위치에 있는 문자의 대소 비교를 통해 정렬한다. 문자열 정렬 자연 정렬 텍스트1.txt 텍스트1.txt 텍스트10.txt 텍스트2.txt 텍스트100txt 텍스트10.txt 텍스트2.txt 텍스트21.txt 텍스트21.txt 텍스트100.txt static &lt;T&gt; int binarySearch(T[] a, T key, Comparator&lt;? super T&gt; c) 자연 순서가 아닌 순서로 줄지어 있는 배열에서 검색하거나 자연 순서를 논리적으로 갖지 않는 클래스 배열에서 검색할 때 적절. Comparator : 클래스 T(또는 클래스 T의 슈퍼 클래스)로 생성한 두 객체의 대소 관계를 판단하기 위한 인터페이스. compare 메서드를 구현해 사용한다. public foo implements Comparator&lt;T&gt;{ int compare(T o1, T o2){ if(o1 &gt; o2) return 양수; if(o1 &lt; o2) return 음수; if(o1 == o2) return 0; } boolean equals(Object obj){ //... }} Ch04. 스택과 큐04-1. 스택 LIFO(Last In First Out) 스택에 데이터를 넣는 push와 데이터를 꺼내는 pop push와 pop을 하는 위치를 꼭대기(top)이라고 하고, 스택의 가장 아랫 부분은 바닥(bottom)이라고 함. 자바에서는 메서드의 호출과 실행시 스택을 사용함. 다음은 메서드 호출 및 실행과정. void x(){} void y(){} void z(){ x(); y(); } void main(){ z(); } push : main push : z push : x pop : x push : y pop : y pop : z pop : main 스택 만들기 class MyStack&lt;E&gt;{ private int max; //스택 용량 private int ptr; //스택 포인터 private E[] stk; //스택 본체 public MyStack(int capacity) { ptr = 0; max = capacity; try{ stk = (E[])new Object[max]; }catch (OutOfMemoryError e){ max = 0; } } //push 메서드 public E push(int x){ if(ptr &gt;= max) throw new OverflowMyStackException(); return stk[ptr++] = x; } //pop 메서드 public int pop(){ if(ptr &lt;= 0) throw new EmptyMyStackException(); return stk[--ptr]; } //peek 메서드 public E peek(){ if(ptr &lt;=0 ) throw new EmptyMyStackException(); return stk[ptr - 1]; } //indexOf 메서드 (top to bottom 선형 검색 수행) public int indexOf(E x){ for(int i=0; i&lt;ptr; i++){ if(stk[i].equals(x)) return i; } return -1; } //clear 메서드 //스택의 모든 작업들은 스택 포인터(ptr)을 이용하여 이루어지기 때문에, //스택의 요솟값을 변경할 필요가 없다. public void clear(){ ptr = 0; } //capacity 메서드 public int capacity(){ return max; } //size 메서드 public int size(){ return ptr-1; } //IsEmpty 메서드 public boolean IsEmpty(){ return ptr &lt;= 0; } //IsFull 메서드 public boolean IsFull(){ return ptr &gt;= max; } //dump 메서드 (스택의 모든 데이터 표시) public void dump(){ if(ptr &lt;= 0) System.out.println(\"스택이 비어있음.\"); else{ for(int i=0; i&lt;ptr; i++){ System.out.println(stk[i] + \" \"); } System.out.println(); } } } class EmptyMyStackException extends RuntimeException{ public EmptyMyStackException() { } } class OverflowMyStackException extends RuntimeException{ public OverflowMyStackException() { } }04-2. 큐 FIFO(First In First Out) 큐에 데이터를 넣는 인큐(enqueue), 데이터를 꺼내는 디큐(dequeue), 데이터를 꺼내는 쪽인 프런트(front), 데이터를 넣는 쪽인 리어(rear) 인큐의 경우 복잡도는 O(1), 디큐의 경우 복잡도는 O(n). 데이터를 꺼내고 다음 두 번째 요소부터 이후의 요소를 모두 앞으로 옮겨야 하기 때문. 링 버퍼(배열 요소를 앞으로 옮기지 않도록 하는 큐) 이용시에는 디큐시에도 복잡도 O(1) 배열을 이용해 큐 구현//해당 예제는 dequeue시 앞으로 옮기는 작업 없도록 구현.(링버퍼) public class MyQueue&lt;E&gt;{ private int max; //큐의 용량 private int front; //맨 앞의 커서 private int rear; //맨 뒤의 커서 private int num; //현재의 데이터 수 private E[] que; //큐의 본체 class EmptyMyQueueException extends RuntimeException{ public EmptyMyQueueException(){} } class OverflowMyQueueException extends RuntimeException{ public OverflowMyQueueException(){} } public MyQueue(int capacity){ num = front = rear = 0; max = capacity; try{ que = (E[])new Object[max]; }catch(OutofMemoryError e){ max = 0; } } public E enqueue(E e){ if(num &gt;= max) throw new OverflowMyQueueException(); que[rear++] = e; num++; if(rear == max) rear = 0; return e; } public E dequeue(){ if(num&lt;=0) throw new EmptyMyQueueException(); E e = que[front++]; num--; if(front == max) front = 0; return e; } //큐에서 데이터를 피크 public E peek(){ if(num&lt;=0) throw new EmptyMyQueueException(); return que[front]; } //indexOf public int indexOf(E e){ for(int i=0; i&lt;num; i++){ int idx = (i + front) % max; if(que[idx].equals(e)) return idx; //검색 성공 } return -1; //검색 실패 } //clear public void clear(){ num = front = rear = 0; } //capacity public int capacity(){ return max; } //size public int size(){ return num; } //isEmpty public boolean isEmpty(){ return num&lt;=0; } //isFull public boolean isFull(){ return num &gt;= max; } //dump public void dump(){ if(num&lt;=0) System.out.println(\"큐가 비었습니다.\"); else{ for(int i=0; i&lt;num; i++) System.out.print(que[(i+front)%max] + \" \"); System.out.println(); } } //search public int search(E e){ for(int i=0; i&lt;num; i++){ if(que[(i + front) % max].equals(e)) return i+1; } return 0; } }Ch05. 재귀 알고리즘05-1. 재귀의 기본 재귀란? 어떤 사건이 자기 자신을 포함하고, 다시 자기 자신을 사용하여 정의되는 것을 의미함. 재귀의 특징을 이용하여 어떠한 문제가 있을 경우 해당 문제를 부분적으로 쪼개 해결하는 것이 가능함. 1부터 n까지의 곱을 구해야 하는 경우(팩토리얼), 4!은 4 * 3!이므로 n!은 n*(n-1)!과 같다. 이런 식으로 수학에서의 귀납법 원리를 이용하여 문제를 해결할 수 있다. 재귀 알고리즘의 이해를 위해선 선언형 프로그래밍과 명령형 프로그래밍의 차이를 이해하는 것이 필요. 우선 명령형 프로그래밍은 알고리즘을 명시하고 목표를 명시하지 않음. 하지만 선언형 프로그래밍은 목표를 명시하고 알고리즘은 명시하지 않음. 목표를 명시한다는 것은 문제를 명확하게 정의하고 적절한 종료조건이 설정되어야 한다는 것. 예를 들어서 팩토리얼 함수를 구현할 때, 명령형 프로그래밍에 의하면 어떠한 값이 나오는지가 아니라, n부터 1까지를 곱하는 알고리즘을 작성하게 되고, 선언형 프로그래밍에 따르면 n의 팩토리얼은 n이 1일때 종료되며 n!은 n*(n-1)!으로 문제를 정의하게 됨. 예시(팩토리얼) public class factorial{ public int NFactorial(int n){ if(n &gt; 0) n*NFactorial(n-1); //재귀 호출. else return 1; }} 직접 재귀와 간접 재귀 위의 예시처럼 자신과 같은 메서드를 호출하면 직접 재귀, 다른 메서드를 거쳐 다시 자신을 호출하게 되면 간접재귀.(ex. a에서 b를 호출하고 b에서 다시 a를 호출) 유클리드 호제법 최대공약수를 구하는 알고리즘. 두 정수가 있을 때, 큰 값을 작은 값으로 나누어 떨어지는 가장 작은 값. 호제법이란 말은 두 수가 서로 상대방 수를 나누어 원하는 수를 얻는 알고리즘을 의미함. 2개의 자연수 a, b에 대해 a를 b로 나눈 나머지를 r이라 하면(단, a&gt;b) a와 b의 최대 공약수는 b와 r의 최대 공약수와 같음. 이러한 성질에 따라 다시 b를 r로 나눈 나머지 r1을 구하고, 다시 r을 r1으로 나눈 나머지를 구하는 과정을 반복해 나머지가 0이 되었을 때 나누는 수가 a와 b의 최대 공약수이다. ex1) 22와 8 22 % 8 = 6 8 % 6 = 2 6 % 2 = 0 최대 공약수는 마지막에 나눈 수인 2 ex2) 1071과 1029 1071 % 1029 = 42 1029 % 42 = 21 42 % 21 = 0 최대 공약수는 마지막에 나눈 수인 21 이를 메서드로 구현해보면, int gcd(int a, int b){ if(b == 0) return a; else return gcd(b, a%b); } //세 개 이상 수의 최대공약수 구하기 int gcd(int a, int b){ if(a%b == 0) return b; else return gcd(b, a%b); } int arrGcd(int[] arr, int start){ if(start == arr.length) return arr[start-1]; return gcd(arr[start], arrGcd(arr, start+1)); } 05-2. 재귀 알고리즘 분석 하향식 분석 가장 위쪽에 위치한 상자의 메서드 호출부터 시작해 계단식으로 자세히 조사하는 분석 기법. 처음 호출부터 스택을 쌓아가는 식 상향식 분석 아래쪽부터 쌓아 올리며 분석하는 방법. 실행 결과를 합쳐나가는 느낌. 재귀 알고리즘의 비재귀적 표현 재귀 함수 호출은 context switching으로 인한 오버헤드, 시스템 부하 등의 문제 발생 가능. 따라서 최종 최적화 단계에서는 대체로 비재귀적으로 변경. TODO //재귀static void recur1(int n){ if(n&gt;0){ recur1(n-1); //n을 n-1로 업데이트하고 메서드 재실행한다는 의미를 가짐. //단, 다음 행에서 n을 그대로 출력해야 하므로 값을 임시로 저장해야 함. //또한 n을 출력하기 전에 recur1(n-1)부터 실행해야 함. //이러한 문제 해결에 효과적인 데이터 구조가 Stack. System.out.println(n); recur1(n-2); //n을 n-2로 업데이트하고 메서드 재실행한다는 의미를 가짐. }}static void recur2(int n){ if(n&gt;0){ recur2(n-1); recur2(n-2); System.out.println(n); }}//====================================================================================//비재귀class IntStack{ private int max; private int ptr; private int[] stk; public IntStack(int capacity){ this.max = capacity; stk = new int[capacity]; } //pop, push 등 구현 생략...}static void recur1_1(int n){ IntStack s = new IntStack(n); while(true){ if(n&gt;0){ s.push(n); //출력 전에 n-1로 업데이트된 상태에서 재귀호출 해야함. -&gt; coninue //recur(n-1)은 n = n-1; continue;과 같음. n = n-1; continue; } if(s.isEmpty() != true){ n = s.pop(); System.out.println(n); //아래에선(꼬리재귀) recur(n-2)은 n = n-2; continue;과 같음. n = n-2; continue; } break; }} //TODO .. static void recur2_1(int n){ int[] nstk = new int[100]; int[] sstk = new int[100]; int ptr = -1; int sw = 0; while(true){ if(n&gt;0){ ptr++; nstk[ptr] = n; sstk[ptr] = sw; if(sw == 0){ n = n-1; }else if(sw == 1){ n = n-2; sw = 0; } continue; } do{ n = nstk[ptr]; sw = sstk[ptr--]+1; if(sw == 2){ System.out.println(n); if(ptr&lt;0) return; } }while(sw == 2); }} 05-3. 하노이의 탑 문제 정의 : 원반 1부터 n-1까지 겹친 상태를 하나의 그룹으로 보고, 원반 n을 시작 기둥에서 목표 기둥으로 옮긴 후, 나머지 그룹을 중간 기둥에서 목표 기둥으로 옮긴다. 단, 원반이 한개인 경우는 목표 기둥으로 곧바로 옮긴다. 종료 조건 : n이 1일때는 자기 자신을 호출할 필요 없다. 목표 기둥으로 곧바로 옮기면 된다. 실행 횟수 : n-1개의 원반을 옮기는 경우 실행 횟수를 A라고 했을 때, 1부터 n-1까지의 원반 그룹을 중간 기둥으로 옮기는 횟수 A회, n번째 원반을 목표 기둥으로 옮기는 횟수 1회, 1부터 n-1까지의 원반 그룹을 목표 기둥으로 옮기는 횟수 A회로 총 2A+1회이다. class Hanoi{//재귀public static void move(int n, int x, int y){ if(n &gt; 1) //기둥을 정수 1, 2, 3으로 표현했을 때, 중간 기둥은 목표 기둥과 시작 기둥을 제외한 나머지. move(n-1, x, 6-x-y); System.out.println(\"원반[\"+ n +\"]을\" + x + \"기둥에서 \"+ y + \"기둥으로 옮김.\"); if(n &gt; 1) move(n-1, 6-x-y, y); } //비재귀 public static void move_1(int n, int x, int y){ int[] xstk = new int[50]; int[] ystk = new int[50]; int[] sstk = new int[50]; int ptr = 0; //스택 포인터 int sw = 0; while(true){ if(sw==0 &amp;&amp; n&gt;1){ xstk[ptr] = x; ystk[ptr] = y; sstk[ptr] = sw; ptr++; n -= 1; y = 6 - x - y; continue; } System.out.printf(\"%d 원반을 %d 기둥에서 %d 기둥으로 옮김.\\n\", n, x, y); if(sw==1 &amp;&amp; n&gt;1){ xstk[ptr] = x; ystk[ptr] = y; sstk[ptr] = sw; ptr++; n -= 1; x = 6 - x - y; if(++sw == 2) sw = 0; continue; } do{ if(ptr-- == 0) return; x = xstk[ptr]; y = ystk[ptr]; sw = sstk[ptr]+1; n++; }while(sw == 2); }}} 05-4. 8퀸 문제 8 * 8의 체스판에서 퀸이 서로를 공격해 잡을 수 없도록 배치하는 문제이다. 1단계, 2단계, 3단계로 나누어 해결해본다. public class EightQueen{ static int[] pos = new int[8]; static boolean flag_a = new boolean[8]; static boolean flag_b = new boolean[15]; static boolean flag_c = new boolean[15]; static void print(){ for(int i=0; i&lt;8; i++){ System.out.printf(\"%2d\", i); } System.out.println(); } /* 1단계. 각 열에 퀸을 1개만 배치한다. 총 경우의 수 : 8^8 = 16,777,216*/ static void setPos_1(int i){ for(int j=0; j&lt;8; j++){ pos[i] = j; //퀸을 i열의 j행에 배치한다. if(i == 7) print(); //재귀호출을 반복하다가 i가 7이 되고, //이는 8개의 퀸이 모두 배치된다는 것을 의미. else setPos_1(i+1);//다음 열에 퀸을 배치한다. } } /* 2단계. 1단계에서 각 행에 퀸을 1개만 배치한다. 즉, 각 퀸은 모두 다른 행과 열에 배치되어야 한다. 이는 boolean 배열인 flag_a를 이용한다. flag[j]는 j행에 퀸 배치여부를 관리한다. 각 열에서 퀸이 배치되면, 고려해야 할 행이 하나씩 줄어드는 것이므로 총 경우의 수 : 8! = 40320 */ static void setPos_2(int i){ for(int j=0; j&lt;8; j++){ if(!flag_a[j]){ //j행에 퀸이 배치되지 않은 경우만 고려한다. pos[i] = j; if(i == 7) print(); else{ flag_a[j] = true; //8열을 제외한 나머지 열에서 //j행에 퀸을 배치하였으므로 true로 바꿔준다. //이렇게 하면 8열에서 loop문을 돌 때, j행은 고려하지 않는다. setPos_2(i+1); flag_a[j] = false;//재귀 호출한 setPos_2(i+1)메서드의 실행이 끝나면 //퀸의 배치를 옮겨서 다시 경우를 따지므로 false로 바꿔준다. } } } } /* 3단계. 마지막으로, 퀸은 대각선으로도 공격할 수 있으므로 배치하는 퀸의 우상향, 우하향 대각선 상에 다른 퀸이 존재하지 않아야 한다는 조건 추가 flag_b와 flag_c는 각각 우상향, 우하향 대각선에 퀸 배치여부를 관리한다. b의 경우 우상향인데, 체스판에 대각선을 그어 0부터 14까지 넘버링을 하고, i+j로 해당 위치를 구할 수 있다. c의 경우 우하향인데 i - j + 7으로 구할 수 있다. 실행횟수 : 92 */ static void setPos_3(int i){ for(int j=0; j&lt;8; j++){ //2단계에서 조건만 추가되었다. if(!flag_a[i] &amp;&amp; !flag_b[i+j] &amp;&amp; !flag_c[i-j+7]){ pos[i] = j; if(i == 7) print(); else{ flag_a[i] = flag_b[i+j] = flag_c[i-j+7] = true setPos_3(i+1); flag_a[i] = flag_b[i+j] = flag_c[i-j+7] = false } } } }} Ch06. 정렬06-1. 정렬 핵심 항목의 대소 관계에 따라 데이터 집합을 일정한 순서로 줄지어 늘어서도록 바꾸는 작업으로서 정렬 알고리즘은 교환, 선택, 삽입의 세 가지 핵심 요소 가짐. 정렬의 안정성 안정성은 같은 값의 키를 가진 요소의 순서가 정렬 전후에도 유지되는지 여부를 기준으로 판단. 06-2. 버블 정렬 이웃한 두 요소의 대소 관계를 비교하여 교환을 반복하는 방법. n개의 요소를 가진 배열의 경우 첫번째 패스에서는 n - 1회 비교, k번째 패스에서는 n - k회 비교. 모든 정렬이 끝나려면 패스는 n - 1회 수행되어야 함. 패스를 k회 수행하면 앞 or 뒤의 요소 k개가 정렬된 상태가 됨. 비교 횟수는 (n-1)회 + (n-2)회 + … + 1 = n*(n-1)/2회. 교환 횟수는 배열의 요솟값에 따라 달라지므로 평균값은 비교 횟수의 절반인 n*(n-1)/4. 서로 이웃한 요소에 대해서만 교환하므로 안정적인 알고리즘임. 특징 장점 단순함. 단점 특정 요소가 적절한 위치에 있음에도 인접한 요소와의 대소관계만을 고려하기 때문에 교환이 이루어지는 상황 발생할 수 있음. 지나친 교환작업. 코드 //교환 메서드static void swap(int[] a, int idx1, int idx2){ int tmp = a[idx1]; a[idx1] = a[idx2]; a[idx2] = tmp;}//정렬 메서드static void bubbleSort(int[] a, int n){ for(int i=0; i&lt;n-1; i++){ for(int j=n-1; j &gt; i; j--){ if(a[j]&lt;a[j-1]) swap(a, j-1, j); } }} 알고리즘 개선 n개의 요소를 가진 배열의 모든 정렬이 끝나려면 패스는 n-1회 수행되어야 하는데, 이미 정렬이 되어있는 경우에는 굳이 수행할 필요 없음. 반복문 안에서 교환 횟수가 0일 경우 정렬을 중단하는 방법(1), 혹은 마지막에 정렬을 수행한 위치를 기억하여 범위를 줄여나가는 방법(2)이 있음. static void bubbleSort_1(int[] a, int n){ for(int i=n-1; i&gt;0; i--){ int cnt = 0; for(int j=0; j&lt;i; j++){ if(a[j] &gt; a[j+1]){ swap(a, j, j+1); cnt++; } } //교환이 없다는 것은 정렬된 상태라는 것이므로 중단한다. if(cnt == 0) break; } } static void bubbleSort_2(int[] a, int n){ int last = n-1; for(int i=n-1; i&gt;0; i--){ for(int j=0; j&lt;i; j++){ if(a[j] &gt; a[j+1]){ swap(a, j, j+1); //last의 값을 가장 마지막의 인덱스로 계속 갱신 last = j; } } //범위를 좁힌다. i = last; } } 정렬 과정에서 값은 한 칸씩 이동하므로, 최댓값이 맨 처음에 있는 경우나, 최솟값이 맨 마지막에 있는 경우에는 위의 두 방법이 무의미함. 이러한 문제를 해결할 수 있는 알고리즘 : 양방향 버블정렬 = 칵테일 정렬 = 셰이커 정렬 패스를 수행할 때마다 방향을 바꾸어 정렬하는 알고리즘. 그림을 통해 이해하면 쉽다. 구현 코드 static void shakerSort(int[] a, int n){ int left = 0; int right, last = right = n-1; while(left &lt; right){ //왼 -&gt; 오 for(int i=0; i&lt;right; i++){ if(a[i] &gt; a[i+1]){ swap(a, i, i+1); last = i; } } right = last; //오 -&gt; 왼 for(int i=right; i&gt;left; i--){ if(a[i] &lt; a[i-1]){ swap(a, i-1, i); last = i; } } left = last; }}//(2)번 방법을 양방향으로 한다고 보면 될듯. 06-3. 단순 선택 정렬 가장 작은 요소부터 적절한 위치에 배치하여 정렬하는 알고리즘. 아직 정렬하지 않은 요소 중 가장 작은 값의 요소를 선택하고, 이 값을 정렬하지 않은 첫 번째 요소와 교체함. 제자리 정렬(추가 메모리 요하지 않음.) 특징 장점 비교횟수는 많은 대신 교환횟수가 적음. 따라서 교환횟수가 많이 요구되는 역순정렬에 유리함. 단점 매번 최솟값을 찾기 때문에 정렬을 위한 비교횟수가 많음. 서로 떨어져있는 요소를 교환하는 알고리즘이기 때문에 기존 배열 요소의 순서가 보장되지 않음. 안정적이지X. 구현 static void selectionSort(int[] a, int n){ for(int i=0; i&lt;n; i++){ int min = i; //일단 정렬되지 않은 첫 번째 요소의 인덱스를 최솟값의 인덱스로 지정함. for(int j=i+1; j&lt;n; j++){ if(a[min] &gt; a[j]) min = j //반복문 돌며, 정렬되지 않은 요소중 최솟값을 찾는 과정 } swap(a, i, min); //교환 }} 06-4. 단순 삽입 정렬 단순 선택 정렬은 최솟값을 찾아 맨 앞부터 교환해나가는 알고리즘이었다면, 단순 삽입 정렬은 정렬되지 않은 요소 중 첫 번째 요소를 정렬된 부분의 적절한 위치를 찾아서 끼워넣는 것. 떨어져 있는 요소들이 서로 뒤바뀌지 않기 때문에 안정적인 정렬. 특징 장점 최선의 경우(교환 없이 비교만 이루어지는 경우-&gt;내부 반복문은 수행되지 않음. n-1회의 비교만을 수행) O(N)의 시간복잡도를 가짐. 요소의 개수가 적거나 정렬상태에 가까울수록 효율적임. 단점 요소의 개수가 많을 경우 비효율적. 구현 static void insertionSort(int[] a, int n){ //맨 첫번째 요소(a[0])는 정렬되어 있는 것으로 간주. i=1부터 for(int i=1; i&lt;n; i++){ int j; //정렬할 대상은 a[i]. 정렬되지 않은 부분의 첫 요소 int tmp = a[i]; //정렬되지 않은 첫 요소의 인덱스부터 시작한다. //앞의 요소가 정렬 대상 요소보다 크다면 for(j = i; j&gt;0 &amp;&amp; a[j-1] &gt; tmp; j--){ //뒤로 땡긴다. a[j] = a[j-1]; }//배열의 맨 앞까지 도달(정렬 대상보다 작은 요소가 없는 경우)하거나 //정렬 대상 요소보다 작거나 같은 값이 존재하는 경우에는 a[j] = tmp; //값 삽입. }} 보초법을 이용한 단순 삽입 정렬 보초법은 선형검색 파트에서 다뤘었음. 검색 목표 값을 배열 후단에 추가하여 검색 실패시의 조건(인덱스가 끝까지 다다랐을 경우)을 생략할 수 있도록 하는 방법. 단순 삽입 정렬에서 j가 0보다 클 때를 조건에서 제하기 위해 배열 첫 요소에 tmp값을 계속 넣어주면 j가 0보다 크고 a[j-1]의 값이 tmp 값보다 클 때라는 두 가지 조건을 하나로 줄일 수 있음. 구현 static void selectionSort(int[] a, int n){ for(int i=2; i&lt;n; i++){ int tmp = a[0] = a[i]; //a[i]의 값은 정렬을 위해 삽입할 값이며 위치 탐색의 종료 조건으로서 a[0]에 세팅. int j = i; while(a[j-1]&gt;tmp){ //기존에는 j가 양수인 경우까지 따져줘야 했으나, 보초법을 통해 조건 하나를 제할 수 있음. a[j] = a[j-1]; j--; } if(j&gt;0) a[j] = tmp; }} 이진 검색을 이용한 단순 삽입 정렬 단순 삽입 정렬은 요소 수가 많아질 수록 비교와 대입을 위한 비용이 커짐 단순 삽입 정렬은 특성상 정렬된 부분과 정렬되지 않은 부분으로 나뉘고, 정렬된 배열에 대해 이진 검색이 가능하므로 이를 활용하여 효율적으로 정렬시킬 수 있음. 구현 static void selectionSortBinary(int[] a, int n){ for(int i=1; i&lt;n; i++){ int l = 0; int r = i-1;//정렬된 부분으로 검색 범위 제한 int key = a[i]; int c; do{ c = (l+r)/2; if(a[c] == key) break; else if(a[c] &lt; key) l = c+1; else r = c-1; }while(l&lt;=r); int idx = (l&lt;=r) ? c+1 : r+1; //한 칸씩 시프팅 for(int j=i; j&gt;idx; j--){ a[j] = a[j-1]; } //멈춘 위치에서 key값 대입. a[idx] = key; }} 06-5. 셸 정렬 단순 삽입 정렬은 정렬되지 않은 요소가 적절한 위치에서 멀리 떨어져있을 경우 적절한 위치부터 해당 요소의 앞까지 모두 시프팅을 해야한다는 단점이 있음. 셸 정렬은 정렬할 배열의 요소를 몇 개의 그룹으로 나누어 그룹별로 단순 삽입 정렬을 수행하고, 그룹을 합쳐가며 정렬해나간다. 이러면 배열은 정렬된 상태에 가까워짐 특징 장점 셸 정렬에 의하면 정렬해야 하는 횟수는 늘지만, 요소 이동의 횟수는 줄어듬.(삽입정렬 보완) 단점 간격 설정이 효율적이지 못할 경우 성능이 저하될 수 있음. 구현 static void shellSort(int[] a, int n){ //셸 정렬은 간격을 기준으로 배열을 부분 배열로 나누는데, //간격은 일단 배열 길이를 2로 나누어 가며 사용함. for(int interval = n/2; interval&gt;=1; interval/=2){ //비교 및 요소 이동 로직은 삽입 정렬과 동일하나, //차이는 비교하는 두 요소가 붙어있는 것이 아니라 interval만큼 떨어져있음. for(int start = interval; start&lt;n; start++){ int j; int key = a[start]; for(j=start; j&gt;=0 &amp;&amp; a[j-interval] &gt; key; j-=interval){ a[j] = a[j-interval]; } a[j] = key; } }} 효율적인 간격? 셸 정렬을 위한 간격은 너무 적으면 속도가 느리고, 간격이 너무 많으면 오버헤드가 발생한다. 때문에 다양한 정형화된 간격이 존재하는 것 같은데, 해당 교재에서는 1, 4, 13, 40, 121, … 즉 전 항에 3을 곱하고 1을 더한 수열을 제시한다. 또한 오버헤드가 발생하지 않도록 간격이 배열의 요소수를 9로 나눈 몫을 넘지 않도록 한다. 정리하자면 n을 요솟수라고 하였을 때, i(x+1) = i(x)*3+1 간격 &lt; n/9 구현 static void shellSort_v2(int[] a, int n){ int interval=1; for(; interval&lt;n/9; interval=interval*3+1){} for(; interval&gt;0; interval/=3){ for(int start=interval; start&lt;n; start++){ int j, tmp = a[start]; for(j=start-interval; j&gt;=0 &amp;&amp; a[j] &gt; tmp; j--){ a[j+interval] = a[j]; } a[j+interval] = tmp; } } } 06-6. 퀵 정렬 정렬 속도가 매우 빠른 정렬 알고리즘 중 하나. 단, 요소의 수가 적으면 비효율적일 수 있다. 그룹의 요소 중 기준이 될 요소(피벗, 배열의 가운데 요소)을 하나 택하여 피벗을 기준으로 그룹을 나누고, 다시 피벗을 설정하고 그룹을 나누는 과정을 반복하는 정렬 알고리즘.(분할 정복 기법, 재귀 호출) 특징 장점 별도의 추가적인 메모리를 사용하지 않아 제자리 정렬의 특징을 지닌다. 단점 서로 떨어진 요소들을 교환하기 때문에 안정적이지 않음 피벗을 잘못 설정할 경우 성능이 저하될 수 있음. 과정1 : 왼-&gt;오 방향으로 피벗보다 큰 값의 요소를 찾을 때까지 진행하고(인덱스 l), 2 : 오-&gt;왼 방향으로 피벗보다 작은 값의 요소를 찾을 때까지 진행한다.(인덱스 r) 3 : 배열[l]과 배열[r]을 교환하며 위 과정을 l과 r이 교차할 때까지 계속 반복한다. 4 : l과 r이 교차하는 것이 아닌 같아지는 경우는 별도로 체크하지 않고 배열[l]과 배열[r]을 교환하는 무의미한 작업을 수행하도록 한다. 해당 문제를 교환으로 해결할 경우는 수행 횟수가 최대 1회에 그치지만, 조건으로 해결하고자 할 때에는 수행 횟수가 n회이기 때문. 구현 static void partition(int[] a, int n){ int l = 0; int r = n-1; int pivot = a[n/2]; do{ while(a[l]&lt;pivot) l++; while(a[r]&gt;pivot) r--; if(pl&lt;=pr) swap(a, l++, r--); //교환 하고 다음부터 진행하도록 증감연산자 사용. }while(l&lt;=r);} 퀵 정렬은 분할 정렬 알고리즘이므로, 위의 partion 메서드를 토대로 재귀 호출을 통해 퀵 정렬을 구현할 수 있음. 재귀 호출 할 것이므로 종료 조건을 명확히 해야 한다. 그런데 이 알고리즘은 재귀 호출하는 과정에서 최소한 피벗은 위치가 정해지기 때문에 종료 조건이 명확함. 구현(재귀) static void quickSort_recursive(int[] a, int left, int right){ int l = left; int r = right; int pivot = a[(l + r)/2]; do{ while(a[l] &lt; pivot) l++; while(a[r] &gt; pivot) r--; if(l&lt;=r) swap(a, l++, r--); }while(l&lt;=r); ////////////////재귀 호출//////////////// if(left&lt;r) quickSort(a, left, r); if(right&gt;l) quickSort(a, l, right); ////////////////////////////////////////} 위의 루프 부분에서 l과 r은 교차하게 되고, 왼쪽 그룹에 대한 퀵 정렬을 위해 right의 인자값으로 r을, 오른쪽 그룹에 대한 퀵 정렬을 위해 left의 인자값으로 l을 넘겨준다. 그룹의 요소가 하나만 남았을 때는 더 이상 정렬할 필요가 없기 때문에 각 그룹의 재귀 호출에 대해 조건을 걸어준다. (요소가 하나만 남았을 경우 left와 r은 같을 것이므로 조건이 거짓이고 따라서 탈출. l과 right의 경우도 마찬가지.) 구현(비재귀) static void quickSort_non_recursive(int[] a, int left, int right){ //좌 우로 나뉘는 그룹의 인덱스를 기억할 스택. //lStk에는 그룹의 첫번째 인덱스를, rStk에는 그룹의 끝 인덱스를 저장한다. Stack lStk = new Stack(right - left + 1); Stack rStk = new Stack(right - left + 1); lStk.push(left); rStk.push(right); while(!lStk.isEmpty()){ int l = left = lStk.pop(); int r = right = rStk.pop(); int pivot = a[(l + r)/2]; do{ while(a[l] &lt; pivot) l++; while(a[r] &gt; pivot) r--; if(l&lt;=r) swap(a, l++, r--); }while(l&lt;=r); if(l&lt;right){ lStk.push(l); rStk.push(right); } if(r&gt;left){ lStk.push(left); rStk.push(r); } }} 스택의 크기 피벗을 기준으로 나뉘는 두 그룹의 요소의 개수는 차이가 있을 수 있다. 이에 착안하여 스택에 push하는 순서를 지정함으로써 퀵 정렬에 사용할 스택의 크기를 작게 할 수 있다. 예를 들어 나뉜 두 그룹중 요소의 개수가 적은 그룹 x와 많은 그룹 y가 있을 때, x의 인덱스를 먼저 push한다면 나중에 push되는 y의 인덱스가 먼저 pop되어 y부터 정렬이 시작된다. 당연히 요소의 수가 적을수록 적은 횟수의 분할로 정렬을 마무리 할 수 있으므로 스택에 동시에 쌓이는 데이터의 수도 적음. 위 방식대로 요소의 수가 적은 그룹부터 정렬을 해나가도록 하면 전체 배열의 요수 수가 n개라고 할 때, 스택에 쌓이는 데이터의 최대 개수는 log n에 불과하다.(?) 요소 수가 더 많은 부분 배열을 먼저 푸쉬하고 요소 수가 적은 배열을 나중에 푸쉬하도록 left와 pr, pl과 right의 차이를 대소비교 하고, 조건식을 통해 순서를 제어한다. //처리 순서를 조건에 따라 직접 지정하는 것보다 변수를 교체해주는 편이 간결함. if(pr - left &gt; right - pl){ int tmp; tmp = pr; pr = right; right = tmp; tmp = left; left = pl; pl = tmp; } if(right &gt; pl){ lStk.push(pl); rStk.push(right); } if(pr &gt; left){ lStk.push(left); rStk.push(pr); } 피벗의 선정 퀵 정렬은 피벗을 기준으로 배열을 각 그룹으로 분할하고 정렬하는 과정을 반복하는 알고리즘이기 때문에, 피벗 선정에 있어서 한 쪽으로 치우치게 되면 효율적인 정렬을 기대할 수 없음. 안정적이고 효율적인 정렬을 위해선 배열의 중앙값을 피벗으로 선정하면 되지만, 배열 전체에 대해 이러한 작업을 수행하는 것은 지나치기 때문에 제시되는 방법 두 가지가 존재. 첫번째, 나눌 배열의 요소의 개수가 3개 이상이면, 임의의 세 개의 요소를 선택하고 그 중 중앙값인 요소를 피벗으로 선정한다. 두번째, 나눌 배열의 처음, 가운데, 끝 요소를 정렬한 다음 가운데 요소와 끝에서 두 번째 요소를 교환하여 나눌 범위를 축소한다.(기존에는 스캔 범위가 left ~ right였으나, 해당 과정을 거친 후에는 left+1 ~ right-2로 축소됨.) static int sortMedain(int[] a, int x, int y, int z){ if(a[x] &gt; a[y]) swap(a, x, y); if(a[y] &gt; a[z]) swap(a, y, z); if(a[x] &gt; a[y]) swap(a, x, y); return y; } static void quickSort_non_recursive(int[] a, int left, int right){ Stack lStk = new Stack(right - left + 1); Stack rStk = new Stack(right - left + 1); lStk.push(left); rStk.push(right); while(!lStk.isEmpty()){ int l = left = (int)lStk.pop(); int r = right = (int)rStk.pop(); //중앙값의 인덱스를 구해 int m = sortMedain(a, l, (l+r)/2, r); //해당 인덱스의 요소를 피벗으로 지정. int pivot = a[m]; //피벗을 배열의 맨 뒤에서 두번째 요소와 교체 swap(a, m, r-1); //스캔범위 축소 l++; r-=2; //첫 번째 방법은 피벗을 중간값으로 구해주기만 하면 됨. do{ while(a[l] &lt; pivot) l++; while(a[r] &gt; pivot) r--; if(l&lt;=r) swap(a, l++, r--); }while(l&lt;=r); if(l&lt;right){ lStk.push(l); rStk.push(right); } if(r&gt;left){ lStk.push(left); rStk.push(r); } } } 06-7. 병합 정렬 배열을 앞부분과 뒷부분으로 나누어 각각 정렬한 다음 병합하는 작업을 반복적으로 수행하여 정렬하는 알고리즘. 분할 정복 알고리즘 과정 배열을 반으로 나누어 2개의 부분 배열로 분할함 부분 배열을 정렬하되, 부분 배열의 크기가 충분히 작지 않으면 재귀 호출. 정렬 과정에서 앞 부분의 배열을 별도의 공간에 저장하고, 뒷 부분과 대소 비교(제자리 정렬 아님.) Linked List로 구성된 레코드에 대해 병합 정렬 수행할 경우 제자리 정렬로 구현 가능. 매우 효율적 정렬된 부분 배열을 병합 특징 장점 퀵정렬과 달리 항상 절반으로 분할하기 때문에 분할 기준에 따른 성능 저하가 없음. 단점 추가적인 메모리가 요구됨. 구현 static int[] buffer; static void mergeSort(int[] a, int n){ buffer = new int[n]; __mergeSort(a, 0, n-1); buffer = null; } static void __mergeSort(int[] a, int left, int right){ if(left &lt; right){ int i, j, k, l, center; i = 0; j = 0; k = left; l = 0; center = (left + right)/2; //분할 __mergeSort(a, left, center); __mergeSort(a, center+1, right); //정렬 및 합병 for(i = left; i&lt;=center; i++) //별도 공간에 배열 앞 부분 복사 buffer[l++] = a[i]; //(1) while(i&lt;=right &amp;&amp; j &lt; l) //대소 비교하여 작은 값을 배열의 앞 부분부터 채움 a[k++] = (buffer[j] &lt;= a[i]) ? buffer[j++] : a[i++]; //(2) while(j &lt; l) //buff에 남아있는 요소가 있다면 배열 a에 복사. a[k++] = buffer[j++]; } } Arrays 클래스의 정렬 메서드 기본 자료형을 요소로 하는 배열의 정렬(Arrays.sort)메서드는 퀵 정렬 알고리즘 사용. 참조 자료형을 요소로 하는 배열의 정렬 메서드는 두 종류로 나눌 수 있음. 병합 정렬 알고리즘 사용. 자연 정렬이 필요한 배열 Comparable 인터페이스와 compateTo 메서드 구현 자연 정렬이 필요하지 않은 배열 Comparator 구현체를 매개변수로 전달. 06-8. 힙 정렬06-99. 시간복잡도 비교Reference Do it! 자료구조와 함께 배우는 알고리즘 입문 자바 편" }, { "title": "Log4j2", "url": "/posts/Log4j2/", "categories": "Spring, Log4j2", "tags": "log4j2", "date": "2022-05-09 00:00:00 +0900", "snippet": "Springboot, Log4j, gradle1. 의존성 설정 spring-boot-starter-web은 logback이 default 로깅 모듈이기 때문에 log4j2 의존성을 그대로 추가하면 multiple binding error가 발생한다. 따라서 spring-boot-starter-logging을 exclude.configurations { all{ exclude group : 'org.springframework.boot' module : 'spring-boot-starter-logging' }}dependencies{ implementation 'org.springframework.boot:spring-boot-starter-log4j2' //yml dataformat 의존성. implementation 'com.fasterxml.jackson.dataformat:jackson-dataformat-yaml'}2. application.yml 설정logging: config: classpath:log4j2.yml #yml파일이 src 외부에 있는 경우에는 file:3. log4j2.yml 설정Configuration: name: DefaultConfig status: warn Properties: property: name: filePath value: target/test-yml.log appenders: Console: name: Console_Appender target: SYSTEM_OUT PatternLayout: pattern: \"[%d{yyyy-MM-dd HH:mm:ss}][%-5level] [%t] [%logger{36}(%L)] - %m %n\" Loggers: logger: - name: com.springframework level: debug additivity: false AppenderRef: ref: Console_Appender Root: level: info AppenderRef: ref: Console_Appender Configuration로그 설정의 최상위 요소. Properties, Appenders, Loggers 자식요소를 가짐. additivitylogger는 정의한 패키지의 조상으로부터 모든 appender를 상속받기 때문에 부모 자식관계의 logger가 같은 appender를 사용한다면 같은 로그가 중복되게 찍힘. 이런 경우 자식 logger의 additivity를 false로 주면 이런 중복을 막을 수 있음 Appenderlog 메시지를 특정 위치에 전달해주는 역할을 한다. layout을 통해 로그를 formatting하고, 어떤 방식으로 로그를 제공할지 결정함.Appender는 ConsoleAppender, RollingFileAppender, AsyncAppender, FileAppender, JDBCAppender, SMTP 등등 존재. Logger로깅 작업의 수행주체. Root Logger를 포함한 모든 Logger는 Loggers 아래에 선언한다. Logger의 level과 appender의 name에 따라 출력 대상과 위치 결정된다. 여기서 level은 최하 레벨을 의미. ThresholdFilterlevel, onMatch, onMismatch 속성을 지정할 수 있는데, log event에서 넘어온 level이 thresholdfilter에서 지정한 log level보다 같거나 높으면 onMatch를 따르고, 그렇지 않을 경우에는 onMismatch를 따름.onMatch, onMismatch의 속성으로는 ACCEPT, DENY, NEUTRAL이 있다.DENY : 로그 이벤트는 drop, 나머지 필터 검증과정 거치지 않음.NEUTRAL : 다음 필터에게 검증을 넘김.ACCEPT : 다른 필터 decide과정 스킵 후 동작 ThreadContextMapFilter ThreadContext에 있는 key/value가 일치할 때만 onMatch, 아닐땐 onMismatch etc Log Level 종류 로그 레벨 설명 fatal 애플리케이션 작동이 불가능할 정도의 심각한 에러 error 요청 처리 중 문제가 발생한 상태 warn 처리 가능한 문제이지만 향후 시스템 에러의 원인이 될 수 있는 경고성 메시지 info 로그인, 상태변경과 같은 정보성 메시지 debug 개발시 디버그 용도로 사용한 메시지 trace 디버그 레벨이 너무 광범위한 것을 해결하기 위해 좀 더 상세한 상태를 나타냄 PatternLayout Format 표현 설명 %c, %logger 해당 로그를 쓰는 로거의 이름. %C, %class 해당 로그를 요청한 클래스 이름. %d, %date 해당 로그가 발생한 시간 %enc, %encode 특정 언어에서의 출력을 위한 문자 인코딩 %ex, %exception, %throwable 예외 로그. 길이 설정 가능 %F, %file 해당 로그가 발생한 클래스 파일명 %l, %location 해당 로그가 발생한 클래스명.메소드명(파일:라인) %L, %line 해당 로그가 발생한 라인 번호 %m, %msg, %message 로그문에 전달된 메시지 %n 줄바꿈 %p, %level 로그 레벨 %r, %relative 로그 처리시간 %t, %thread 해당 로그가 발생한 스레드명 %style{pattern}{ANSI style} ANSI를 사용해 특정 패턴 스타일링 %highlight{pattern}{style} 로그 레벨명을 ANSI 색깔로 하이라이트 Referenceshttps://aircook.tistory.com/entry/log4j%EC%9D%98-additivity-%EC%98%B5%EC%85%98https://velog.io/@bread_dd/Log4j-2-%EC%A0%9C%EB%8C%80%EB%A1%9C-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0-%EA%B0%9C%EB%85%90https://velog.io/@2dh2wdk/%EC%8A%A4%ED%94%84%EB%A7%81%EB%B6%80%ED%8A%B8%EC%97%90-log4j2-%EC%84%A4%EC%A0%95https://www.egovframe.go.kr/wiki/doku.php?id=egovframework:rte:fdl:logging" }, { "title": "Jekyll, Chirpy doc", "url": "/posts/chirpy-Notes/", "categories": "etc, Jekyll_Chirpy", "tags": "chirpy", "date": "2022-05-06 00:00:00 +0900", "snippet": "서문 Jekyll, chirpy를 이용한 깃헙 블로그를 만들기 위해 찾아본 chirpy, Jekyll 문서 일부를 번역한 글입니다. 잘못된 정보가 있을 수도 있습니다Jekyll Predefined VariablesJekyll doc 변수 설명 layout 사용할 layout 파일을 특정하는 속성. 확장자는 제외하고 파일명만. layout 파일은 반드시 _layouts directory에 위치해야 함. permalink 다른 blog의 post 사용하고 싶을때. final url로 사용됨. published generated 됐을 때 보여줄지 말지 date post의 날짜를 덮어쓸 수 있으며 정확성 있는 정렬에 활용될 수 있음. 형식은 YYYY-MM-DD HH:MM:SS +/- TTTT인데, 뒤의 timezone은 optional. categorycategories 특정 폴더에 post를 위치시키는 대신, post가 속할 하나 이상의 카테고리를 지정할 수 있음. tags categories와 비슷함. 하나 이상의 tags들이 post에 추가될 수 있음. Custom Variablesfront matter block에서 변수를 지정하여 다음의 방식으로 본문에서 사용할 수 있음.---food: Pizza---&lt;h1&gt;{{ page.food }}&lt;/h1&gt;Chirpy GuideFront Mattertitle: TITLEdate: YYYY-MM-DD HH:MM:SS +/-TTTTcategories: [TOP_CATEGORIE, SUB_CATEGORIE]tags: [TAG] # TAG names should always be lowercaselayout 속성은 default 설정되어있으므로 Front Matter block에 추가할 필요 없음." }, { "title": "build.gradle의 dependencies configuration", "url": "/posts/build.gradle%EC%9D%98-dependencies-configuration/", "categories": "Spring, gradle", "tags": "gradle, scope, dependencies configuration", "date": "2022-05-06 00:00:00 +0900", "snippet": " gradle document 링크1.Java Library Plugin 설정 구성 녹색은 의존성 선언시 사용하는 키워드 파랑색은 클래스 패스. compileClasspath는 compileOnly와 implementation, runtimeClasspath는 runtimeOnly와 implementation과 연결되어 있는 걸 확인할 수 있음. 잘 모르겠을때 implementation 때려박으면 되는 이유.@TODO 분홍색은 컴포넌트가 컴파일되거나 라이브러리에 대해 실행될 때 사용된다고 하는데 잘 모르겠음. apiElements는 library 컴파일시, runtimeElements는 library 실행시 필수적인 라이브러리를 찾기 위해 사용된다는 설명.2.Java Test Library Plugin 설정 구성3.구성요소 컴파일 타임에만 사용될 때에는 compileOnly, 런타임에만 사용될 때에는 runtimeOnly, 테스트시에는 앞에 test가 붙은 키워드 사용하면 된다. api가 뒤에 붙은 것들이 눈에 보이는데 implementation과 api의 차이를 알아야 함. 4.Implementation과 Api의 차이gradle 문서의 설명에 보면 api에 대해선 transitively exported to consumers implementation에 대해선 purely internal and not meant to be exposed to consumers라고 적혀있음. A라는 모듈에서 api를 통해 어떠한 라이브러리를 가져오게 되면, A 모듈을 의존하고 있는 다른 모듈에서도 동일한 라이브러리를 가져옴. A 모듈을 사용하는 다른 모듈은 A의 인터페이스만 알고 사용할 수 있도록 해야 하는데 A의 라이브러리까지 다른 모듈에서 알게 되는 것. 반면 implementation을 통해 어떠한 라이브러리를 가져오게 되면, A 모듈을 의존하고 있는 다른 모듈에서는 라이브러리를 가져오지 않는다. 정리하자면, api와 implementation은 모듈간 coupling 관계에 있어서 차이를 가짐. 유지보수적 측면에서 implementation을 쓰는 것이 좋음. etc 롬복의 경우에는 컴파일타임에 이미 작성된 코드의 동작 방식을 변경시키기 위해 annotationProcessor를 추가적으로 사용함.test시에는 testCompileOnly와 testAnnotationProcessor그 외에는 compileOnly와 annotationProcessorbuild.gradle의 configurations block에 compileOnly가 annotationProcessor 상속받도록 설정이 되어 있음. test의 경우에도 똑같이 적용시켜 testCompileOnly만 dependencies에 잡아줘도 됨.Reference4. api와 implementation의 차이" }, { "title": "Chirpy로 깃헙 블로그 만들기", "url": "/posts/Chipry%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%B4-%EA%B9%83%ED%97%99%EB%B8%94%EB%A1%9C%EA%B7%B8-%EB%A7%8C%EB%93%A4%EA%B8%B0/", "categories": "etc, Jekyll_Chirpy", "tags": "jekyll, chirpy", "date": "2022-05-06 00:00:00 +0900", "snippet": "로컬 환경 구성 ruby 설치. 참고 github에서 소스를 fork받거나 zip을 받아 임의의 directory에 설치 github 도메인을 사용하기 위해선 &lt;github 아이디&gt;.github.io로 소스 홈에서 명령 사용하여 chirpy 초기화하기 $ tools/init.sh 성공시 [INFO] Initializeation successful! 로컬에서 실행하여 테스트 $ bundle --&gt; 의존성 모듈 설치$ jekyll serve --&gt; 로컬 실행. 127.0.0.1:4000 배포 해당 github repository에 commit, push repository Settings &gt; Pages &gt; Source 에서 Branch를 gh-pages로 변경 에러 403 에러 : Settings &gt; Actions &gt; General &gt; Workflow permissions를 Read and write permissions로 변경 " }, { "title": "마크다운 정리", "url": "/posts/%EB%A7%88%ED%81%AC%EB%8B%A4%EC%9A%B4-%EC%A0%95%EB%A6%AC/", "categories": "etc, Markdown", "tags": "markdown", "date": "2022-05-05 00:00:00 +0900", "snippet": "1. 제목 {#}, [======, ——]2. 구분선 * * *, —, ___3. 강조 이탤릭체*내용* || _내용_ Bold**내용**||**내용** 취소~~내용~~ 밑줄&lt;u&gt;&lt;/u&gt; 4. 링크 [대체텍스트][url \"링크 설명\"] ex) - [Naver](https://naver.com) : Naver - &lt;https://naver.com&gt; : https://naver.com url만 사용하고자 한다면 &lt;URL&gt; 형식으로.5. 이미지(Images) ![대체 텍스트](링크) ex) ![chirpy theme](../assets/img/favicons/android-chrome-512x512.png) 6. 코드(Code) 강조 `` ` : grave 3개로 감싸면 코드블럭 {{ }} 사용하고자 할 때는 {% row %}와 {% endrow %}로 감쌀 것.7. 표 헤더 구분 : 세 개 이상의 dash 사용 dash 뒤에 Colons(:)으로 내용 정렬 가능 가장 우측과 좌측에 있는 | 기호는 생략 가능 테이블 내에서 개행을 하려면 &lt;br&gt; 칼럼1 칼럼2 칼럼3 static 유형(기준)없음/배치 불가능 static relative 요소 자신을 기준으로 배치   absolute 위치 상 부모(조상) 요소를 기준으로 배치   fixed 브라우저 창을 기준으로 배치   8. 인용문 인용문 : &gt; 사용 인용문 1 인용문 2(&gt; 두개) 인용문 3(&gt; 세개) 9. Markdown에서 특수문자 사용하기 Symbol HTML Number HTML Name ! &#38;#33;   ” &#38;#34; &#38;quot; # &#38;#35;   $ &#38;#36;   % &#38;#37;   &amp; &#38;#38; &#38;amp; ’ &#38;#39;   ( &#38;#40;   ) &#38;#41;   * &#38;#42;   + &#38;#43;   , &#38;#44;   - &#38;#45;   . &#38;#46;   / &#38;#47;   : &#38;#58;   ; &#38;#59;   &lt; &#38;#60; &#38;lt; = &#38;#61;   &gt; &#38;#62; &#38;gt; ? &#38;#63;   @ &#38;#64;   [ &#38;#91;   \\ &#38;#92;   ] &#38;#93;   ^ &#38;#94;   _ &#38;#95;   ` &#38;#96;   { &#38;#123;   | &#38;#124;   } &#38;#125;   ~ &#38;#126;   " } ]
